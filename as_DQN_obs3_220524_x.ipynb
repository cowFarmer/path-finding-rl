{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","__file__ = '/content/drive/Othercomputers/MacBook_Air/path-finding-rl/data'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lRpfPDrdk9wB","executionInfo":{"status":"ok","timestamp":1653374500568,"user_tz":-540,"elapsed":5892,"user":{"displayName":"노현호","userId":"15410213599666758892"}},"outputId":"f5eaca0b-b3d6-4ff4-85a6-4a10e5acb496"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["from string import ascii_uppercase\n","#from draw_utils import *\n","#from pyglet.gl import *\n","import numpy as np\n","import pandas as pd\n","import os\n","import random\n","from datetime import datetime\n","import pytz\n","import matplotlib.pyplot as plt\n","\n","# reward\n","move_reward = -0.1\n","obs_reward = -0.1\n","goal_reward = 10\n","###################################\n","# train or test 모드 지정\n","train_mode = True\n","###################################\n","print('reward:' , move_reward, obs_reward, goal_reward)\n","\n","#__file__ = '/home/ogangza/heung_path_finding/path-finding-rl/data' # GCP용\n","local_path = os.path.abspath(os.path.join(os.path.dirname(__file__)))\n","\n","\n","class Simulator:\n","    def __init__(self):\n","        '''\n","        height : 그리드 높이\n","        width : 그리드 너비 \n","        inds : A ~ Q alphabet list\n","        '''\n","        #######################################################################################\n","        # Load train or test data\n","        if train_mode:  # 훈련 데이타 읽기\n","            self.files = pd.read_csv(os.path.join(local_path, \"data/factory_order_train.csv\"))\n","            print('data/factory_order_train.csv used')\n","        else:  # 테스트 데이터 읽기\n","            self.files = pd.read_csv(os.path.join(local_path, \"data/factory_order_test.csv\"))\n","            print('data/factory_order_test.csv used')\n","        #######################################################################################        \n","        self.height = 10\n","        self.width = 9\n","        self.inds = list(ascii_uppercase)[:17]\n","\n","    def set_box(self):\n","        '''\n","        아이템들이 있을 위치를 미리 정해놓고 그 위치 좌표들에 아이템이 들어올 수 있으므로 그리드에 100으로 표시한다.\n","        데이터 파일에서 이번 에피소드 아이템 정보를 받아 가져와야 할 아이템이 있는 좌표만 -100으로 표시한다.\n","        self.local_target에 에이전트가 이번에 방문해야할 좌표들을 저장한다.\n","        따라서 가져와야하는 아이템 좌표와 end point 좌표(처음 시작했던 좌표로 돌아와야하므로)가 들어가게 된다.\n","        '''\n","        box_data = pd.read_csv(os.path.join(local_path, \"./data/box.csv\"))\n","        \n","        # 물건이 들어있을 수 있는 경우\n","        for box in box_data.itertuples(index = True, name ='Pandas'):\n","            self.grid[getattr(box, \"row\")][getattr(box, \"col\")] = 100\n","\n","        # 물건이 실제 들어있는 경우\n","        order_item = list(set(self.inds) & set(self.items))\n","        order_csv = box_data[box_data['item'].isin(order_item)]\n","\n","        for order_box in order_csv.itertuples(index = True, name ='Pandas'):\n","            self.grid[getattr(order_box, \"row\")][getattr(order_box, \"col\")] = -100\n","            # local target에 가야 할 위치 좌표 넣기\n","            self.local_target.append(\n","                [getattr(order_box, \"row\"),\n","                 getattr(order_box, \"col\")]\n","                )\n","        # self.local_target.sort() \n","        self.local_target.append([9,4]) \n","\n","        # 알파벳을 Grid에 넣어서 -> grid에 2Dconv 적용 가능\n","\n","    def set_obstacle(self):\n","        '''\n","        장애물이 있어야하는 위치는 미리 obstacles.csv에 정의되어 있다. 이 좌표들을 0으로 표시한다.\n","        '''\n","        obstacles_data = pd.read_csv(os.path.join(local_path, \"./data/obstacles.csv\"))\n","        for obstacle in obstacles_data.itertuples(index = True, name ='Pandas'):\n","            self.grid[getattr(obstacle, \"row\")][getattr(obstacle, \"col\")] = 0\n","\n","    def reset(self, epi):\n","        '''\n","        reset()은 첫 스텝에서 사용되며 그리드에서 에이전트 위치가 start point에 있게 한다.\n","\n","        :param epi: episode, 에피소드 마다 가져와야 할 아이템 리스트를 불러올 때 사용\n","        :return: 초기셋팅 된 그리드\n","        :rtype: numpy.ndarray\n","        _____________________________________________________________________________________\n","        items : 이번 에피소드에서 가져와야하는 아이템들\n","        terminal_location : 현재 에이전트가 찾아가야하는 목적지\n","        local_target : 한 에피소드에서 찾아가야하는 아이템 좌표, 마지막 엔드 포인트 등의 위치좌표들\n","        actions: visualization을 위해 에이전트 action을 저장하는 리스트\n","        curloc : 현재 위치\n","        '''\n","\n","        # initial episode parameter setting\n","        self.epi = epi\n","        self.items = list(self.files.iloc[self.epi])[0]\n","        self.cumulative_reward = 0\n","        self.terminal_location = None\n","        self.local_target = []\n","        self.actions = []\n","\n","        # initial grid setting\n","        self.grid = np.ones((self.height, self.width), dtype=\"float16\")\n","\n","        # set information about the gridworld\n","        self.set_box()\n","        self.set_obstacle()\n","\n","        # start point를 grid에 표시\n","        ################################################\n","        self.curloc = [9, 4]  # 끝에 경로 길이 추가\n","        ################################################\n","        self.grid[int(self.curloc[0])][int(self.curloc[1])] = -5\n","        self.done = False\n","\n","        return self.grid\n","\n","    def apply_action(self, action, cur_x, cur_y):\n","        '''\n","        에이전트가 행한 action대로 현 에이전트의 위치좌표를 바꾼다.\n","        action은 discrete하며 4가지 up,down,left,right으로 정의된다.\n","        \n","        :param x: 에이전트의 현재 x 좌표\n","        :param y: 에이전트의 현재 y 좌표\n","        :return: action에 따라 변한 에이전트의 x 좌표, y 좌표\n","        :rtype: int, int\n","        '''\n","        new_x = cur_x\n","        new_y = cur_y\n","        # up\n","        if action == 0:\n","            new_x = cur_x - 1\n","        # down\n","        elif action == 1:\n","            new_x = cur_x + 1\n","        # left\n","        elif action == 2:\n","            new_y = cur_y - 1\n","        # right\n","        else:\n","            new_y = cur_y + 1\n","\n","        return int(new_x), int(new_y)\n","\n","    def get_reward(self, new_x, new_y, out_of_boundary):\n","        '''\n","        get_reward함수는 리워드를 계산하는 함수이며, 상황에 따라 에이전트가 action을 옳게 했는지 판단하는 지표가 된다.\n","\n","        :param new_x: action에 따른 에이전트 새로운 위치좌표 x\n","        :param new_y: action에 따른 에이전트 새로운 위치좌표 y\n","        :param out_of_boundary: 에이전트 위치가 그리드 밖이 되지 않도록 제한\n","        :return: action에 따른 리워드\n","        :rtype: float\n","        '''\n","\n","        # 바깥으로 나가는 경우\n","        if any(out_of_boundary):\n","            reward = obs_reward\n","                       \n","        else:\n","            # 장애물에 부딪히는 경우 \n","            if self.grid[new_x][new_y] == 0:\n","                reward = obs_reward  \n","\n","            # 현재 목표에 도달한 경우\n","            elif new_x == self.terminal_location[0] and new_y == self.terminal_location[1]:\n","                reward = goal_reward\n","\n","            # 그냥 움직이는 경우 \n","            else:\n","                reward = move_reward\n","\n","        return reward\n","\n","    def step(self, action):\n","        ''' \n","        에이전트의 action에 따라 step을 진행한다.\n","        action에 따라 에이전트 위치를 변환하고, action에 대해 리워드를 받고, 어느 상황에 에피소드가 종료되어야 하는지 등을 판단한다.\n","        에이전트가 endpoint에 도착하면 gif로 에피소드에서 에이전트의 행동이 저장된다.\n","\n","        :param action: 에이전트 행동\n","        :return:\n","            grid, 그리드\n","            reward, 리워드\n","            cumulative_reward, 누적 리워드\n","            done, 종료 여부\n","            goal_ob_reward, goal까지 아이템을 모두 가지고 돌아오는 finish율 계산을 위한 파라미터\n","\n","        :rtype: numpy.ndarray, float, float, bool, bool/str\n","\n","        (Hint : 시작 위치 (9,4)에서 up말고 다른 action은 전부 장애물이므로 action을 고정하는 것이 좋음)\n","        '''\n","\n","        self.terminal_location = self.local_target[0]\n","        cur_x,cur_y = self.curloc\n","        #############################################################\n","        # cur_x, cur_y, path_length = self.curloc  # 경로 길이 추가\n","        #############################################################\n","        self.actions.append((cur_x, cur_y))\n","        goal_ob_reward = False\n","        new_x, new_y = self.apply_action(action, cur_x, cur_y)\n","        out_of_boundary = [new_x < 0, new_x >= self.height, new_y < 0, new_y >= self.width]\n","\n","        # 바깥으로 나가는 경우 종료\n","        if any(out_of_boundary):\n","            #원 위치\n","            #new_x = cur_x\n","            #new_y = cur_y\n","            self.done = True\n","            goal_ob_reward = True\n","        else:\n","            # 장애물에 부딪히는 경우 종료\n","            if self.grid[new_x][new_y] == 0:\n","                #원 위치\n","                #new_x = cur_x\n","                #new_y = cur_y\n","                self.done = True\n","                goal_ob_reward = True\n","\n","            # 현재 목표에 도달한 경우, 다음 목표 설정\n","            elif new_x == self.terminal_location[0] and new_y == self.terminal_location[1]:\n","\n","                # end point 일 때\n","                if [new_x, new_y] == [9,4]:\n","                    self.done = True\n","\n","                self.local_target.remove(self.local_target[0])\n","                self.grid[cur_x][cur_y] = 1\n","                self.grid[new_x][new_y] = -5\n","                goal_ob_reward = True\n","                # self.curloc = [new_x, new_y, path_length]\n","                self.curloc = [new_x, new_y]\n","            else:\n","                # 그냥 움직이는 경우 \n","                self.grid[cur_x][cur_y] = 1\n","                self.grid[new_x][new_y] = -5\n","                # self.curloc = [new_x,new_y, path_length]\n","                self.curloc = [new_x,new_y]\n","                \n","        reward = self.get_reward(new_x, new_y, out_of_boundary)\n","        self.cumulative_reward += reward\n","        ########################################################\n","        if self.done == True:\n","            goal_of_reward = 'finish'\n","        ########################################################\n","        # print(f\"gird = \\n{self.grid}\")\n","\n","        return self.grid, reward, self.cumulative_reward, self.done, goal_ob_reward"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tQRnyv3UlBcu","executionInfo":{"status":"ok","timestamp":1653374574762,"user_tz":-540,"elapsed":632,"user":{"displayName":"노현호","userId":"15410213599666758892"}},"outputId":"073dd52a-31e8-4aeb-d488-9ed21c4d2dce"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["reward: -0.1 -0.1 10\n"]}]},{"cell_type":"code","execution_count":8,"metadata":{"id":"uwgy-OBbk1b4","executionInfo":{"status":"ok","timestamp":1653374686088,"user_tz":-540,"elapsed":786,"user":{"displayName":"노현호","userId":"15410213599666758892"}}},"outputs":[],"source":["import gym\n","import collections\n","import random\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","#Hyperparameters\n","learning_rate = 0.0005\n","gamma         = 0.98\n","buffer_limit  = 50000\n","batch_size    = 32\n","\n","class ReplayBuffer():\n","    def __init__(self):\n","        self.buffer = collections.deque(maxlen=buffer_limit)\n","    \n","    def put(self, transition):\n","        self.buffer.append(transition)\n","    \n","    def sample(self, n):\n","        mini_batch = random.sample(self.buffer, n)\n","        s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [], [], [], [], []\n","        \n","        for transition in mini_batch:\n","            s, a, r, s_prime, done_mask = transition\n","            s_lst.append(s)\n","            a_lst.append([a])\n","            r_lst.append([r])\n","            s_prime_lst.append(s_prime)\n","            done_mask_lst.append([done_mask])\n","        ##############################################################################\n","        ## *_list를 np.array(*_lst)로 변경\n","        ##############################################################################\n","        return torch.tensor(np.array(s_lst), dtype=torch.float), torch.tensor(np.array(a_lst)), \\\n","               torch.tensor(np.array(r_lst)), torch.tensor(np.array(s_prime_lst), dtype=torch.float), \\\n","               torch.tensor(np.array(done_mask_lst))\n","    \n","    def size(self):\n","        return len(self.buffer)\n","\n","class Qnet(nn.Module):\n","    def __init__(self):\n","        super(Qnet, self).__init__()\n","        ###################################################################\n","        self.fc1 = nn.Linear(94, 512)  # input 정보에 E(M, s, g) -> Map 90, start point 2, goal point 2\n","        ###################################################################\n","        self.fc2 = nn.Linear(512, 512)\n","        self.fc3 = nn.Linear(512, 4)\n","\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","      \n","    def sample_action(self, obs, epsilon):\n","        out = self.forward(obs)\n","        coin = random.random()\n","        if coin < epsilon:\n","            return random.randint(0,3)\n","        else : \n","            return out.argmax().item()\n","    ###################################################\n","    def test_action(self, obs):  # Test용 action 추가\n","        out = self.forward(obs)\n","        return out.argmax().item()\n","    ###################################################\n","            \n","def train(q, q_target, memory, optimizer):\n","    for i in range(10):\n","        s,a,r,s_prime,done_mask = memory.sample(batch_size)\n","\n","        q_out = q(s)\n","        q_a = q_out.gather(1,a)\n","        max_q_prime = q_target(s_prime).max(1)[0].unsqueeze(1)\n","        target = r + gamma * max_q_prime * done_mask\n","        loss = F.smooth_l1_loss(q_a, target)\n","        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","def main():\n","    tz = pytz.timezone('Asia/Seoul')\n","\n","    env = Simulator()\n","    q = Qnet()\n","    q_target = Qnet()\n","    q_target.load_state_dict(q.state_dict())\n","    memory = ReplayBuffer()\n","\n","    print_interval = 1000\n","    score = 0.0  \n","    optimizer = optim.Adam(q.parameters(), lr=learning_rate)\n","    print('len(env.files):', len(env.files))\n","\n","    for n_epi in range(len(env.files)): # range()의 인수로 len(env.files) 사용하면 됨 (=39,999)\n","        \n","        epsilon = max(0.01, 0.08 - 0.01*(n_epi/200)) #Linear annealing from 8% to 1%\n","        env.reset(n_epi)\n","        print(env.reset(n_epi))\n","\n","        ##################\n","        # path_length = len(env.local_target)\n","        # s_before = env.curloc\n","        # s_before.append(path_length)\n","        # s = np.array(s_before)\n","        # print(s_before)\n","        \n","        grid_map = env.grid.reshape(-1)\n","        start_point = [9,4]\n","        end_point = env.local_target[0]\n","\n","        grid_map = np.append(grid_map, start_point)\n","        grid_map = np.append(grid_map, end_point)\n","        s = grid_map\n","        # print(\"grid_map = \\n\")\n","        # print(grid_map)\n","        ##################\n","\n","        old_score = 0.0\n","        done = False\n","\n","        while not done:  # OB, 장애물, 최종 목표 도달시 종료\n","            a = q.sample_action(torch.from_numpy(s).float(), epsilon)  # 인풋 정보에 경로 길이 추가\n","            obs, r, cum_reward, done, goal_ob_reward = env.step(a)\n","            s_prime = np.array(env.curloc)\n","            done_mask = 0.0 if done else 1.0\n","            memory.put((s,a,r/10.0,s_prime, done_mask))\n","            s = s_prime\n","            score += r\n","            '''\n","            if score > old_score:\n","                    cur_time = datetime.now(tz)\n","                    simple_cur_time = cur_time.strftime(\"%H:%M:%S\")\n","                    print('▶ Episode #', n_epi, 'start time:', simple_cur_time, end='→')\n","                    print('Score =', score, 'appended actions =', s, end='...')\n","                    print('경로 길이:', len(env.actions))\n","            '''\n","            old_score = score\n","            #if done:\n","                #break\n","            # while loop 종료\n","\n","        ############################################################################\n","                ## memory.size(): 2000 → 20000 → 25000 수정... 이후 훈련 시작\n","        ############################################################################\n","        if memory.size() > 25000:\n","            train(q, q_target, memory, optimizer)\n","\n","        # print_interval (=1000) 마다 현황 디스플레이하고 q_target 업데이트 및 score 초기화\n","        if n_epi % print_interval == 0 and n_epi != 0:\n","            cur_time = datetime.now(tz)\n","            simple_cur_time = cur_time.strftime(\"%H:%M:%S\")\n","            print('▶ Episode #', n_epi, 'start time:', simple_cur_time, end='→')\n","\n","            q_target.load_state_dict(q.state_dict())\n","\n","            print(\"n_episode :{}, score : {:.1f}, n_buffer : {}, eps : {:.1f}%\".format(n_epi, score/print_interval, memory.size(), epsilon*100))\n","            score = 0.0\n","            # torch.save(q, '/content/drive/MyDrive/aiffelthon/data/model.pt')\n","            torch.save(q, '/content/drive/Othercomputers/MacBook_Air/path-finding-rl/data/model.pt')\n","\n","    # 모든 에피소드 종료 후 결과 디스플레이 및 q_target 업데이트\n","    cur_time = datetime.now(tz)\n","    simple_cur_time = cur_time.strftime(\"%H:%M:%S\")\n","    print('▶ Episode #', n_epi, 'start time:', simple_cur_time, end='→')\n","\n","    q_target.load_state_dict(q.state_dict())\n","\n","    print(\"n_episode :{}, score : {:.1f}, n_buffer : {}, eps : {:.1f}%\".format(n_epi, score/print_interval, memory.size(), epsilon*100))\n","    \n","    # 학습된 결과 저장\n","    # torch.save(q, '/content/drive/MyDrive/aiffelthon/data/model.pt')\n","    torch.save(q, '/content/drive/Othercomputers/MacBook_Air/path-finding-rl/data/model.pt')"]},{"cell_type":"code","source":["#train 모드 실행\n","main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"l2PN2ryWHNbt","executionInfo":{"status":"error","timestamp":1653374688081,"user_tz":-540,"elapsed":1997,"user":{"displayName":"노현호","userId":"15410213599666758892"}},"outputId":"94d1dc4b-5e54-4ebf-f576-0fe81b49c219"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["data/factory_order_train.csv used\n","len(env.files): 39999\n","[[ 100.  100.  100. -100.  100.  100.  100. -100. -100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [ 100.    1.    1.    1.    1.    1.    1.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[ 100. -100.  100.  100.  100.  100.  100.  100. -100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [ 100.    1.    1.    1.    1.    1.    1.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[ 100. -100.  100.  100.  100.  100.  100.  100. -100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [ 100.    1.    1.    1.    1.    1.    1.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [-100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[ 100.  100. -100.  100.  100.  100. -100.  100. -100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [ 100.    1.    1.    1.    1.    1.    1.    1. -100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[ 100. -100.  100.  100.  100. -100.  100.  100.  100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [-100.    1.    1.    1.    1.    1.    1.    1. -100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [-100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[ 100.  100. -100.  100. -100.  100. -100.  100.  100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [-100.    1.    1.    1.    1.    1.    1.    1.  100.]\n"," [-100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[ 100.  100.  100.  100. -100.  100.  100.  100.  100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [ 100.    1.    1.    1.    1.    1.    1.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[ 100.  100. -100.  100. -100. -100.  100.  100.  100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [ 100.    1.    1.    1.    1.    1.    1.    1.  100.]\n"," [-100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [-100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[ 100.  100.  100. -100.  100.  100.  100.  100.  100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [-100.    1.    1.    1.    1.    1.    1.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [-100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[ 100.  100.  100. -100.  100. -100. -100.  100.  100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [-100.    1.    1.    1.    1.    1.    1.    1. -100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[ 100. -100.  100.  100. -100.  100.  100.  100.  100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [-100.    1.    1.    1.    1.    1.    1.    1. -100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [-100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[ 100.  100.  100.  100.  100. -100. -100.  100.  100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [-100.    1.    1.    1.    1.    1.    1.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [-100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[-100. -100.  100. -100.  100.  100.  100. -100.  100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [ 100.    1.    1.    1.    1.    1.    1.    1.  100.]\n"," [-100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[ 100.  100. -100. -100. -100. -100.  100.  100.  100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [ 100.    1.    1.    1.    1.    1.    1.    1.  100.]\n"," [-100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[ 100.  100.  100.  100.  100. -100.  100. -100. -100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [ 100.    1.    1.    1.    1.    1.    1.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [-100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[-100.  100.  100. -100.  100.  100.  100. -100.  100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [-100.    1.    1.    1.    1.    1.    1.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [-100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [-100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[ 100.  100. -100.  100.  100.  100. -100. -100.  100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [ 100.    1.    1.    1.    1.    1.    1.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[-100.  100.  100. -100.  100.  100.  100.  100.  100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [-100.    1.    1.    1.    1.    1.    1.    1. -100.]\n"," [-100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[-100.  100.  100.  100.  100. -100.  100. -100.  100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [ 100.    1.    1.    1.    1.    1.    1.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[-100. -100.  100.  100. -100.  100. -100.  100.  100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [ 100.    1.    1.    1.    1.    1.    1.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [-100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [-100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[ 100.  100.  100. -100.  100. -100.  100. -100.  100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [ 100.    1.    1.    1.    1.    1.    1.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [-100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [-100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[ 100. -100.  100.  100. -100.  100.  100. -100. -100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [ 100.    1.    1.    1.    1.    1.    1.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [-100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[ 100. -100.  100.  100.  100.  100.  100. -100.  100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [ 100.    1.    1.    1.    1.    1.    1.    1.  100.]\n"," [-100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [-100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[ 100.  100. -100. -100.  100.  100.  100. -100.  100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [-100.    1.    1.    1.    1.    1.    1.    1. -100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [-100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[-100.  100.  100. -100.  100.  100. -100.  100. -100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [ 100.    1.    1.    1.    1.    1.    1.    1.  100.]\n"," [-100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [-100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[ 100. -100.  100.  100. -100. -100.  100.  100.  100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [ 100.    1.    1.    1.    1.    1.    1.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[ 100.  100.  100. -100.  100.  100.  100. -100.  100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [ 100.    1.    1.    1.    1.    1.    1.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [-100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [-100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[-100.  100.  100. -100.  100. -100.  100.  100. -100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [ 100.    1.    1.    1.    1.    1.    1.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[ 100. -100.  100.  100. -100. -100. -100.  100.  100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [ 100.    1.    1.    1.    1.    1.    1.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [-100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[ 100.  100.  100.  100.  100.  100.  100.  100.  100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [ 100.    1.    1.    1.    1.    1.    1.    1. -100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[ 100.  100. -100. -100.  100. -100. -100.  100.  100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [-100.    1.    1.    1.    1.    1.    1.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [-100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[ 100.  100. -100.  100.  100. -100.  100.  100. -100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [ 100.    1.    1.    1.    1.    1.    1.    1.  100.]\n"," [-100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[-100.  100. -100.  100.  100.  100.  100.  100.  100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [ 100.    1.    1.    1.    1.    1.    1.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[ 100.  100. -100. -100.  100.  100.  100.  100.  100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [ 100.    1.    1.    1.    1.    1.    1.    1. -100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[ 100.  100.  100.  100.  100.  100. -100. -100. -100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [-100.    1.    1.    1.    1.    1.    1.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [-100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[ 100.  100.  100.  100.  100. -100.  100. -100.  100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [-100.    1.    1.    1.    1.    1.    1.    1. -100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [-100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[ 100.  100. -100.  100.  100. -100.  100.  100.  100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [-100.    1.    1.    1.    1.    1.    1.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[-100.  100. -100.  100.  100.  100.  100.  100. -100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [ 100.    1.    1.    1.    1.    1.    1.    1.  100.]\n"," [-100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[-100. -100.  100.  100.  100.  100.  100. -100. -100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [-100.    1.    1.    1.    1.    1.    1.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[ 100. -100. -100. -100.  100.  100.  100. -100.  100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [ 100.    1.    1.    1.    1.    1.    1.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[-100.  100. -100.  100. -100. -100.  100. -100.  100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [ 100.    1.    1.    1.    1.    1.    1.    1.  100.]\n"," [-100.    1.    0.    1.    0.    1.    0.    1. -100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[ 100. -100.  100.  100.  100.  100.  100.  100. -100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [-100.    1.    1.    1.    1.    1.    1.    1. -100.]\n"," [-100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [-100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n","[[ 100.  100. -100.  100. -100.  100. -100.  100.  100.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [ 100.    1.    1.    1.    1.    1.    1.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [ 100.    1.    0.    1.    0.    1.    0.    1.  100.]\n"," [   1.    1.    0.    1.    0.    1.    0.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   1.    1.    1.    1.    1.    1.    1.    1.    1.]\n"," [   0.    0.    0.    0.   -5.    0.    0.    0.    0.]]\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/content/drive/Othercomputers/MacBook_Air/path-finding-rl/data\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#train 모드 실행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/drive/Othercomputers/MacBook_Air/path-finding-rl/data\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# OB, 장애물, 최종 목표 도달시 종료\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 인풋 정보에 경로 길이 추가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcum_reward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal_ob_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0ms_prime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/Othercomputers/MacBook_Air/path-finding-rl/data\u001b[0m in \u001b[0;36msample_action\u001b[0;34m(self, obs, epsilon)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mcoin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcoin\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/Othercomputers/MacBook_Air/path-finding-rl/data\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x2 and 94x512)"]}]},{"cell_type":"code","source":["## test 메서드 추가 #################################################################################\n","def test():\n","    # model = torch.load('/content/drive/MyDrive/aiffelthon/data/model.pt')\n","    model = torch.load('/content/drive/Othercomputers/MacBook_Air/path-finding-rl/data/model.pt')\n","    train_mode = False  # False\n","    tz = pytz.timezone('Asia/Seoul')\n","    env = Simulator()\n","    q = Qnet()\n","    s_before = None\n","    print_interval = 1  # \n","    score = 0.0\n","\n","    for n_epi in range(len(env.files)): # range()의 인수로 len(env.files) 사용하면 됨 (=1225)\n","        env.reset(n_epi)\n","        print('env.local_target:', env.local_target)\n","        ############################################\n","        ## 인풋 정보(obs)에 경로 길이 추가\n","        # path_length = len(env.local_target)\n","        # print('path_length', path_length)\n","        # s_before = env.curloc\n","        # s_before.append(path_length)\n","        ############################################        \n","        s = np.array(s_before)\n","        done = False\n","\n","        while not done:  # OB, 장애물, 최종 목표 도달시 종료\n","            #####################################################################################\n","            # (option) test 경우 추가: 출발점에서는 무조건 위로 올라간다 (action=0)\n","            x, y, _ = s\n","            if [x,y] == [9,4]:\n","                a = 0\n","            else:\n","                a = q.test_action(torch.from_numpy(s).float())  # test_action 수행\n","            #####################################################################################\n","            #a = q.test_action(torch.from_numpy(s).float())  # test_action 수행\n","            #####################################################################################\n","            obs, r, cum_reward, done, goal_ob_reward = env.step(a)\n","            s_prime = np.array(env.curloc)\n","            s = s_prime\n","            score += r\n","\n","        # print_interval (=1) 마다 현황 디스플레이하고 q_target 업데이트 및 score 초기화\n","        if n_epi % print_interval == 0 and n_epi != 0:\n","            cur_time = datetime.now(tz)\n","            simple_cur_time = cur_time.strftime(\"%H:%M:%S\")\n","            print('▶ Episode #', n_epi, end=' → ')\n","            print('Score =', score, end='...')\n","            print('경로 길이:', len(env.actions), end=', ')\n","            if goal_ob_reward == 'finish':\n","                print('성공 여부: ', goal_ob_reward)\n","            else:\n","                print('성공 여부 : 실패', goal_ob_reward)\n","        \n","        score = 0.0\n","        print('→ pred_path:', env.actions)\n","\n","    # 모든 에피소드 종료 후 결과 디스플레이\n","    # 코드 추가할 것!!!"],"metadata":{"id":"utOrw1pzrHwu","executionInfo":{"status":"aborted","timestamp":1653374503616,"user_tz":-540,"elapsed":12,"user":{"displayName":"노현호","userId":"15410213599666758892"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test 모드 실행\n","train_mode = False\n","test()"],"metadata":{"id":"F2ehRlhBPRcd","executionInfo":{"status":"aborted","timestamp":1653374503616,"user_tz":-540,"elapsed":12,"user":{"displayName":"노현호","userId":"15410213599666758892"}}},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.13"},"colab":{"name":"as_DQN_obs3_220524.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}
{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"lRpfPDrdk9wB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654238026647,"user_tz":-540,"elapsed":32427,"user":{"displayName":"노현호","userId":"15410213599666758892"}},"outputId":"64ee7d0b-5e38-4027-af67-572493a5813d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","__file__ = '/content/drive/Othercomputers/MacBook_Air/path-finding-rl/data'"]},{"cell_type":"markdown","metadata":{"id":"UHFqTLgjMNbJ"},"source":["## Env\n","- 경로 이동 제한 사항 반영: del apply_action() 수정\n","- def grid_box(self):  # 그리드 박스 초기화 용도로 정의\n","- 그리드값 변경\n","  - target_gridval (목표물)  = 10, 9, 8, ...\n","  - curloc_gridval (현 위치) = 1\n","  - default_gridval (기본)   = 0\n","  - rack_gridval (선반)      = -1\n","  - obs_gridval (장애물)     = -10\n","- 종료 조건\n","  - **그리드월드 밖**으로 나가는 경우 **종료하지 않음**\n","  - **장애물**에 부딪히는 경우 **종료**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tQRnyv3UlBcu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654240486837,"user_tz":-540,"elapsed":1443,"user":{"displayName":"노현호","userId":"15410213599666758892"}},"outputId":"78c7a5c4-32ba-460c-ebc2-d85b68eba8a3"},"outputs":[{"output_type":"stream","name":"stdout","text":["reward: -1 -10 10\n"]}],"source":["from string import ascii_uppercase\n","import numpy as np\n","import pandas as pd\n","import os\n","import random\n","from datetime import datetime\n","import pytz\n","import matplotlib.pyplot as plt\n","\n","###################################\n","# 보상 Reward\n","move_reward = -1  # 0.1\n","obs_reward = -10  # 0.1\n","goal_reward = 10  # 10\n","###################################\n","# 그리드값\n","# target_gridval = 10, 9, 8... # 목표물: 10, 9, 8, ...\n","curloc_gridval  = 1            # 현 위치: 1\n","default_gridval = 0            # 기본: 0\n","rack_gridval    = -1           # 선반: -1\n","obs_gridval     = -10          # 장애물: -10\n","###################################\n","# train / test 모드 지정\n","train_mode = True\n","###################################\n","print('reward:' , move_reward, obs_reward, goal_reward)\n","\n","#__file__ = '/home/ogangza/heung_path_finding/path-finding-rl/data'\n","\n","local_path = os.path.abspath(os.path.join(os.path.dirname(__file__)))\n","\n","class Simulator:\n","    def __init__(self):\n","        # Load train or test data\n","        # if train_mode:  # 훈련 데이타 읽기\n","        #     self.files = pd.read_csv(os.path.join(local_path, \"data/factory_order_train.csv\"))\n","        #     print('data/factory_order_train.csv used')\n","        # else:           # 테스트 데이터 읽기\n","        #     self.files = pd.read_csv(os.path.join(local_path, \"data/factory_order_test.csv\"))\n","        #     print('data/factory_order_test.csv used')\n","        ##########################################################################################\n","        self.height = 10  # 그리드 높이\n","        self.width = 9    #  그리드 너비\n","        self.inds = list(ascii_uppercase)[:17]  # A ~ Q alphabet list\n","\n","    def set_box(self):  # 선반 위치, 목적지 그리드값 설정. 목적지 리스트 생성\n","        box_data = pd.read_csv(os.path.join(local_path, \"data/box.csv\"))\n","        for box in box_data.itertuples(index = True, name ='Pandas'):  # 선반 위치: 그리드값 = rack_gridval\n","            self.grid[getattr(box, \"row\")][getattr(box, \"col\")] = rack_gridval\n","        order_item = list(set(self.inds) & set(self.items))\n","        order_csv = box_data[box_data['item'].isin(order_item)]\n","        for i, order_box in enumerate(order_csv.itertuples(index = True, name ='Pandas')):  # 목적지: 그리드값 = target_gridval\n","            self.grid[getattr(order_box, \"row\")][getattr(order_box, \"col\")] = 10 - i\n","            self.local_target.append([getattr(order_box, \"row\"), getattr(order_box, \"col\")])  # 목적지 리스트 생성: local_target\n","        # self.local_target.sort() # 불필요. 인풋 데이터 A, B, C순 정렬되어 있음... 정렬 필요시 코드 바꾸어야 함\n","        self.local_target.append([9,4]) # 목적지 리스트에 최종 목적지(9,4) 추가\n","        self.local_target_original = self.local_target.copy()  # gif 생성을 위해 추가.  에피소드의 경로 저장\n","        self.target_length = len(self.local_target_original)  # 목적지 그리드값 10, 9, 8, ... 지정 위해 추가\n","        self.grid[9,4] = 10 + 1 - self.target_length  # 최종 목적지 [9,4] 그리드값 지정 위해 추가\n","\n","    def set_obstacle(self):  # 장애물 위치 그리드값 설정 = obs_gridval\n","        obstacles_data = pd.read_csv(os.path.join(local_path, \"data/obstacles.csv\"))\n","        for obstacle in obstacles_data.itertuples(index = True, name ='Pandas'):\n","            self.grid[getattr(obstacle, \"row\")][getattr(obstacle, \"col\")] = obs_gridval\n","\n","    def grid_box(self):  # 그리드 박스 초기화 용도로 정의: 선반, 목적지, 장애물 그리드값 초기화\n","        box_data = pd.read_csv(os.path.join(local_path, \"data/box.csv\"))\n","        for box in box_data.itertuples(index = True, name ='Pandas'):  # 선반 위치: 그리드값 = rack_gridval\n","            self.grid[getattr(box, \"row\")][getattr(box, \"col\")] = rack_gridval\n","        order_item = list(set(self.inds) & set(self.items))\n","        order_csv = box_data[box_data['item'].isin(order_item)]\n","        for i, order_box in enumerate(order_csv.itertuples(index = True, name ='Pandas')):  # 목적지: 그리드값 = target_gridval\n","            self.grid[getattr(order_box, \"row\")][getattr(order_box, \"col\")] = 10 - i\n","        self.grid[9,4] = 10 + 1 - self.target_length  # 최종 목적지 [9,4] 그리드값 지정 위해 추가\n","        self.set_obstacle()  # 장애물 위치 그리드값 설정 = obs_gridval\n","        \n","    def reset(self, epi):  # 에피소드 시작시 12개 값 초기화\n","        self.epi = epi                                            #1. 에피소드 번호 받기\n","        # self.items = list(self.files.iloc[self.epi])[0]           #2. 에피소드의 목적지 받기: [ 'H', 'L', 'M']\n","        #####################################################################################\n","        coin = random.randint(0,16)\n","        self.items = [chr(coin+65)]  # A~Q 까지 1개 랜덤으로 받아서 items에 1개 넣어주기, 반복 횟수는 main의 epochs 조절하기\n","        ####################################################################################\n","        self.cumulative_reward = 0                                #3. 누적 보상값 = 0\n","        self.terminal_location = None                             #4. 최초 목적지\n","        self.local_target = []                                    #5. 목적지 리스트 초기화\n","        self.actions = []                                         #6. 지나온 경로 리스트 초기화\n","        self.grid = np.zeros((self.height, self.width), dtype=\"float16\")  #7. 그리드월드 전체 그리드값(default_gridval) 초기화\n","        self.set_box()                                            #8. 선반 위치, 목적지 그리드값 설정. 목적지 리스트 생성\n","        self.set_obstacle()                                       #9. 장애물 그리드값 설정\n","        ######################\n","        # print('최초 그리드맵:')  # 그리드맵 확인\n","        # print(self.grid.reshape(10,9))\n","        ######################\n","        self.curloc = [9, 4]                                      #10. 현재 위치를 출발점으로 세팅\n","        self.grid[int(self.curloc[0])][int(self.curloc[1])] = curloc_gridval  #11. 현재 위치(출발점) 그리드값 세팅\n","        self.done = False                                         #12. 경로 찾기 종료 여부 = False\n","        self.goal_ob_reward = False                      # (추가) #13. 최종 목적지 도착 여부 = False\n","        ######################\n","        # print('현 위치 추가:')   # 그리드맵 확인\n","        # print(self.grid.reshape(10,9))\n","        ######################\n","        self.move_track = [[9,4]]                                        #14. 이동하는 경로를 저장하는 변수, 에피소드 시작시 에이전트가 [9,4]에 있으므로 [[9,4]]로 초기화\n","        self.isReset =  False                                       #15. 처음으로 terminal_location == 9,4가 되면, moveTrack을 초기화해주기 위해 필요한 변수 isFinal -> isReset 로 변경(처음으로 불러졌냐 안불러졌냐)\n","        self.prior_distance = 9999                                  #16. 이전 time step의 거리와 현재 거리를 비교하기 위해서 필요한 변수\n","        ######################\n","        return self.grid\n","\n","    def apply_action(self, action, cur_x, cur_y):  # action에 따른 새 좌표값 반환\n","        new_x = cur_x\n","        new_y = cur_y\n","        if action == 0:          # up\n","            #new_x = cur_x - 1\n","            new_x = self.move_up(cur_x, cur_y, new_x, new_y)\n","        elif action == 1:        # down\n","            #new_x = cur_x + 1\n","            new_x = self.move_down(cur_x, cur_y, new_x, new_y)\n","        elif action == 2:        # left\n","            #new_y = cur_y - 1\n","            new_y = self.move_left(cur_x, cur_y, new_x, new_y)\n","        else:                    # right\n","            #new_y = cur_y + 1\n","            new_y = self.move_right(cur_x, cur_y, new_x, new_y)\n","        return int(new_x), int(new_y)\n","    \n","    # >>> 현재 위치에서 이동이 불가한 위치 추가 (시작) <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","    def move_up(self, cur_x, cur_y, new_x, new_y):  # action == 0:\n","        if cur_x in [6,5,4,3,2] and cur_y in [0,8]:\n","            pass\n","        else:\n","            new_x = cur_x - 1\n","        return new_x\n","    def move_down(self, cur_x, cur_y, new_x, new_y): # action == 1:\n","        if cur_x in [1,2,3,4,5] and cur_y in [0,8]:\n","            pass\n","        else:\n","            new_x = cur_x + 1\n","        return new_x\n","    def move_left(self, cur_x, cur_y, new_x, new_y): # left elif action == 2:\n","        if cur_y in [1,2,3,4,5,6,7,8] and cur_x == 0:\n","            pass\n","        else:\n","            new_y = cur_y - 1\n","        return new_y\n","    def move_right(self, cur_x, cur_y, new_x, new_y): # right else: action == 3:\n","        if cur_y in [0,1,2,3,4,5,6,7] and cur_x == 0:\n","            pass\n","        else:\n","            new_y = cur_y + 1\n","        return new_y\n","    # >>> 추가 (끝) <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","\n","    def get_reward(self, new_x, new_y, out_of_boundary):  # action에 의해 이동시 얻는 보상\n","        if any(out_of_boundary):                                        # 바깥으로 나가는 경우\n","            reward = obs_reward\n","        else:\n","            if self.grid[new_x][new_y] == obs_gridval :     # 장애물에 부딪히는 경우\n","                reward = obs_reward\n","                self.grid[new_x][new_y] = curloc_gridval   # 현 위치(장애물)에서 종료되었음을 표시. 원래는 장애물이었음                \n","            elif self.grid[new_x][new_y] == rack_gridval:   # 선반에 부딪히는 경우\n","                reward = obs_reward\n","                new_x = self.curloc[0]  # 선반인 경우 못들어가고, 현재 위치로 유지\n","                new_y = self.curloc[1]  # 선반인 경우 못들어가고, 현재 위치로 유지\n","            elif new_x == self.terminal_location[0] and new_y == self.terminal_location[1]:  # 현재 목적지에 도달한 경우\n","                reward = goal_reward\n","            # 그냥 움직이는 경우 \n","            else: \n","                cur_distance = self.get_distance()\n","                if self.prior_distance > cur_distance :                         # 이전의 거리 > 현재의 거리 = 현재 아이템에 더 가깝다 => + 보상얻기\n","                    reward = self.get_positive_distance_reward(cur_distance)\n","                    # print('posi', reward)\n","                else:                                                           # 이전의 거리 < 현재의 거리 = 현재 아이템에서 멀어졌다 => - 보상얻기\n","                    reward = self.get_negative_distance_reward(cur_distance)\n","                    # print('nega', reward)\n","                self.prior_distance = cur_distance      \n","\n","                if [new_x, new_y] not in self.move_track:                           # 이동한 곳이 처음온 곳이면 move_track에 추가\n","                    self.move_track.append([new_x, new_y])\n","                else:                                                           # 이동한 곳이 이미 왔던 곳이면 기존 보상에서 -1\n","                    reward = reward -1\n","        return reward\n","\n","    def step(self, action):  # action에 따른 이동 실행\n","        self.terminal_location = self.local_target[0]           # 목적지 리스트의 첫 번째 요소를 목적지로 설정\n","        cur_x, cur_y = self.curloc                              # 현재 위치 기억\n","        new_x, new_y = self.apply_action(action, cur_x, cur_y)  # 다음 위치 받기\n","        self.actions.append((cur_x, cur_y))                     # 현재 위치(지나온 위치)를 경로 리스트에 추가\n","        self.goal_ob_reward = False                             # 최종 목적지에 도착한 경우에 True. self.reset()에서 초기화\n","        out_of_boundary = [new_x < 0, new_x >= self.height, new_y < 0, new_y >= self.width]  # 그리드월드 밖으로 나갔는가? OB = True\n","\n","        if any(out_of_boundary):  #1. 바깥으로 나가는 경우, 빈 선반에 부딪치는 경우 종료하지 않음\n","            #print('OB')\n","            new_x = cur_x  # 종료 처리할 경우 코멘트 처리\n","            new_y = cur_y  # 종료 처리할 경우 코멘트 처리\n","            ######################################################종료 처리할 경우 실행\n","            #self.done = True                             # while loop 종료\n","            #self.grid_box()                              # 선반, 목적지, 장애물 그리드값 초기화\n","            #self.actions.append((new_x,new_y))           # 경로 리스트에 최종 위치 추가. (주의) 좌표값이 그리드월드를 벗어나는 값 발생!\n","            ######################################################\n","        else:\n","            if self.grid[new_x][new_y] == obs_gridval:  #2. 장애물에 부딪히는 경우 종료\n","                # print('장애물')\n","                # new_x = cur_x  # 종료 처리할 경우 코멘트 처리\n","                # new_y = cur_y  # 종료 처리할 경우 코멘트 처리\n","                ###################################################종료 처리할 경우 실행\n","                self.done = True                           # while loop 종료\n","                self.grid[cur_x][cur_y] = default_gridval  # 현 위치의 그리드값을 기본값으로 초기화\n","                self.grid_box()                            # 선반, 목적지, 장애물 그리드값 초기화\n","                self.actions.append((new_x,new_y))         # 경로 리스트에 최종 위치 추가\n","                ###################################################\n","            elif self.grid[new_x][new_y] == rack_gridval:\n","                pass\n","            elif new_x == self.terminal_location[0] and new_y == self.terminal_location[1]:  #3. 현재 목적지에 도착한 경우 다음 목적지 설정\n","                #print('목적지 도착')\n","                if [new_x, new_y] == [9, 4]:            #3-1. 최종 목적지에 도착한 경우 종료\n","                    self.done = True                       # while loop 종료\n","                    self.goal_ob_reward = True             # True = 1 (OB, 장애물 종료 처리 할 경우 self.done=True가 많아지므로 이때 사용)\n","                    self.actions.append((new_x,new_y))     # 경로 리스트에 최종 위치 추가\n","\n","                self.local_target.remove(self.local_target[0])  # 다음 목적지 설정. 최종 목적지에 도착한 경우에는 마지막 요소인 [9,4]를  제거\n","                self.grid[cur_x][cur_y] = default_gridval  # 현 위치의 그리드값을 기본값으로 초기화\n","                self.grid_box()                            # 선반, 목적지, 장애물 그리드값 초기화\n","                self.grid[new_x][new_y] = curloc_gridval   # 현 위치(목적지)에서 종료되었음을 표시. 원래는 목적지이었음\n","                self.curloc = [new_x, new_y]               # 새로 도착한 위치를 현재 위치로 변경\n","            \n","            else:                                       #4. 그냥 움직이는 경우\n","                #print('이동')\n","                self.grid[cur_x][cur_y] = default_gridval  # 현 위치의 그리드값을 기본값으로 초기화\n","                self.grid_box()                            # 선반, 목적지, 장애물 그리드값 초기화\n","                self.grid[new_x][new_y] = curloc_gridval   # 현 위치에서 종료되었음을 표시\n","                self.curloc = [new_x,new_y]\n","\n","        ############################### 보상받는 처리 시작 ###############################\n","        # 마지막 위치에서 위로 올라가는 행동을 한다면 - 보상받음 태양\n","        if self.terminal_location == [9, 4]:\n","            if not self.isReset:                                    # 처음으로 terminal_location == [9,4]가 되었다면,,\n","                self.move_track = []                                # 아이템을 찾으러 돌아다니는 경로 초기화\n","                self.isReset = True                                 # move_track이 초기화 되었으니 isReset = True\n","            reward = self.get_reward(new_x, new_y, out_of_boundary)\n","            if action == 0:\n","                reward = obs_reward                                # 처음위치로 갈 때 위로 올라가는거 금지\n","        else : \n","            reward = self.get_reward(new_x, new_y, out_of_boundary)\n","        ############################### 보상받는 처리 끝 ###############################   \n","\n","        self.cumulative_reward += reward\n","        return self.grid, reward, self.cumulative_reward, self.done\n","\n","    # >>> distance를 입력으로 받아 + 보상을 계산하는 메소드 (시작) <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< \n","    def get_positive_distance_reward(self, distance):\n","        positive_reward = (20 - distance) / 200     # 0.095 ~ 0.001\n","        return positive_reward\n","    # >>> 추가 (끝) <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","\n","    # >>> distance를 입력으로 받아 - 보상을 계산하는 메소드 (시작) <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","    def get_negative_distance_reward(self, distance):\n","        negative_reward = -(distance / 200)\n","        return negative_reward\n","    # >>> 추가 (끝) <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<    \n","\n","    # >>> 현재 위치에서 타겟까지의 거리를 구하는 메소드 (시작) <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","    def get_distance(self): \n","        cur_x, cur_y, target_x, target_y = self.get_current_state()\n","        \n","        distance = (abs(cur_x-target_x) + abs(cur_y-target_y))\n","        # print(cur_x, cur_y, target_x, target_y)\n","        # print('distance : ', distance)\n","        return distance\n","    # >>> 추가 (끝) <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<    \n","\n","    # >>> 현재 상황에 대한 정보를 구하는 메소드 (시작) <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","    def get_current_state(self):\n","        # if len(self.local_target) != 0:\n","        #     state = (self.curloc[0], self.curloc[1], self.local_target[0][0], self.local_target[0][1])\n","        # else :\n","        state = (self.curloc[0], self.curloc[1], self.terminal_location[0], self.terminal_location[1])\n","        return np.array(state) #(cur_x, cur_y, tar_x, tar_y)\n","    # >>> 추가 (끝) <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<        \n"]},{"cell_type":"markdown","metadata":{"id":"JfJoLw7BM2xw"},"source":["## Agent\n","- def test_action(self, obs): 추가"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uwgy-OBbk1b4"},"outputs":[],"source":["import collections\n","import random\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","class ReplayBuffer():  # 리플레이 버퍼: 경험 저장소\n","    def __init__(self):\n","        self.buffer = collections.deque(maxlen=buffer_limit)\n","    \n","    def put(self, transition):  # 리플레이 버퍼(메모리)를 경험(transition)으로 채우기\n","        self.buffer.append(transition)\n","    \n","    def sample(self, n):  # memory.sample(batch_size)로 사용\n","        mini_batch = random.sample(self.buffer, n)  # 미니배치 샘플링\n","        '''\n","        s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [], [], [], [], []\n","        for transition in mini_batch:  # 경험의 각 요소들을 각각의 미니배치로 구성\n","            s, a, r, s_prime, done_mask = transition\n","            s_lst.append(s)\n","            a_lst.append([a])\n","            r_lst.append([r])\n","            s_prime_lst.append(s_prime)\n","            done_mask_lst.append([done_mask])\n","        return torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst), \\\n","               torch.tensor(r_lst), torch.tensor(s_prime_lst, dtype=torch.float), \\\n","               torch.tensor(done_mask_lst)\n","        '''\n","        state1_batch = torch.cat([s1 for (s1,a,r,s2,d) in mini_batch])\n","        action_batch = torch.Tensor([a for (s1,a,r,s2,d) in mini_batch])\n","        reward_batch = torch.Tensor([r for (s1,a,r,s2,d) in mini_batch])\n","        state2_batch = torch.cat([s2 for (s1,a,r,s2,d) in mini_batch])\n","        done_batch = torch.Tensor([d for (s1,a,r,s2,d) in mini_batch])\n","\n","        return state1_batch, action_batch, reward_batch, state2_batch, done_batch\n","    \n","    def size(self):  # 메모리 크기\n","        return len(self.buffer)\n","\n","class Qnet(nn.Module):\n","    '''##### Linear 모델 #####\n","    def __init__(self):\n","        super(Qnet, self).__init__()\n","\n","        in_size = 90  # input 크기\n","        L1 = 250\n","        L2 = 150\n","        out_size  = 4\n","\n","        self.fc1 = nn.Linear(in_size, L1)\n","        self.fc2 = nn.Linear(L1, L2)\n","        self.fc3 = nn.Linear(L2, out_size)\n","\n","    def forward(self, x):\n","        x = x.to(device)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","    '''\n","    ##### Convolution 모델 #####\n","    def __init__(self):\n","        super(Qnet, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(4, 32, 3, 1) #### 1이었던 부분을 4로 변경\n","        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n","        self.conv3 = nn.Conv2d(64, 64, 3, 1)\n","        self.fc1 = nn.Linear(768, 512)\n","        self.fc2 = nn.Linear(512, 4)\n","\n","    def forward(self, x):\n","        x = x.to(device)               # (N, 4, 10, 9)\n","        x = F.relu(self.conv1(x))      # (N, 32, 8, 7)\n","        x = F.relu(self.conv2(x))      # (N, 64, 6, 5)\n","        x = F.relu(self.conv3(x))\n","        x = torch.flatten(x, 1)        # (N, 64, 30)\n","        x = F.relu(self.fc1(x))        # (N, 1920) -> (N, 128)\n","        x = self.fc2(x)                # (N, 128)  -> (N, 4)\n","        return x\n","\n","    def sample_action(self, obs, epsilon):  # Qnet()을 실행해서 모든 action에 대한 Qval을 구한 후 action 선택\n","        out = self.forward(obs)  # out = Q_value, obs = state = 그리드맵\n","        coin = random.random()  # e-greedy로 action 선택\n","        if coin < epsilon:\n","            return random.randint(0,3)\n","        else : \n","            return out.argmax().item()\n","    \n","    def test_action(self, obs):  # Qnet()을 실행해서 모든 action에 대한 Qvalue을 구한 후 action 선택\n","        out = self.forward(obs)  # out = Q_value, obs = state = 그리드맵\n","        return out.argmax().item()\n","\n","def train(q, q_target, memory, optimizer):  # 메모리에 경험이 미니배치 크기 이상 쌓이면 미니배치 훈련 시작\n","    '''\n","    for i in range(10):\n","        s, a, r, cr, s_prime, done_mask, gr = memory.sample(batch_size)\n","        q_out = q(s)\n","        q_a = q_out.gather(1,a.to(device))\n","        \n","        max_q_prime = q_target(s_prime).max(1)[0].unsqueeze(1)\n","        target = r.to(device) + gamma * max_q_prime * done_mask.to(device)\n","        \n","        loss = F.smooth_l1_loss(q_a, target)\n","        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","    '''\n","    s,a,r,s_prime,done_mask = memory.sample(batch_size)  # 메모리에서 미니배치를 뽑기: batch_size=1600\n","    Q1 = q(s)  # Qnet의 Qvalue\n","    X = Q1.gather(dim=1,index=a.long().unsqueeze(dim=1).to(device)).squeeze() # Qnet의 Qvalue 변환\n","    with torch.no_grad():\n","        Q2 = q_target(s_prime)\n","    Y = r.to(device) + gamma * done_mask.to(device) * torch.max(Q2,dim=1)[0]\n","    loss = F.smooth_l1_loss(X, Y.detach())\n","    #loss = nn.MSELoss(X.to(torch.float32), Y.detach().to(torch.float32))  # 손실함수 변경. target.detach()로 변경\n","    optimizer.zero_grad()  # gradient값 초기화\n","    loss.backward()  # 자동미분\n","    optimizer.step()  # gradient 업데이트\n","    return loss.item()"]},{"cell_type":"markdown","metadata":{"id":"wK35ngIkNM6I"},"source":["## Main: DQN...\n","  - GPU를 사용할 경우 구현\n","  - 학습한 모델 불러올 수 있는 코드 추가\n","    - '#' 제거하고 실행시키면 됨"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j9qFCqbbjf3F","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"e06e607a-3fed-4848-ad57-1b7dc681e842","executionInfo":{"status":"ok","timestamp":1654261780994,"user_tz":-540,"elapsed":21117145,"user":{"displayName":"노현호","userId":"15410213599666758892"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor in cuda\n","종료: done = True ... j = 2500  move = 5\n","종료: done = True ... j = 4100  move = 47\n","종료: done = True ... j = 4200  move = 23\n","종료: done = True ... j = 7000  move = 3\n","종료: done = True ... j = 9800  move = 3\n","종료: done = True ... j = 10100  move = 15\n","종료: done = True ... j = 11100  move = 9\n","종료: done = True ... j = 12100  move = 71\n","종료: done = True ... j = 12400  move = 5\n","종료: done = True ... j = 12700  move = 9\n","종료: done = True ... j = 13100  move = 11\n","종료: done = True ... j = 15400  move = 57\n","종료: done = True ... j = 17100  move = 9\n","종료: done = True ... j = 17600  move = 7\n","종료: done = True ... j = 17800  move = 5\n","종료: done = True ... j = 18400  move = 7\n","종료: done = True ... j = 20700  move = 29\n","종료: done = True ... j = 21000  move = 20\n","종료: done = True ... j = 21200  move = 13\n","종료: done = True ... j = 23300  move = 11\n","종료: done = True ... j = 26000  move = 5\n","종료: done = True ... j = 26600  move = 14\n","종료: done = True ... j = 27000  move = 19\n","종료: done = True ... j = 27700  move = 7\n","종료: done = True ... j = 30500  move = 3\n","종료: done = True ... j = 30600  move = 9\n","종료: done = True ... j = 31100  move = 9\n","종료: done = True ... j = 31300  move = 20\n","종료: done = True ... j = 31500  move = 33\n","종료: done = True ... j = 31600  move = 7\n","종료: done = True ... j = 31900  move = 33\n","종료: done = True ... j = 33200  move = 18\n","종료: done = True ... j = 33800  move = 9\n","종료: done = True ... j = 34000  move = 9\n","종료: done = True ... j = 34300  move = 5\n","종료: done = True ... j = 34900  move = 11\n","종료: done = True ... j = 36000  move = 4\n","종료: done = True ... j = 36700  move = 47\n","종료: done = True ... j = 38500  move = 25\n","종료: done = True ... j = 39100  move = 11\n","종료: done = True ... j = 39600  move = 29\n","종료: done = True ... j = 40500  move = 45\n","종료: done = True ... j = 45000  move = 19\n","종료: done = True ... j = 45400  move = 3\n","종료: done = True ... j = 48100  move = 7\n","종료: done = True ... j = 50700  move = 9\n","종료: done = True ... j = 50800  move = 3\n","종료: done = True ... j = 54500  move = 24\n","epiode #: 3995 loss: 0.21329829096794128 j: 55000\n","epiode #: 4216 loss: 0.07173698395490646 j: 60000\n","종료: done = True ... j = 61500  move = 11\n","종료: done = True ... j = 63600  move = 15\n","epiode #: 4479 loss: 0.018118150532245636 j: 65000\n","종료: done = True ... j = 65100  move = 9\n","종료: done = True ... j = 68000  move = 5\n","종료: done = True ... j = 68700  move = 8\n","종료: done = True ... j = 69500  move = 7\n","종료: done = True ... j = 69700  move = 9\n","epiode #: 5140 loss: 0.02141583152115345 j: 70000\n","종료: done = True ... j = 71300  move = 5\n","종료: done = True ... j = 71400  move = 5\n","종료: done = True ... j = 71800  move = 9\n","종료: done = True ... j = 73400  move = 5\n","epiode #: 5701 loss: 0.030484769493341446 j: 75000\n","종료: done = True ... j = 75400  move = 5\n","종료: done = True ... j = 77400  move = 8\n","종료: done = True ... j = 77800  move = 14\n","epiode #: 6166 loss: 0.018510259687900543 j: 80000\n","종료: done = True ... j = 80000  move = 15\n","종료: done = True ... j = 82400  move = 25\n","종료: done = True ... j = 83600  move = 16\n","종료: done = True ... j = 84100  move = 9\n","종료: done = True ... j = 84400  move = 6\n","epiode #: 6605 loss: 0.012598746456205845 j: 85000\n","종료: done = True ... j = 85900  move = 3\n","종료: done = True ... j = 86200  move = 23\n","종료: done = True ... j = 87200  move = 9\n","종료: done = True ... j = 87500  move = 14\n","종료: done = True ... j = 87600  move = 8\n","종료: done = True ... j = 88700  move = 20\n","종료: done = True ... j = 89600  move = 11\n","epiode #: 7060 loss: 0.014661205932497978 j: 90000\n","종료: done = True ... j = 93400  move = 17\n","epiode #: 7489 loss: 0.0167169738560915 j: 95000\n","종료: done = True ... j = 95100  move = 20\n","종료: done = True ... j = 95800  move = 23\n","종료: done = True ... j = 96700  move = 3\n","종료: done = True ... j = 97100  move = 14\n","종료: done = True ... j = 97300  move = 11\n","종료: done = True ... j = 98600  move = 27\n","epiode #: 7895 loss: 0.01207907684147358 j: 100000\n","종료: done = True ... j = 100500  move = 21\n","종료: done = True ... j = 100800  move = 10\n","종료: done = True ... j = 101700  move = 7\n","종료: done = True ... j = 104800  move = 9\n","epiode #: 8263 loss: 0.020392494276165962 j: 105000\n","종료: done = True ... j = 105400  move = 7\n","종료: done = True ... j = 105700  move = 10\n","종료: done = True ... j = 109900  move = 26\n","epiode #: 8627 loss: 0.02210363559424877 j: 110000\n","종료: done = True ... j = 110400  move = 13\n","종료: done = True ... j = 112300  move = 15\n","종료: done = True ... j = 112400  move = 11\n","epiode #: 8927 loss: 0.05899433791637421 j: 115000\n","종료: done = True ... j = 115100  move = 15\n","종료: done = True ... j = 115200  move = 39\n","종료: done = True ... j = 115400  move = 19\n","종료: done = True ... j = 117200  move = 31\n","epiode #: 9188 loss: 0.04781027138233185 j: 120000\n","종료: done = True ... j = 120700  move = 27\n","종료: done = True ... j = 123300  move = 46\n","epiode #: 9422 loss: 0.07101315259933472 j: 125000\n","종료: done = True ... j = 127000  move = 7\n","epiode #: 9664 loss: 0.15159724652767181 j: 130000\n","['P'] 종료: env.goal_ob_reward = True ... j = 130373  move = 57 @ 에피소드 # 9684\n","9684번째 에피소드까지 총 1번 finish 했습니다.\n","종료: done = True ... j = 132100  move = 36\n","['O'] 종료: env.goal_ob_reward = True ... j = 132178  move = 30 @ 에피소드 # 9787\n","9787번째 에피소드까지 총 2번 finish 했습니다.\n","종료: done = True ... j = 134500  move = 64\n","종료: done = True ... j = 134700  move = 5\n","epiode #: 9938 loss: 0.18802836537361145 j: 135000\n","종료: done = True ... j = 135900  move = 10\n","▶ 모델 저장됨!!! @ 에피소드 10000\n","종료: done = True ... j = 136800  move = 21\n","['N'] 종료: env.goal_ob_reward = True ... j = 138819  move = 60 @ 에피소드 # 10168\n","10168번째 에피소드까지 총 3번 finish 했습니다.\n","종료: done = True ... j = 139400  move = 18\n","epiode #: 10244 loss: 0.06333999335765839 j: 140000\n","['D'] 종료: env.goal_ob_reward = True ... j = 140392  move = 23 @ 에피소드 # 10258\n","10258번째 에피소드까지 총 4번 finish 했습니다.\n","종료: done = True ... j = 143600  move = 51\n","epiode #: 10502 loss: 0.22674942016601562 j: 145000\n","종료: done = True ... j = 147200  move = 39\n","epiode #: 10788 loss: 0.1655648648738861 j: 150000\n","종료: done = True ... j = 152100  move = 29\n","종료: done = True ... j = 154700  move = 43\n","epiode #: 11047 loss: 0.3002760112285614 j: 155000\n","종료: done = True ... j = 155100  move = 46\n","종료: done = True ... j = 158400  move = 3\n","종료: done = True ... j = 159100  move = 25\n","epiode #: 11312 loss: 0.3962213695049286 j: 160000\n","종료: done = True ... j = 164500  move = 8\n","epiode #: 11597 loss: 0.519017219543457 j: 165000\n","종료: done = True ... j = 165100  move = 6\n","종료: done = True ... j = 166200  move = 90\n","종료: done = True ... j = 168500  move = 5\n","종료: done = True ... j = 168900  move = 17\n","종료: done = True ... j = 169600  move = 5\n","epiode #: 11864 loss: 0.20956803858280182 j: 170000\n","종료: done = True ... j = 170100  move = 6\n","['I'] 종료: env.goal_ob_reward = True ... j = 170469  move = 36 @ 에피소드 # 11888\n","11888번째 에피소드까지 총 5번 finish 했습니다.\n","종료: done = True ... j = 172100  move = 17\n","epiode #: 12121 loss: 0.2858738899230957 j: 175000\n","종료: done = True ... j = 175000  move = 17\n","종료: done = True ... j = 175300  move = 30\n","종료: done = True ... j = 176100  move = 8\n","종료: done = True ... j = 177900  move = 8\n","['K'] 종료: env.goal_ob_reward = True ... j = 178016  move = 54 @ 에피소드 # 12262\n","12262번째 에피소드까지 총 6번 finish 했습니다.\n","['C'] 종료: env.goal_ob_reward = True ... j = 178245  move = 22 @ 에피소드 # 12279\n","12279번째 에피소드까지 총 7번 finish 했습니다.\n","종료: done = True ... j = 178600  move = 23\n","epiode #: 12370 loss: 0.2296188622713089 j: 180000\n","종료: done = True ... j = 181500  move = 7\n","종료: done = True ... j = 184400  move = 5\n","epiode #: 12619 loss: 0.168780118227005 j: 185000\n","종료: done = True ... j = 185000  move = 3\n","['N'] 종료: env.goal_ob_reward = True ... j = 185058  move = 58 @ 에피소드 # 12620\n","12620번째 에피소드까지 총 8번 finish 했습니다.\n","종료: done = True ... j = 186300  move = 28\n","['P'] 종료: env.goal_ob_reward = True ... j = 186579  move = 28 @ 에피소드 # 12713\n","12713번째 에피소드까지 총 9번 finish 했습니다.\n","종료: done = True ... j = 189400  move = 14\n","epiode #: 12906 loss: 0.2362799048423767 j: 190000\n","종료: done = True ... j = 190100  move = 11\n","종료: done = True ... j = 190800  move = 30\n","종료: done = True ... j = 191600  move = 7\n","종료: done = True ... j = 191800  move = 12\n","종료: done = True ... j = 193200  move = 3\n","epiode #: 13165 loss: 0.35900571942329407 j: 195000\n","종료: done = True ... j = 195200  move = 7\n","종료: done = True ... j = 196000  move = 3\n","['Q'] 종료: env.goal_ob_reward = True ... j = 196081  move = 44 @ 에피소드 # 13224\n","13224번째 에피소드까지 총 10번 finish 했습니다.\n","종료: done = True ... j = 196400  move = 5\n","['B'] 종료: env.goal_ob_reward = True ... j = 196633  move = 38 @ 에피소드 # 13255\n","13255번째 에피소드까지 총 11번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 196783  move = 21 @ 에피소드 # 13263\n","13263번째 에피소드까지 총 12번 finish 했습니다.\n","epiode #: 13429 loss: 0.2680240869522095 j: 200000\n","['D'] 종료: env.goal_ob_reward = True ... j = 200504  move = 25 @ 에피소드 # 13449\n","13449번째 에피소드까지 총 13번 finish 했습니다.\n","['N'] 종료: env.goal_ob_reward = True ... j = 202643  move = 26 @ 에피소드 # 13551\n","13551번째 에피소드까지 총 14번 finish 했습니다.\n","종료: done = True ... j = 203000  move = 15\n","['P'] 종료: env.goal_ob_reward = True ... j = 204467  move = 26 @ 에피소드 # 13647\n","13647번째 에피소드까지 총 15번 finish 했습니다.\n","epiode #: 13674 loss: 0.25367221236228943 j: 205000\n","종료: done = True ... j = 205800  move = 21\n","종료: done = True ... j = 206300  move = 8\n","['D'] 종료: env.goal_ob_reward = True ... j = 206484  move = 54 @ 에피소드 # 13751\n","13751번째 에피소드까지 총 16번 finish 했습니다.\n","['N'] 종료: env.goal_ob_reward = True ... j = 207515  move = 30 @ 에피소드 # 13796\n","13796번째 에피소드까지 총 17번 finish 했습니다.\n","종료: done = True ... j = 207900  move = 44\n","['A'] 종료: env.goal_ob_reward = True ... j = 208746  move = 20 @ 에피소드 # 13852\n","13852번째 에피소드까지 총 18번 finish 했습니다.\n","종료: done = True ... j = 209200  move = 12\n","['D'] 종료: env.goal_ob_reward = True ... j = 209252  move = 52 @ 에피소드 # 13873\n","13873번째 에피소드까지 총 19번 finish 했습니다.\n","epiode #: 13914 loss: 0.4244837462902069 j: 210000\n","종료: done = True ... j = 212500  move = 41\n","['O'] 종료: env.goal_ob_reward = True ... j = 214644  move = 32 @ 에피소드 # 14128\n","14128번째 에피소드까지 총 20번 finish 했습니다.\n","epiode #: 14152 loss: 0.25325101613998413 j: 215000\n","종료: done = True ... j = 216300  move = 10\n","['N'] 종료: env.goal_ob_reward = True ... j = 216690  move = 44 @ 에피소드 # 14235\n","14235번째 에피소드까지 총 21번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 216883  move = 28 @ 에피소드 # 14247\n","14247번째 에피소드까지 총 22번 finish 했습니다.\n","종료: done = True ... j = 217300  move = 7\n","종료: done = True ... j = 219700  move = 57\n","epiode #: 14389 loss: 0.42819342017173767 j: 220000\n","['A'] 종료: env.goal_ob_reward = True ... j = 220765  move = 20 @ 에피소드 # 14427\n","14427번째 에피소드까지 총 23번 finish 했습니다.\n","['K'] 종료: env.goal_ob_reward = True ... j = 221144  move = 38 @ 에피소드 # 14445\n","14445번째 에피소드까지 총 24번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 221230  move = 86 @ 에피소드 # 14446\n","14446번째 에피소드까지 총 25번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 222685  move = 16 @ 에피소드 # 14514\n","14514번째 에피소드까지 총 26번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 223913  move = 36 @ 에피소드 # 14557\n","14557번째 에피소드까지 총 27번 finish 했습니다.\n","epiode #: 14606 loss: 0.49552664160728455 j: 225000\n","종료: done = True ... j = 227200  move = 17\n","종료: done = True ... j = 229500  move = 8\n","종료: done = True ... j = 229900  move = 40\n","epiode #: 14868 loss: 0.2612285912036896 j: 230000\n","['Q'] 종료: env.goal_ob_reward = True ... j = 232742  move = 46 @ 에피소드 # 15009\n","15009번째 에피소드까지 총 28번 finish 했습니다.\n","epiode #: 15131 loss: 0.6203131675720215 j: 235000\n","['L'] 종료: env.goal_ob_reward = True ... j = 235345  move = 63 @ 에피소드 # 15147\n","15147번째 에피소드까지 총 29번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 235522  move = 20 @ 에피소드 # 15153\n","15153번째 에피소드까지 총 30번 finish 했습니다.\n","종료: done = True ... j = 236400  move = 6\n","종료: done = True ... j = 237500  move = 10\n","['B'] 종료: env.goal_ob_reward = True ... j = 238112  move = 25 @ 에피소드 # 15291\n","15291번째 에피소드까지 총 31번 finish 했습니다.\n","종료: done = True ... j = 239000  move = 7\n","종료: done = True ... j = 239200  move = 3\n","epiode #: 15381 loss: 0.4327496290206909 j: 240000\n","['H'] 종료: env.goal_ob_reward = True ... j = 240981  move = 31 @ 에피소드 # 15428\n","15428번째 에피소드까지 총 32번 finish 했습니다.\n","종료: done = True ... j = 243700  move = 5\n","종료: done = True ... j = 243900  move = 5\n","종료: done = True ... j = 244500  move = 13\n","epiode #: 15611 loss: 0.5116094946861267 j: 245000\n","종료: done = True ... j = 245900  move = 29\n","['A'] 종료: env.goal_ob_reward = True ... j = 246576  move = 24 @ 에피소드 # 15688\n","15688번째 에피소드까지 총 33번 finish 했습니다.\n","종료: done = True ... j = 247000  move = 36\n","['A'] 종료: env.goal_ob_reward = True ... j = 247254  move = 46 @ 에피소드 # 15724\n","15724번째 에피소드까지 총 34번 finish 했습니다.\n","['N'] 종료: env.goal_ob_reward = True ... j = 248620  move = 84 @ 에피소드 # 15797\n","15797번째 에피소드까지 총 35번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 248771  move = 43 @ 에피소드 # 15804\n","15804번째 에피소드까지 총 36번 finish 했습니다.\n","epiode #: 15858 loss: 0.4326401352882385 j: 250000\n","종료: done = True ... j = 250800  move = 41\n","종료: done = True ... j = 254700  move = 32\n","종료: done = True ... j = 254800  move = 7\n","epiode #: 16119 loss: 0.46088892221450806 j: 255000\n","['Q'] 종료: env.goal_ob_reward = True ... j = 256007  move = 24 @ 에피소드 # 16177\n","16177번째 에피소드까지 총 37번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 257546  move = 38 @ 에피소드 # 16244\n","16244번째 에피소드까지 총 38번 finish 했습니다.\n","종료: done = True ... j = 259400  move = 3\n","epiode #: 16358 loss: 0.23628944158554077 j: 260000\n","종료: done = True ... j = 260900  move = 7\n","['H'] 종료: env.goal_ob_reward = True ... j = 261874  move = 28 @ 에피소드 # 16477\n","16477번째 에피소드까지 총 39번 finish 했습니다.\n","종료: done = True ... j = 262100  move = 7\n","종료: done = True ... j = 263700  move = 9\n","epiode #: 16644 loss: 0.6175905466079712 j: 265000\n","종료: done = True ... j = 265500  move = 16\n","종료: done = True ... j = 268900  move = 31\n","epiode #: 16909 loss: 0.46969011425971985 j: 270000\n","['A'] 종료: env.goal_ob_reward = True ... j = 270786  move = 64 @ 에피소드 # 16950\n","16950번째 에피소드까지 총 40번 finish 했습니다.\n","종료: done = True ... j = 271100  move = 5\n","종료: done = True ... j = 271900  move = 8\n","['B'] 종료: env.goal_ob_reward = True ... j = 272224  move = 26 @ 에피소드 # 17019\n","17019번째 에피소드까지 총 41번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 272417  move = 24 @ 에피소드 # 17032\n","17032번째 에피소드까지 총 42번 finish 했습니다.\n","종료: done = True ... j = 272800  move = 16\n","['B'] 종료: env.goal_ob_reward = True ... j = 273352  move = 20 @ 에피소드 # 17088\n","17088번째 에피소드까지 총 43번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 273899  move = 38 @ 에피소드 # 17119\n","17119번째 에피소드까지 총 44번 finish 했습니다.\n","['K'] 종료: env.goal_ob_reward = True ... j = 274376  move = 42 @ 에피소드 # 17150\n","17150번째 에피소드까지 총 45번 finish 했습니다.\n","['L'] 종료: env.goal_ob_reward = True ... j = 274810  move = 50 @ 에피소드 # 17175\n","17175번째 에피소드까지 총 46번 finish 했습니다.\n","epiode #: 17189 loss: 0.3820221722126007 j: 275000\n","종료: done = True ... j = 276200  move = 13\n","['Q'] 종료: env.goal_ob_reward = True ... j = 277574  move = 46 @ 에피소드 # 17331\n","17331번째 에피소드까지 총 47번 finish 했습니다.\n","종료: done = True ... j = 279400  move = 53\n","epiode #: 17464 loss: 0.6116905808448792 j: 280000\n","['Q'] 종료: env.goal_ob_reward = True ... j = 280191  move = 78 @ 에피소드 # 17475\n","17475번째 에피소드까지 총 48번 finish 했습니다.\n","['H'] 종료: env.goal_ob_reward = True ... j = 282459  move = 73 @ 에피소드 # 17599\n","17599번째 에피소드까지 총 49번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 283869  move = 44 @ 에피소드 # 17676\n","17676번째 에피소드까지 총 50번 finish 했습니다.\n","종료: done = True ... j = 283900  move = 31\n","['F'] 종료: env.goal_ob_reward = True ... j = 283900  move = 31 @ 에피소드 # 17677\n","17677번째 에피소드까지 총 51번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 284410  move = 27 @ 에피소드 # 17708\n","17708번째 에피소드까지 총 52번 finish 했습니다.\n","epiode #: 17740 loss: 0.5156463384628296 j: 285000\n","['H'] 종료: env.goal_ob_reward = True ... j = 285429  move = 24 @ 에피소드 # 17761\n","17761번째 에피소드까지 총 53번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 286839  move = 24 @ 에피소드 # 17840\n","17840번째 에피소드까지 총 54번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 287167  move = 22 @ 에피소드 # 17861\n","17861번째 에피소드까지 총 55번 finish 했습니다.\n","종료: done = True ... j = 287300  move = 42\n","종료: done = True ... j = 287500  move = 6\n","종료: done = True ... j = 289100  move = 7\n","epiode #: 18014 loss: 0.5260933041572571 j: 290000\n","종료: done = True ... j = 290000  move = 5\n","종료: done = True ... j = 290500  move = 21\n","종료: done = True ... j = 290600  move = 14\n","종료: done = True ... j = 291200  move = 5\n","종료: done = True ... j = 292600  move = 40\n","['B'] 종료: env.goal_ob_reward = True ... j = 292849  move = 40 @ 에피소드 # 18178\n","18178번째 에피소드까지 총 56번 finish 했습니다.\n","종료: done = True ... j = 294900  move = 23\n","epiode #: 18299 loss: 0.5624343156814575 j: 295000\n","['O'] 종료: env.goal_ob_reward = True ... j = 296386  move = 48 @ 에피소드 # 18355\n","18355번째 에피소드까지 총 57번 finish 했습니다.\n","종료: done = True ... j = 298500  move = 5\n","종료: done = True ... j = 299000  move = 19\n","epiode #: 18533 loss: 0.3154135048389435 j: 300000\n","종료: done = True ... j = 301200  move = 9\n","종료: done = True ... j = 301400  move = 41\n","['C'] 종료: env.goal_ob_reward = True ... j = 302501  move = 38 @ 에피소드 # 18665\n","18665번째 에피소드까지 총 58번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 303175  move = 18 @ 에피소드 # 18701\n","18701번째 에피소드까지 총 59번 finish 했습니다.\n","종료: done = True ... j = 303200  move = 11\n","['J'] 종료: env.goal_ob_reward = True ... j = 303415  move = 30 @ 에피소드 # 18720\n","18720번째 에피소드까지 총 60번 finish 했습니다.\n","종료: done = True ... j = 303600  move = 10\n","epiode #: 18794 loss: 0.4195193350315094 j: 305000\n","['Q'] 종료: env.goal_ob_reward = True ... j = 306628  move = 24 @ 에피소드 # 18878\n","18878번째 에피소드까지 총 61번 finish 했습니다.\n","종료: done = True ... j = 307100  move = 3\n","['G'] 종료: env.goal_ob_reward = True ... j = 307395  move = 32 @ 에피소드 # 18922\n","18922번째 에피소드까지 총 62번 finish 했습니다.\n","종료: done = True ... j = 307400  move = 5\n","종료: done = True ... j = 308400  move = 14\n","종료: done = True ... j = 308700  move = 13\n","epiode #: 19058 loss: 0.53448885679245 j: 310000\n","종료: done = True ... j = 310200  move = 3\n","종료: done = True ... j = 310400  move = 36\n","['Q'] 종료: env.goal_ob_reward = True ... j = 312124  move = 22 @ 에피소드 # 19162\n","19162번째 에피소드까지 총 63번 finish 했습니다.\n","종료: done = True ... j = 312800  move = 8\n","종료: done = True ... j = 313300  move = 13\n","['I'] 종료: env.goal_ob_reward = True ... j = 314712  move = 30 @ 에피소드 # 19283\n","19283번째 에피소드까지 총 64번 finish 했습니다.\n","epiode #: 19301 loss: 0.6676761507987976 j: 315000\n","종료: done = True ... j = 317100  move = 10\n","['F'] 종료: env.goal_ob_reward = True ... j = 317192  move = 36 @ 에피소드 # 19413\n","19413번째 에피소드까지 총 65번 finish 했습니다.\n","종료: done = True ... j = 317900  move = 24\n","['A'] 종료: env.goal_ob_reward = True ... j = 318764  move = 23 @ 에피소드 # 19485\n","19485번째 에피소드까지 총 66번 finish 했습니다.\n","종료: done = True ... j = 319600  move = 25\n","종료: done = True ... j = 319800  move = 22\n","epiode #: 19549 loss: 0.36831480264663696 j: 320000\n","['O'] 종료: env.goal_ob_reward = True ... j = 320141  move = 44 @ 에피소드 # 19554\n","19554번째 에피소드까지 총 67번 finish 했습니다.\n","['N'] 종료: env.goal_ob_reward = True ... j = 320717  move = 32 @ 에피소드 # 19594\n","19594번째 에피소드까지 총 68번 finish 했습니다.\n","['H'] 종료: env.goal_ob_reward = True ... j = 321026  move = 24 @ 에피소드 # 19608\n","19608번째 에피소드까지 총 69번 finish 했습니다.\n","['H'] 종료: env.goal_ob_reward = True ... j = 321823  move = 40 @ 에피소드 # 19646\n","19646번째 에피소드까지 총 70번 finish 했습니다.\n","종료: done = True ... j = 322000  move = 10\n","종료: done = True ... j = 322100  move = 6\n","epiode #: 19819 loss: 0.4125027358531952 j: 325000\n","['A'] 종료: env.goal_ob_reward = True ... j = 325360  move = 21 @ 에피소드 # 19835\n","19835번째 에피소드까지 총 71번 finish 했습니다.\n","종료: done = True ... j = 325500  move = 38\n","['J'] 종료: env.goal_ob_reward = True ... j = 325581  move = 29 @ 에피소드 # 19845\n","19845번째 에피소드까지 총 72번 finish 했습니다.\n","종료: done = True ... j = 326500  move = 3\n","종료: done = True ... j = 327100  move = 7\n","['C'] 종료: env.goal_ob_reward = True ... j = 328076  move = 24 @ 에피소드 # 19984\n","19984번째 에피소드까지 총 73번 finish 했습니다.\n","▶ 모델 저장됨!!! @ 에피소드 20000\n","종료: done = True ... j = 328800  move = 27\n","['P'] 종료: env.goal_ob_reward = True ... j = 328922  move = 31 @ 에피소드 # 20032\n","20032번째 에피소드까지 총 74번 finish 했습니다.\n","['C'] 종료: env.goal_ob_reward = True ... j = 329295  move = 30 @ 에피소드 # 20058\n","20058번째 에피소드까지 총 75번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 329695  move = 20 @ 에피소드 # 20078\n","20078번째 에피소드까지 총 76번 finish 했습니다.\n","epiode #: 20103 loss: 0.4786510467529297 j: 330000\n","['P'] 종료: env.goal_ob_reward = True ... j = 330286  move = 24 @ 에피소드 # 20121\n","20121번째 에피소드까지 총 77번 finish 했습니다.\n","['C'] 종료: env.goal_ob_reward = True ... j = 332278  move = 22 @ 에피소드 # 20232\n","20232번째 에피소드까지 총 78번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 332655  move = 36 @ 에피소드 # 20254\n","20254번째 에피소드까지 총 79번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 332909  move = 30 @ 에피소드 # 20267\n","20267번째 에피소드까지 총 80번 finish 했습니다.\n","['H'] 종료: env.goal_ob_reward = True ... j = 333109  move = 24 @ 에피소드 # 20274\n","20274번째 에피소드까지 총 81번 finish 했습니다.\n","종료: done = True ... j = 333200  move = 7\n","종료: done = True ... j = 333700  move = 8\n","['Q'] 종료: env.goal_ob_reward = True ... j = 334745  move = 64 @ 에피소드 # 20367\n","20367번째 에피소드까지 총 82번 finish 했습니다.\n","epiode #: 20381 loss: 0.5991881489753723 j: 335000\n","종료: done = True ... j = 335800  move = 7\n","['C'] 종료: env.goal_ob_reward = True ... j = 335968  move = 41 @ 에피소드 # 20423\n","20423번째 에피소드까지 총 83번 finish 했습니다.\n","종료: done = True ... j = 336400  move = 6\n","종료: done = True ... j = 336600  move = 24\n","['C'] 종료: env.goal_ob_reward = True ... j = 337342  move = 40 @ 에피소드 # 20494\n","20494번째 에피소드까지 총 84번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 338552  move = 34 @ 에피소드 # 20562\n","20562번째 에피소드까지 총 85번 finish 했습니다.\n","종료: done = True ... j = 338800  move = 84\n","epiode #: 20628 loss: 0.32126447558403015 j: 340000\n","종료: done = True ... j = 340900  move = 18\n","종료: done = True ... j = 341500  move = 96\n","종료: done = True ... j = 341900  move = 39\n","['C'] 종료: env.goal_ob_reward = True ... j = 342952  move = 24 @ 에피소드 # 20782\n","20782번째 에피소드까지 총 86번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 343356  move = 29 @ 에피소드 # 20803\n","20803번째 에피소드까지 총 87번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 343809  move = 16 @ 에피소드 # 20827\n","20827번째 에피소드까지 총 88번 finish 했습니다.\n","epiode #: 20893 loss: 0.5410030484199524 j: 345000\n","['D'] 종료: env.goal_ob_reward = True ... j = 345729  move = 38 @ 에피소드 # 20943\n","20943번째 에피소드까지 총 89번 finish 했습니다.\n","종료: done = True ... j = 346200  move = 43\n","['P'] 종료: env.goal_ob_reward = True ... j = 346200  move = 43 @ 에피소드 # 20970\n","20970번째 에피소드까지 총 90번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 346638  move = 65 @ 에피소드 # 20986\n","20986번째 에피소드까지 총 91번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 348586  move = 20 @ 에피소드 # 21083\n","21083번째 에피소드까지 총 92번 finish 했습니다.\n","종료: done = True ... j = 348700  move = 3\n","종료: done = True ... j = 349700  move = 9\n","epiode #: 21161 loss: 0.456399142742157 j: 350000\n","종료: done = True ... j = 351100  move = 13\n","['A'] 종료: env.goal_ob_reward = True ... j = 351582  move = 28 @ 에피소드 # 21246\n","21246번째 에피소드까지 총 93번 finish 했습니다.\n","종료: done = True ... j = 353100  move = 6\n","종료: done = True ... j = 354200  move = 15\n","epiode #: 21440 loss: 0.6464798450469971 j: 355000\n","['G'] 종료: env.goal_ob_reward = True ... j = 355104  move = 38 @ 에피소드 # 21443\n","21443번째 에피소드까지 총 94번 finish 했습니다.\n","['F'] 종료: env.goal_ob_reward = True ... j = 355586  move = 25 @ 에피소드 # 21471\n","21471번째 에피소드까지 총 95번 finish 했습니다.\n","종료: done = True ... j = 355900  move = 8\n","['J'] 종료: env.goal_ob_reward = True ... j = 355950  move = 26 @ 에피소드 # 21491\n","21491번째 에피소드까지 총 96번 finish 했습니다.\n","종료: done = True ... j = 356000  move = 7\n","종료: done = True ... j = 356200  move = 36\n","['Q'] 종료: env.goal_ob_reward = True ... j = 356249  move = 34 @ 에피소드 # 21510\n","21510번째 에피소드까지 총 97번 finish 했습니다.\n","종료: done = True ... j = 356600  move = 3\n","['D'] 종료: env.goal_ob_reward = True ... j = 357369  move = 30 @ 에피소드 # 21562\n","21562번째 에피소드까지 총 98번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 357691  move = 38 @ 에피소드 # 21578\n","21578번째 에피소드까지 총 99번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 357982  move = 31 @ 에피소드 # 21596\n","21596번째 에피소드까지 총 100번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 358606  move = 42 @ 에피소드 # 21631\n","21631번째 에피소드까지 총 101번 finish 했습니다.\n","epiode #: 21698 loss: 0.2421576976776123 j: 360000\n","['B'] 종료: env.goal_ob_reward = True ... j = 360328  move = 54 @ 에피소드 # 21715\n","21715번째 에피소드까지 총 102번 finish 했습니다.\n","종료: done = True ... j = 360500  move = 38\n","['A'] 종료: env.goal_ob_reward = True ... j = 360804  move = 16 @ 에피소드 # 21734\n","21734번째 에피소드까지 총 103번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 361054  move = 26 @ 에피소드 # 21746\n","21746번째 에피소드까지 총 104번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 362113  move = 25 @ 에피소드 # 21810\n","21810번째 에피소드까지 총 105번 finish 했습니다.\n","epiode #: 21962 loss: 0.22071273624897003 j: 365000\n","종료: done = True ... j = 366000  move = 25\n","['Q'] 종료: env.goal_ob_reward = True ... j = 366766  move = 20 @ 에피소드 # 22050\n","22050번째 에피소드까지 총 106번 finish 했습니다.\n","종료: done = True ... j = 366800  move = 29\n","['Q'] 종료: env.goal_ob_reward = True ... j = 367186  move = 32 @ 에피소드 # 22073\n","22073번째 에피소드까지 총 107번 finish 했습니다.\n","['F'] 종료: env.goal_ob_reward = True ... j = 367386  move = 35 @ 에피소드 # 22085\n","22085번째 에피소드까지 총 108번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 367565  move = 34 @ 에피소드 # 22094\n","22094번째 에피소드까지 총 109번 finish 했습니다.\n","종료: done = True ... j = 368300  move = 5\n","종료: done = True ... j = 368500  move = 20\n","['D'] 종료: env.goal_ob_reward = True ... j = 368835  move = 36 @ 에피소드 # 22164\n","22164번째 에피소드까지 총 110번 finish 했습니다.\n","종료: done = True ... j = 369500  move = 7\n","['K'] 종료: env.goal_ob_reward = True ... j = 369689  move = 32 @ 에피소드 # 22204\n","22204번째 에피소드까지 총 111번 finish 했습니다.\n","epiode #: 22214 loss: 0.4278606176376343 j: 370000\n","['Q'] 종료: env.goal_ob_reward = True ... j = 370032  move = 58 @ 에피소드 # 22214\n","22214번째 에피소드까지 총 112번 finish 했습니다.\n","종료: done = True ... j = 370600  move = 5\n","종료: done = True ... j = 370800  move = 58\n","['O'] 종료: env.goal_ob_reward = True ... j = 371573  move = 52 @ 에피소드 # 22303\n","22303번째 에피소드까지 총 113번 finish 했습니다.\n","['L'] 종료: env.goal_ob_reward = True ... j = 371948  move = 25 @ 에피소드 # 22328\n","22328번째 에피소드까지 총 114번 finish 했습니다.\n","종료: done = True ... j = 373100  move = 22\n","종료: done = True ... j = 374300  move = 7\n","['F'] 종료: env.goal_ob_reward = True ... j = 374414  move = 30 @ 에피소드 # 22459\n","22459번째 에피소드까지 총 115번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 374802  move = 19 @ 에피소드 # 22481\n","22481번째 에피소드까지 총 116번 finish 했습니다.\n","epiode #: 22491 loss: 0.29502221941947937 j: 375000\n","종료: done = True ... j = 376200  move = 19\n","종료: done = True ... j = 377000  move = 18\n","['O'] 종료: env.goal_ob_reward = True ... j = 378118  move = 45 @ 에피소드 # 22665\n","22665번째 에피소드까지 총 117번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 378644  move = 40 @ 에피소드 # 22692\n","22692번째 에피소드까지 총 118번 finish 했습니다.\n","['F'] 종료: env.goal_ob_reward = True ... j = 379750  move = 38 @ 에피소드 # 22749\n","22749번째 에피소드까지 총 119번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 379824  move = 22 @ 에피소드 # 22756\n","22756번째 에피소드까지 총 120번 finish 했습니다.\n","epiode #: 22767 loss: 0.4265943765640259 j: 380000\n","종료: done = True ... j = 380000  move = 31\n","종료: done = True ... j = 380200  move = 49\n","종료: done = True ... j = 383300  move = 14\n","['O'] 종료: env.goal_ob_reward = True ... j = 383409  move = 28 @ 에피소드 # 22953\n","22953번째 에피소드까지 총 121번 finish 했습니다.\n","epiode #: 23035 loss: 0.47917836904525757 j: 385000\n","종료: done = True ... j = 385300  move = 13\n","['Q'] 종료: env.goal_ob_reward = True ... j = 386781  move = 24 @ 에피소드 # 23141\n","23141번째 에피소드까지 총 122번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 387519  move = 80 @ 에피소드 # 23171\n","23171번째 에피소드까지 총 123번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 387641  move = 40 @ 에피소드 # 23175\n","23175번째 에피소드까지 총 124번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 387911  move = 18 @ 에피소드 # 23192\n","23192번째 에피소드까지 총 125번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 389134  move = 24 @ 에피소드 # 23252\n","23252번째 에피소드까지 총 126번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 389623  move = 24 @ 에피소드 # 23287\n","23287번째 에피소드까지 총 127번 finish 했습니다.\n","epiode #: 23303 loss: 0.5144139528274536 j: 390000\n","['H'] 종료: env.goal_ob_reward = True ... j = 390518  move = 30 @ 에피소드 # 23330\n","23330번째 에피소드까지 총 128번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 390839  move = 28 @ 에피소드 # 23346\n","23346번째 에피소드까지 총 129번 finish 했습니다.\n","종료: done = True ... j = 391300  move = 5\n","['P'] 종료: env.goal_ob_reward = True ... j = 391942  move = 53 @ 에피소드 # 23410\n","23410번째 에피소드까지 총 130번 finish 했습니다.\n","종료: done = True ... j = 392000  move = 14\n","종료: done = True ... j = 393900  move = 9\n","epiode #: 23574 loss: 0.599986732006073 j: 395000\n","['A'] 종료: env.goal_ob_reward = True ... j = 395246  move = 18 @ 에피소드 # 23590\n","23590번째 에피소드까지 총 131번 finish 했습니다.\n","종료: done = True ... j = 395500  move = 75\n","['B'] 종료: env.goal_ob_reward = True ... j = 396039  move = 20 @ 에피소드 # 23618\n","23618번째 에피소드까지 총 132번 finish 했습니다.\n","종료: done = True ... j = 396100  move = 8\n","['P'] 종료: env.goal_ob_reward = True ... j = 397036  move = 50 @ 에피소드 # 23672\n","23672번째 에피소드까지 총 133번 finish 했습니다.\n","종료: done = True ... j = 397200  move = 10\n","['G'] 종료: env.goal_ob_reward = True ... j = 397238  move = 31 @ 에피소드 # 23681\n","23681번째 에피소드까지 총 134번 finish 했습니다.\n","종료: done = True ... j = 397800  move = 34\n","['B'] 종료: env.goal_ob_reward = True ... j = 399223  move = 39 @ 에피소드 # 23798\n","23798번째 에피소드까지 총 135번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 399255  move = 32 @ 에피소드 # 23799\n","23799번째 에피소드까지 총 136번 finish 했습니다.\n","종료: done = True ... j = 399300  move = 22\n","epiode #: 23844 loss: 0.2947126030921936 j: 400000\n","['L'] 종료: env.goal_ob_reward = True ... j = 400863  move = 35 @ 에피소드 # 23885\n","23885번째 에피소드까지 총 137번 finish 했습니다.\n","['C'] 종료: env.goal_ob_reward = True ... j = 402891  move = 52 @ 에피소드 # 23978\n","23978번째 에피소드까지 총 138번 finish 했습니다.\n","epiode #: 24103 loss: 0.5028229355812073 j: 405000\n","['A'] 종료: env.goal_ob_reward = True ... j = 405003  move = 30 @ 에피소드 # 24103\n","24103번째 에피소드까지 총 139번 finish 했습니다.\n","종료: done = True ... j = 406200  move = 9\n","['K'] 종료: env.goal_ob_reward = True ... j = 407107  move = 69 @ 에피소드 # 24219\n","24219번째 에피소드까지 총 140번 finish 했습니다.\n","epiode #: 24374 loss: 0.504060685634613 j: 410000\n","종료: done = True ... j = 410300  move = 42\n","종료: done = True ... j = 411000  move = 32\n","['C'] 종료: env.goal_ob_reward = True ... j = 412199  move = 26 @ 에피소드 # 24499\n","24499번째 에피소드까지 총 141번 finish 했습니다.\n","종료: done = True ... j = 414500  move = 5\n","epiode #: 24634 loss: 0.38357269763946533 j: 415000\n","종료: done = True ... j = 416000  move = 55\n","종료: done = True ... j = 416300  move = 8\n","['A'] 종료: env.goal_ob_reward = True ... j = 416324  move = 24 @ 에피소드 # 24699\n","24699번째 에피소드까지 총 142번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 417874  move = 22 @ 에피소드 # 24779\n","24779번째 에피소드까지 총 143번 finish 했습니다.\n","['G'] 종료: env.goal_ob_reward = True ... j = 418227  move = 43 @ 에피소드 # 24791\n","24791번째 에피소드까지 총 144번 finish 했습니다.\n","종료: done = True ... j = 418400  move = 17\n","종료: done = True ... j = 419300  move = 23\n","epiode #: 24889 loss: 0.18969108164310455 j: 420000\n","['Q'] 종료: env.goal_ob_reward = True ... j = 420075  move = 22 @ 에피소드 # 24893\n","24893번째 에피소드까지 총 145번 finish 했습니다.\n","종료: done = True ... j = 421500  move = 10\n","['Q'] 종료: env.goal_ob_reward = True ... j = 422532  move = 18 @ 에피소드 # 25017\n","25017번째 에피소드까지 총 146번 finish 했습니다.\n","epiode #: 25154 loss: 0.4291761815547943 j: 425000\n","['H'] 종료: env.goal_ob_reward = True ... j = 425867  move = 22 @ 에피소드 # 25214\n","25214번째 에피소드까지 총 147번 finish 했습니다.\n","종료: done = True ... j = 426000  move = 10\n","['H'] 종료: env.goal_ob_reward = True ... j = 426580  move = 26 @ 에피소드 # 25256\n","25256번째 에피소드까지 총 148번 finish 했습니다.\n","종료: done = True ... j = 426700  move = 21\n","['L'] 종료: env.goal_ob_reward = True ... j = 427492  move = 35 @ 에피소드 # 25298\n","25298번째 에피소드까지 총 149번 finish 했습니다.\n","종료: done = True ... j = 428300  move = 14\n","종료: done = True ... j = 428900  move = 10\n","epiode #: 25427 loss: 0.30987659096717834 j: 430000\n","['O'] 종료: env.goal_ob_reward = True ... j = 431753  move = 37 @ 에피소드 # 25510\n","25510번째 에피소드까지 총 150번 finish 했습니다.\n","종료: done = True ... j = 432100  move = 9\n","종료: done = True ... j = 432200  move = 5\n","['A'] 종료: env.goal_ob_reward = True ... j = 432846  move = 20 @ 에피소드 # 25563\n","25563번째 에피소드까지 총 151번 finish 했습니다.\n","종료: done = True ... j = 433300  move = 58\n","['E'] 종료: env.goal_ob_reward = True ... j = 433685  move = 48 @ 에피소드 # 25606\n","25606번째 에피소드까지 총 152번 finish 했습니다.\n","종료: done = True ... j = 433700  move = 15\n","종료: done = True ... j = 434000  move = 10\n","epiode #: 25665 loss: 0.27635544538497925 j: 435000\n","['N'] 종료: env.goal_ob_reward = True ... j = 435888  move = 74 @ 에피소드 # 25702\n","25702번째 에피소드까지 총 153번 finish 했습니다.\n","종료: done = True ... j = 436300  move = 7\n","종료: done = True ... j = 437300  move = 39\n","['Q'] 종료: env.goal_ob_reward = True ... j = 439370  move = 66 @ 에피소드 # 25870\n","25870번째 에피소드까지 총 154번 finish 했습니다.\n","epiode #: 25904 loss: 0.38395559787750244 j: 440000\n","종료: done = True ... j = 440400  move = 45\n","종료: done = True ... j = 440700  move = 8\n","['E'] 종료: env.goal_ob_reward = True ... j = 440758  move = 30 @ 에피소드 # 25941\n","25941번째 에피소드까지 총 155번 finish 했습니다.\n","['N'] 종료: env.goal_ob_reward = True ... j = 440816  move = 28 @ 에피소드 # 25946\n","25946번째 에피소드까지 총 156번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 440840  move = 24 @ 에피소드 # 25947\n","25947번째 에피소드까지 총 157번 finish 했습니다.\n","['K'] 종료: env.goal_ob_reward = True ... j = 441360  move = 44 @ 에피소드 # 25974\n","25974번째 에피소드까지 총 158번 finish 했습니다.\n","종료: done = True ... j = 441400  move = 30\n","종료: done = True ... j = 441500  move = 12\n","epiode #: 26169 loss: 0.4533672332763672 j: 445000\n","['Q'] 종료: env.goal_ob_reward = True ... j = 446621  move = 20 @ 에피소드 # 26269\n","26269번째 에피소드까지 총 159번 finish 했습니다.\n","종료: done = True ... j = 447400  move = 18\n","['O'] 종료: env.goal_ob_reward = True ... j = 448456  move = 25 @ 에피소드 # 26373\n","26373번째 에피소드까지 총 160번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 449332  move = 30 @ 에피소드 # 26420\n","26420번째 에피소드까지 총 161번 finish 했습니다.\n","epiode #: 26450 loss: 0.4656851887702942 j: 450000\n","['G'] 종료: env.goal_ob_reward = True ... j = 450751  move = 38 @ 에피소드 # 26485\n","26485번째 에피소드까지 총 162번 finish 했습니다.\n","종료: done = True ... j = 451000  move = 31\n","['G'] 종료: env.goal_ob_reward = True ... j = 451704  move = 44 @ 에피소드 # 26537\n","26537번째 에피소드까지 총 163번 finish 했습니다.\n","종료: done = True ... j = 452600  move = 26\n","['I'] 종료: env.goal_ob_reward = True ... j = 452730  move = 58 @ 에피소드 # 26585\n","26585번째 에피소드까지 총 164번 finish 했습니다.\n","종료: done = True ... j = 453100  move = 10\n","['O'] 종료: env.goal_ob_reward = True ... j = 453381  move = 49 @ 에피소드 # 26628\n","26628번째 에피소드까지 총 165번 finish 했습니다.\n","['C'] 종료: env.goal_ob_reward = True ... j = 453679  move = 20 @ 에피소드 # 26643\n","26643번째 에피소드까지 총 166번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 453958  move = 22 @ 에피소드 # 26657\n","26657번째 에피소드까지 총 167번 finish 했습니다.\n","종료: done = True ... j = 454500  move = 8\n","epiode #: 26707 loss: 0.3448762893676758 j: 455000\n","['Q'] 종료: env.goal_ob_reward = True ... j = 455189  move = 46 @ 에피소드 # 26712\n","26712번째 에피소드까지 총 168번 finish 했습니다.\n","['K'] 종료: env.goal_ob_reward = True ... j = 456177  move = 26 @ 에피소드 # 26760\n","26760번째 에피소드까지 총 169번 finish 했습니다.\n","종료: done = True ... j = 456700  move = 23\n","종료: done = True ... j = 456800  move = 33\n","종료: done = True ... j = 457400  move = 10\n","['Q'] 종료: env.goal_ob_reward = True ... j = 458465  move = 24 @ 에피소드 # 26879\n","26879번째 에피소드까지 총 170번 finish 했습니다.\n","종료: done = True ... j = 459200  move = 17\n","epiode #: 26964 loss: 0.7643224000930786 j: 460000\n","['Q'] 종료: env.goal_ob_reward = True ... j = 461699  move = 28 @ 에피소드 # 27049\n","27049번째 에피소드까지 총 171번 finish 했습니다.\n","종료: done = True ... j = 461800  move = 5\n","['A'] 종료: env.goal_ob_reward = True ... j = 461858  move = 28 @ 에피소드 # 27062\n","27062번째 에피소드까지 총 172번 finish 했습니다.\n","종료: done = True ... j = 461900  move = 28\n","['G'] 종료: env.goal_ob_reward = True ... j = 462609  move = 38 @ 에피소드 # 27103\n","27103번째 에피소드까지 총 173번 finish 했습니다.\n","종료: done = True ... j = 463900  move = 17\n","epiode #: 27232 loss: 0.5308207869529724 j: 465000\n","종료: done = True ... j = 465300  move = 23\n","['L'] 종료: env.goal_ob_reward = True ... j = 467556  move = 37 @ 에피소드 # 27381\n","27381번째 에피소드까지 총 174번 finish 했습니다.\n","종료: done = True ... j = 467700  move = 47\n","['N'] 종료: env.goal_ob_reward = True ... j = 468169  move = 28 @ 에피소드 # 27409\n","27409번째 에피소드까지 총 175번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 469455  move = 40 @ 에피소드 # 27475\n","27475번째 에피소드까지 총 176번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 469473  move = 18 @ 에피소드 # 27476\n","27476번째 에피소드까지 총 177번 finish 했습니다.\n","종료: done = True ... j = 469900  move = 18\n","epiode #: 27504 loss: 0.3497062623500824 j: 470000\n","['H'] 종료: env.goal_ob_reward = True ... j = 470402  move = 20 @ 에피소드 # 27524\n","27524번째 에피소드까지 총 178번 finish 했습니다.\n","종료: done = True ... j = 471200  move = 22\n","['Q'] 종료: env.goal_ob_reward = True ... j = 471342  move = 22 @ 에피소드 # 27580\n","27580번째 에피소드까지 총 179번 finish 했습니다.\n","종료: done = True ... j = 471400  move = 46\n","종료: done = True ... j = 471800  move = 35\n","종료: done = True ... j = 472000  move = 27\n","['Q'] 종료: env.goal_ob_reward = True ... j = 472166  move = 34 @ 에피소드 # 27628\n","27628번째 에피소드까지 총 180번 finish 했습니다.\n","종료: done = True ... j = 472500  move = 3\n","['A'] 종료: env.goal_ob_reward = True ... j = 472941  move = 20 @ 에피소드 # 27673\n","27673번째 에피소드까지 총 181번 finish 했습니다.\n","['G'] 종료: env.goal_ob_reward = True ... j = 473711  move = 36 @ 에피소드 # 27716\n","27716번째 에피소드까지 총 182번 finish 했습니다.\n","epiode #: 27788 loss: 0.4164666533470154 j: 475000\n","['D'] 종료: env.goal_ob_reward = True ... j = 475514  move = 24 @ 에피소드 # 27822\n","27822번째 에피소드까지 총 183번 finish 했습니다.\n","종료: done = True ... j = 476100  move = 8\n","종료: done = True ... j = 477200  move = 3\n","종료: done = True ... j = 477600  move = 19\n","['O'] 종료: env.goal_ob_reward = True ... j = 477974  move = 39 @ 에피소드 # 27963\n","27963번째 에피소드까지 총 184번 finish 했습니다.\n","epiode #: 28060 loss: 0.14379329979419708 j: 480000\n","종료: done = True ... j = 480600  move = 59\n","['A'] 종료: env.goal_ob_reward = True ... j = 480792  move = 16 @ 에피소드 # 28110\n","28110번째 에피소드까지 총 185번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 481806  move = 34 @ 에피소드 # 28167\n","28167번째 에피소드까지 총 186번 finish 했습니다.\n","['F'] 종료: env.goal_ob_reward = True ... j = 482942  move = 28 @ 에피소드 # 28213\n","28213번째 에피소드까지 총 187번 finish 했습니다.\n","종료: done = True ... j = 484400  move = 4\n","종료: done = True ... j = 484600  move = 8\n","epiode #: 28312 loss: 0.3969416618347168 j: 485000\n","종료: done = True ... j = 486100  move = 3\n","종료: done = True ... j = 486800  move = 12\n","['H'] 종료: env.goal_ob_reward = True ... j = 488455  move = 29 @ 에피소드 # 28491\n","28491번째 에피소드까지 총 188번 finish 했습니다.\n","종료: done = True ... j = 489200  move = 32\n","['C'] 종료: env.goal_ob_reward = True ... j = 489503  move = 63 @ 에피소드 # 28552\n","28552번째 에피소드까지 총 189번 finish 했습니다.\n","epiode #: 28582 loss: 0.5159022212028503 j: 490000\n","종료: done = True ... j = 492400  move = 11\n","종료: done = True ... j = 494200  move = 9\n","['E'] 종료: env.goal_ob_reward = True ... j = 494296  move = 42 @ 에피소드 # 28800\n","28800번째 에피소드까지 총 190번 finish 했습니다.\n","종료: done = True ... j = 494400  move = 3\n","['A'] 종료: env.goal_ob_reward = True ... j = 494443  move = 30 @ 에피소드 # 28811\n","28811번째 에피소드까지 총 191번 finish 했습니다.\n","종료: done = True ... j = 494600  move = 11\n","epiode #: 28837 loss: 0.3916037678718567 j: 495000\n","['Q'] 종료: env.goal_ob_reward = True ... j = 495820  move = 42 @ 에피소드 # 28871\n","28871번째 에피소드까지 총 192번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 495951  move = 24 @ 에피소드 # 28876\n","28876번째 에피소드까지 총 193번 finish 했습니다.\n","['L'] 종료: env.goal_ob_reward = True ... j = 497001  move = 63 @ 에피소드 # 28930\n","28930번째 에피소드까지 총 194번 finish 했습니다.\n","종료: done = True ... j = 497400  move = 21\n","epiode #: 29088 loss: 0.334999680519104 j: 500000\n","['Q'] 종료: env.goal_ob_reward = True ... j = 500292  move = 24 @ 에피소드 # 29097\n","29097번째 에피소드까지 총 195번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 500617  move = 22 @ 에피소드 # 29108\n","29108번째 에피소드까지 총 196번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 501091  move = 32 @ 에피소드 # 29134\n","29134번째 에피소드까지 총 197번 finish 했습니다.\n","['H'] 종료: env.goal_ob_reward = True ... j = 501323  move = 22 @ 에피소드 # 29142\n","29142번째 에피소드까지 총 198번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 501669  move = 65 @ 에피소드 # 29164\n","29164번째 에피소드까지 총 199번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 502185  move = 46 @ 에피소드 # 29193\n","29193번째 에피소드까지 총 200번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 502754  move = 52 @ 에피소드 # 29216\n","29216번째 에피소드까지 총 201번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 503053  move = 39 @ 에피소드 # 29232\n","29232번째 에피소드까지 총 202번 finish 했습니다.\n","종료: done = True ... j = 504900  move = 21\n","epiode #: 29333 loss: 0.4804973006248474 j: 505000\n","종료: done = True ... j = 505500  move = 3\n","종료: done = True ... j = 506400  move = 3\n","종료: done = True ... j = 506900  move = 14\n","종료: done = True ... j = 507900  move = 8\n","['L'] 종료: env.goal_ob_reward = True ... j = 508488  move = 86 @ 에피소드 # 29513\n","29513번째 에피소드까지 총 203번 finish 했습니다.\n","['L'] 종료: env.goal_ob_reward = True ... j = 508555  move = 30 @ 에피소드 # 29517\n","29517번째 에피소드까지 총 204번 finish 했습니다.\n","['K'] 종료: env.goal_ob_reward = True ... j = 509462  move = 22 @ 에피소드 # 29558\n","29558번째 에피소드까지 총 205번 finish 했습니다.\n","종료: done = True ... j = 509700  move = 5\n","epiode #: 29583 loss: 0.31476467847824097 j: 510000\n","['B'] 종료: env.goal_ob_reward = True ... j = 510470  move = 46 @ 에피소드 # 29607\n","29607번째 에피소드까지 총 206번 finish 했습니다.\n","종료: done = True ... j = 510500  move = 30\n","종료: done = True ... j = 510700  move = 7\n","종료: done = True ... j = 511000  move = 13\n","종료: done = True ... j = 511400  move = 20\n","종료: done = True ... j = 511900  move = 10\n","['A'] 종료: env.goal_ob_reward = True ... j = 512061  move = 30 @ 에피소드 # 29703\n","29703번째 에피소드까지 총 207번 finish 했습니다.\n","['G'] 종료: env.goal_ob_reward = True ... j = 513925  move = 67 @ 에피소드 # 29808\n","29808번째 에피소드까지 총 208번 finish 했습니다.\n","종료: done = True ... j = 514500  move = 7\n","epiode #: 29869 loss: 0.3300168514251709 j: 515000\n","종료: done = True ... j = 515200  move = 47\n","종료: done = True ... j = 516100  move = 30\n","종료: done = True ... j = 516700  move = 8\n","▶ 모델 저장됨!!! @ 에피소드 30000\n","종료: done = True ... j = 517500  move = 33\n","['D'] 종료: env.goal_ob_reward = True ... j = 518473  move = 33 @ 에피소드 # 30051\n","30051번째 에피소드까지 총 209번 finish 했습니다.\n","epiode #: 30134 loss: 0.34835052490234375 j: 520000\n","['D'] 종료: env.goal_ob_reward = True ... j = 520001  move = 28 @ 에피소드 # 30134\n","30134번째 에피소드까지 총 210번 finish 했습니다.\n","['K'] 종료: env.goal_ob_reward = True ... j = 520474  move = 36 @ 에피소드 # 30164\n","30164번째 에피소드까지 총 211번 finish 했습니다.\n","종료: done = True ... j = 521100  move = 7\n","['A'] 종료: env.goal_ob_reward = True ... j = 521413  move = 97 @ 에피소드 # 30211\n","30211번째 에피소드까지 총 212번 finish 했습니다.\n","['E'] 종료: env.goal_ob_reward = True ... j = 521801  move = 35 @ 에피소드 # 30236\n","30236번째 에피소드까지 총 213번 finish 했습니다.\n","종료: done = True ... j = 522200  move = 10\n","['D'] 종료: env.goal_ob_reward = True ... j = 523276  move = 32 @ 에피소드 # 30309\n","30309번째 에피소드까지 총 214번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 523587  move = 36 @ 에피소드 # 30321\n","30321번째 에피소드까지 총 215번 finish 했습니다.\n","종료: done = True ... j = 523600  move = 8\n","['N'] 종료: env.goal_ob_reward = True ... j = 524287  move = 93 @ 에피소드 # 30362\n","30362번째 에피소드까지 총 216번 finish 했습니다.\n","종료: done = True ... j = 524700  move = 3\n","['D'] 종료: env.goal_ob_reward = True ... j = 524869  move = 24 @ 에피소드 # 30400\n","30400번째 에피소드까지 총 217번 finish 했습니다.\n","epiode #: 30411 loss: 0.25290173292160034 j: 525000\n","종료: done = True ... j = 528300  move = 20\n","['Q'] 종료: env.goal_ob_reward = True ... j = 528685  move = 46 @ 에피소드 # 30601\n","30601번째 에피소드까지 총 218번 finish 했습니다.\n","epiode #: 30676 loss: 0.4430275559425354 j: 530000\n","['P'] 종료: env.goal_ob_reward = True ... j = 530987  move = 22 @ 에피소드 # 30727\n","30727번째 에피소드까지 총 219번 finish 했습니다.\n","['J'] 종료: env.goal_ob_reward = True ... j = 531286  move = 64 @ 에피소드 # 30736\n","30736번째 에피소드까지 총 220번 finish 했습니다.\n","종료: done = True ... j = 532700  move = 5\n","종료: done = True ... j = 532900  move = 5\n","종료: done = True ... j = 534000  move = 3\n","['P'] 종료: env.goal_ob_reward = True ... j = 534911  move = 43 @ 에피소드 # 30925\n","30925번째 에피소드까지 총 221번 finish 했습니다.\n","epiode #: 30931 loss: 0.3302971124649048 j: 535000\n","['A'] 종료: env.goal_ob_reward = True ... j = 535051  move = 20 @ 에피소드 # 30934\n","30934번째 에피소드까지 총 222번 finish 했습니다.\n","['D'] 종료: env.goal_ob_reward = True ... j = 535123  move = 32 @ 에피소드 # 30940\n","30940번째 에피소드까지 총 223번 finish 했습니다.\n","['N'] 종료: env.goal_ob_reward = True ... j = 537431  move = 49 @ 에피소드 # 31059\n","31059번째 에피소드까지 총 224번 finish 했습니다.\n","['N'] 종료: env.goal_ob_reward = True ... j = 537735  move = 34 @ 에피소드 # 31070\n","31070번째 에피소드까지 총 225번 finish 했습니다.\n","종료: done = True ... j = 538400  move = 14\n","['P'] 종료: env.goal_ob_reward = True ... j = 538594  move = 31 @ 에피소드 # 31113\n","31113번째 에피소드까지 총 226번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 538973  move = 39 @ 에피소드 # 31128\n","31128번째 에피소드까지 총 227번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 539859  move = 45 @ 에피소드 # 31175\n","31175번째 에피소드까지 총 228번 finish 했습니다.\n","epiode #: 31181 loss: 0.41692930459976196 j: 540000\n","종료: done = True ... j = 540500  move = 7\n","['Q'] 종료: env.goal_ob_reward = True ... j = 541460  move = 18 @ 에피소드 # 31258\n","31258번째 에피소드까지 총 229번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 542373  move = 26 @ 에피소드 # 31314\n","31314번째 에피소드까지 총 230번 finish 했습니다.\n","종료: done = True ... j = 543100  move = 16\n","['Q'] 종료: env.goal_ob_reward = True ... j = 543555  move = 30 @ 에피소드 # 31370\n","31370번째 에피소드까지 총 231번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 544414  move = 18 @ 에피소드 # 31417\n","31417번째 에피소드까지 총 232번 finish 했습니다.\n","epiode #: 31446 loss: 0.34543704986572266 j: 545000\n","['I'] 종료: env.goal_ob_reward = True ... j = 545362  move = 26 @ 에피소드 # 31466\n","31466번째 에피소드까지 총 233번 finish 했습니다.\n","['D'] 종료: env.goal_ob_reward = True ... j = 546751  move = 32 @ 에피소드 # 31546\n","31546번째 에피소드까지 총 234번 finish 했습니다.\n","종료: done = True ... j = 547300  move = 7\n","['B'] 종료: env.goal_ob_reward = True ... j = 547970  move = 51 @ 에피소드 # 31611\n","31611번째 에피소드까지 총 235번 finish 했습니다.\n","종료: done = True ... j = 548400  move = 45\n","['Q'] 종료: env.goal_ob_reward = True ... j = 549510  move = 18 @ 에피소드 # 31683\n","31683번째 에피소드까지 총 236번 finish 했습니다.\n","epiode #: 31708 loss: 0.5836520791053772 j: 550000\n","['Q'] 종료: env.goal_ob_reward = True ... j = 550899  move = 36 @ 에피소드 # 31762\n","31762번째 에피소드까지 총 237번 finish 했습니다.\n","['I'] 종료: env.goal_ob_reward = True ... j = 551907  move = 55 @ 에피소드 # 31811\n","31811번째 에피소드까지 총 238번 finish 했습니다.\n","종료: done = True ... j = 552000  move = 67\n","종료: done = True ... j = 553900  move = 9\n","['F'] 종료: env.goal_ob_reward = True ... j = 554229  move = 39 @ 에피소드 # 31923\n","31923번째 에피소드까지 총 239번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 554786  move = 24 @ 에피소드 # 31962\n","31962번째 에피소드까지 총 240번 finish 했습니다.\n","epiode #: 31975 loss: 0.31906813383102417 j: 555000\n","['Q'] 종료: env.goal_ob_reward = True ... j = 555477  move = 26 @ 에피소드 # 32008\n","32008번째 에피소드까지 총 241번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 557459  move = 32 @ 에피소드 # 32101\n","32101번째 에피소드까지 총 242번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 558087  move = 32 @ 에피소드 # 32145\n","32145번째 에피소드까지 총 243번 finish 했습니다.\n","['H'] 종료: env.goal_ob_reward = True ... j = 558419  move = 28 @ 에피소드 # 32160\n","32160번째 에피소드까지 총 244번 finish 했습니다.\n","['E'] 종료: env.goal_ob_reward = True ... j = 559098  move = 60 @ 에피소드 # 32195\n","32195번째 에피소드까지 총 245번 finish 했습니다.\n","epiode #: 32241 loss: 0.38106685876846313 j: 560000\n","종료: done = True ... j = 560900  move = 8\n","['Q'] 종료: env.goal_ob_reward = True ... j = 562570  move = 22 @ 에피소드 # 32366\n","32366번째 에피소드까지 총 246번 finish 했습니다.\n","종료: done = True ... j = 562700  move = 12\n","['F'] 종료: env.goal_ob_reward = True ... j = 562783  move = 51 @ 에피소드 # 32374\n","32374번째 에피소드까지 총 247번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 562877  move = 30 @ 에피소드 # 32377\n","32377번째 에피소드까지 총 248번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 563802  move = 42 @ 에피소드 # 32426\n","32426번째 에피소드까지 총 249번 finish 했습니다.\n","epiode #: 32495 loss: 0.2931327223777771 j: 565000\n","['Q'] 종료: env.goal_ob_reward = True ... j = 569844  move = 40 @ 에피소드 # 32730\n","32730번째 에피소드까지 총 250번 finish 했습니다.\n","epiode #: 32740 loss: 0.42672964930534363 j: 570000\n","종료: done = True ... j = 570100  move = 5\n","['F'] 종료: env.goal_ob_reward = True ... j = 570648  move = 30 @ 에피소드 # 32772\n","32772번째 에피소드까지 총 251번 finish 했습니다.\n","['I'] 종료: env.goal_ob_reward = True ... j = 572270  move = 28 @ 에피소드 # 32846\n","32846번째 에피소드까지 총 252번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 574231  move = 20 @ 에피소드 # 32934\n","32934번째 에피소드까지 총 253번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 574557  move = 29 @ 에피소드 # 32948\n","32948번째 에피소드까지 총 254번 finish 했습니다.\n","epiode #: 32970 loss: 0.3342101275920868 j: 575000\n","종료: done = True ... j = 576700  move = 8\n","['I'] 종료: env.goal_ob_reward = True ... j = 577304  move = 40 @ 에피소드 # 33089\n","33089번째 에피소드까지 총 255번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 577345  move = 23 @ 에피소드 # 33093\n","33093번째 에피소드까지 총 256번 finish 했습니다.\n","종료: done = True ... j = 577500  move = 19\n","['N'] 종료: env.goal_ob_reward = True ... j = 579219  move = 27 @ 에피소드 # 33205\n","33205번째 에피소드까지 총 257번 finish 했습니다.\n","['J'] 종료: env.goal_ob_reward = True ... j = 579495  move = 32 @ 에피소드 # 33220\n","33220번째 에피소드까지 총 258번 finish 했습니다.\n","epiode #: 33255 loss: 0.6015241742134094 j: 580000\n","['Q'] 종료: env.goal_ob_reward = True ... j = 580223  move = 26 @ 에피소드 # 33267\n","33267번째 에피소드까지 총 259번 finish 했습니다.\n","['H'] 종료: env.goal_ob_reward = True ... j = 580354  move = 33 @ 에피소드 # 33275\n","33275번째 에피소드까지 총 260번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 581041  move = 22 @ 에피소드 # 33307\n","33307번째 에피소드까지 총 261번 finish 했습니다.\n","['H'] 종료: env.goal_ob_reward = True ... j = 582236  move = 40 @ 에피소드 # 33364\n","33364번째 에피소드까지 총 262번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 583240  move = 20 @ 에피소드 # 33421\n","33421번째 에피소드까지 총 263번 finish 했습니다.\n","['E'] 종료: env.goal_ob_reward = True ... j = 584057  move = 35 @ 에피소드 # 33471\n","33471번째 에피소드까지 총 264번 finish 했습니다.\n","종료: done = True ... j = 584700  move = 10\n","epiode #: 33516 loss: 0.49112647771835327 j: 585000\n","['G'] 종료: env.goal_ob_reward = True ... j = 585770  move = 26 @ 에피소드 # 33564\n","33564번째 에피소드까지 총 265번 finish 했습니다.\n","종료: done = True ... j = 587700  move = 5\n","종료: done = True ... j = 588800  move = 14\n","['B'] 종료: env.goal_ob_reward = True ... j = 589694  move = 18 @ 에피소드 # 33791\n","33791번째 에피소드까지 총 266번 finish 했습니다.\n","epiode #: 33810 loss: 0.4046657979488373 j: 590000\n","['C'] 종료: env.goal_ob_reward = True ... j = 590370  move = 22 @ 에피소드 # 33834\n","33834번째 에피소드까지 총 267번 finish 했습니다.\n","종료: done = True ... j = 590600  move = 22\n","종료: done = True ... j = 591200  move = 45\n","['Q'] 종료: env.goal_ob_reward = True ... j = 591226  move = 26 @ 에피소드 # 33872\n","33872번째 에피소드까지 총 268번 finish 했습니다.\n","['N'] 종료: env.goal_ob_reward = True ... j = 591438  move = 22 @ 에피소드 # 33882\n","33882번째 에피소드까지 총 269번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 592481  move = 36 @ 에피소드 # 33926\n","33926번째 에피소드까지 총 270번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 592707  move = 18 @ 에피소드 # 33941\n","33941번째 에피소드까지 총 271번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 592789  move = 60 @ 에피소드 # 33944\n","33944번째 에피소드까지 총 272번 finish 했습니다.\n","종료: done = True ... j = 593100  move = 13\n","종료: done = True ... j = 594700  move = 19\n","epiode #: 34065 loss: 0.3871292471885681 j: 595000\n","종료: done = True ... j = 595000  move = 23\n","['F'] 종료: env.goal_ob_reward = True ... j = 595344  move = 66 @ 에피소드 # 34077\n","34077번째 에피소드까지 총 273번 finish 했습니다.\n","['G'] 종료: env.goal_ob_reward = True ... j = 595708  move = 30 @ 에피소드 # 34098\n","34098번째 에피소드까지 총 274번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 595894  move = 24 @ 에피소드 # 34108\n","34108번째 에피소드까지 총 275번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 597270  move = 28 @ 에피소드 # 34188\n","34188번째 에피소드까지 총 276번 finish 했습니다.\n","종료: done = True ... j = 597400  move = 6\n","['A'] 종료: env.goal_ob_reward = True ... j = 598450  move = 61 @ 에피소드 # 34239\n","34239번째 에피소드까지 총 277번 finish 했습니다.\n","['C'] 종료: env.goal_ob_reward = True ... j = 599330  move = 43 @ 에피소드 # 34286\n","34286번째 에피소드까지 총 278번 finish 했습니다.\n","epiode #: 34318 loss: 0.24965351819992065 j: 600000\n","종료: done = True ... j = 600100  move = 38\n","['C'] 종료: env.goal_ob_reward = True ... j = 601224  move = 54 @ 에피소드 # 34378\n","34378번째 에피소드까지 총 279번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 601708  move = 52 @ 에피소드 # 34399\n","34399번째 에피소드까지 총 280번 finish 했습니다.\n","종료: done = True ... j = 603100  move = 14\n","epiode #: 34598 loss: 0.3745012581348419 j: 605000\n","['P'] 종료: env.goal_ob_reward = True ... j = 605663  move = 58 @ 에피소드 # 34630\n","34630번째 에피소드까지 총 281번 finish 했습니다.\n","종료: done = True ... j = 606800  move = 22\n","종료: done = True ... j = 607200  move = 5\n","['Q'] 종료: env.goal_ob_reward = True ... j = 607256  move = 20 @ 에피소드 # 34718\n","34718번째 에피소드까지 총 282번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 607395  move = 51 @ 에피소드 # 34722\n","34722번째 에피소드까지 총 283번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 608361  move = 31 @ 에피소드 # 34773\n","34773번째 에피소드까지 총 284번 finish 했습니다.\n","epiode #: 34850 loss: 0.19998842477798462 j: 610000\n","['Q'] 종료: env.goal_ob_reward = True ... j = 612115  move = 18 @ 에피소드 # 34967\n","34967번째 에피소드까지 총 285번 finish 했습니다.\n","['C'] 종료: env.goal_ob_reward = True ... j = 612747  move = 31 @ 에피소드 # 35000\n","35000번째 에피소드까지 총 286번 finish 했습니다.\n","종료: done = True ... j = 614200  move = 18\n","['P'] 종료: env.goal_ob_reward = True ... j = 614522  move = 56 @ 에피소드 # 35091\n","35091번째 에피소드까지 총 287번 finish 했습니다.\n","epiode #: 35116 loss: 0.34103667736053467 j: 615000\n","['L'] 종료: env.goal_ob_reward = True ... j = 615096  move = 57 @ 에피소드 # 35118\n","35118번째 에피소드까지 총 288번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 616374  move = 34 @ 에피소드 # 35189\n","35189번째 에피소드까지 총 289번 finish 했습니다.\n","종료: done = True ... j = 617200  move = 35\n","['Q'] 종료: env.goal_ob_reward = True ... j = 617771  move = 40 @ 에피소드 # 35281\n","35281번째 에피소드까지 총 290번 finish 했습니다.\n","['G'] 종료: env.goal_ob_reward = True ... j = 618118  move = 30 @ 에피소드 # 35300\n","35300번째 에피소드까지 총 291번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 618915  move = 27 @ 에피소드 # 35339\n","35339번째 에피소드까지 총 292번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 618945  move = 27 @ 에피소드 # 35341\n","35341번째 에피소드까지 총 293번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 619335  move = 30 @ 에피소드 # 35370\n","35370번째 에피소드까지 총 294번 finish 했습니다.\n","['G'] 종료: env.goal_ob_reward = True ... j = 619570  move = 72 @ 에피소드 # 35378\n","35378번째 에피소드까지 총 295번 finish 했습니다.\n","종료: done = True ... j = 619600  move = 7\n","epiode #: 35409 loss: 0.2969578206539154 j: 620000\n","종료: done = True ... j = 620900  move = 13\n","['P'] 종료: env.goal_ob_reward = True ... j = 620989  move = 40 @ 에피소드 # 35466\n","35466번째 에피소드까지 총 296번 finish 했습니다.\n","종료: done = True ... j = 621600  move = 10\n","종료: done = True ... j = 622600  move = 3\n","종료: done = True ... j = 622900  move = 10\n","종료: done = True ... j = 624000  move = 60\n","종료: done = True ... j = 624400  move = 7\n","['D'] 종료: env.goal_ob_reward = True ... j = 624685  move = 38 @ 에피소드 # 35666\n","35666번째 에피소드까지 총 297번 finish 했습니다.\n","['G'] 종료: env.goal_ob_reward = True ... j = 624916  move = 40 @ 에피소드 # 35678\n","35678번째 에피소드까지 총 298번 finish 했습니다.\n","epiode #: 35684 loss: 0.2096656709909439 j: 625000\n","종료: done = True ... j = 625300  move = 16\n","종료: done = True ... j = 625800  move = 21\n","종료: done = True ... j = 626000  move = 13\n","['O'] 종료: env.goal_ob_reward = True ... j = 626691  move = 57 @ 에피소드 # 35779\n","35779번째 에피소드까지 총 299번 finish 했습니다.\n","종료: done = True ... j = 627200  move = 29\n","['C'] 종료: env.goal_ob_reward = True ... j = 627738  move = 28 @ 에피소드 # 35837\n","35837번째 에피소드까지 총 300번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 628060  move = 78 @ 에피소드 # 35855\n","35855번째 에피소드까지 총 301번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 628389  move = 49 @ 에피소드 # 35868\n","35868번째 에피소드까지 총 302번 finish 했습니다.\n","['K'] 종료: env.goal_ob_reward = True ... j = 628597  move = 34 @ 에피소드 # 35877\n","35877번째 에피소드까지 총 303번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 628783  move = 51 @ 에피소드 # 35886\n","35886번째 에피소드까지 총 304번 finish 했습니다.\n","종료: done = True ... j = 629100  move = 8\n","epiode #: 35953 loss: 0.3728818893432617 j: 630000\n","['J'] 종료: env.goal_ob_reward = True ... j = 633643  move = 41 @ 에피소드 # 36139\n","36139번째 에피소드까지 총 305번 finish 했습니다.\n","종료: done = True ... j = 634500  move = 29\n","종료: done = True ... j = 634600  move = 7\n","['K'] 종료: env.goal_ob_reward = True ... j = 634874  move = 36 @ 에피소드 # 36206\n","36206번째 에피소드까지 총 306번 finish 했습니다.\n","epiode #: 36212 loss: 0.5339540839195251 j: 635000\n","['O'] 종료: env.goal_ob_reward = True ... j = 635186  move = 38 @ 에피소드 # 36222\n","36222번째 에피소드까지 총 307번 finish 했습니다.\n","종료: done = True ... j = 635400  move = 3\n","['P'] 종료: env.goal_ob_reward = True ... j = 635968  move = 35 @ 에피소드 # 36262\n","36262번째 에피소드까지 총 308번 finish 했습니다.\n","종료: done = True ... j = 637100  move = 18\n","['H'] 종료: env.goal_ob_reward = True ... j = 637665  move = 33 @ 에피소드 # 36356\n","36356번째 에피소드까지 총 309번 finish 했습니다.\n","['N'] 종료: env.goal_ob_reward = True ... j = 638485  move = 38 @ 에피소드 # 36400\n","36400번째 에피소드까지 총 310번 finish 했습니다.\n","['K'] 종료: env.goal_ob_reward = True ... j = 638786  move = 28 @ 에피소드 # 36418\n","36418번째 에피소드까지 총 311번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 639076  move = 16 @ 에피소드 # 36432\n","36432번째 에피소드까지 총 312번 finish 했습니다.\n","['N'] 종료: env.goal_ob_reward = True ... j = 639577  move = 24 @ 에피소드 # 36461\n","36461번째 에피소드까지 총 313번 finish 했습니다.\n","epiode #: 36482 loss: 0.4969361126422882 j: 640000\n","종료: done = True ... j = 641200  move = 22\n","['Q'] 종료: env.goal_ob_reward = True ... j = 641397  move = 26 @ 에피소드 # 36555\n","36555번째 에피소드까지 총 314번 finish 했습니다.\n","epiode #: 36743 loss: 0.3549341857433319 j: 645000\n","['O'] 종료: env.goal_ob_reward = True ... j = 645304  move = 22 @ 에피소드 # 36755\n","36755번째 에피소드까지 총 315번 finish 했습니다.\n","['J'] 종료: env.goal_ob_reward = True ... j = 645490  move = 26 @ 에피소드 # 36764\n","36764번째 에피소드까지 총 316번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 645659  move = 20 @ 에피소드 # 36770\n","36770번째 에피소드까지 총 317번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 645954  move = 18 @ 에피소드 # 36787\n","36787번째 에피소드까지 총 318번 finish 했습니다.\n","종료: done = True ... j = 646300  move = 26\n","['A'] 종료: env.goal_ob_reward = True ... j = 646667  move = 42 @ 에피소드 # 36827\n","36827번째 에피소드까지 총 319번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 646818  move = 26 @ 에피소드 # 36836\n","36836번째 에피소드까지 총 320번 finish 했습니다.\n","종료: done = True ... j = 646900  move = 6\n","['A'] 종료: env.goal_ob_reward = True ... j = 647818  move = 24 @ 에피소드 # 36885\n","36885번째 에피소드까지 총 321번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 647877  move = 18 @ 에피소드 # 36889\n","36889번째 에피소드까지 총 322번 finish 했습니다.\n","종료: done = True ... j = 648300  move = 9\n","종료: done = True ... j = 648900  move = 4\n","['A'] 종료: env.goal_ob_reward = True ... j = 649173  move = 52 @ 에피소드 # 36954\n","36954번째 에피소드까지 총 323번 finish 했습니다.\n","epiode #: 37004 loss: 0.1761990189552307 j: 650000\n","종료: done = True ... j = 653700  move = 7\n","종료: done = True ... j = 653800  move = 5\n","epiode #: 37282 loss: 0.5788411498069763 j: 655000\n","['A'] 종료: env.goal_ob_reward = True ... j = 655170  move = 36 @ 에피소드 # 37294\n","37294번째 에피소드까지 총 324번 finish 했습니다.\n","['H'] 종료: env.goal_ob_reward = True ... j = 658665  move = 50 @ 에피소드 # 37466\n","37466번째 에피소드까지 총 325번 finish 했습니다.\n","종료: done = True ... j = 659000  move = 8\n","epiode #: 37528 loss: 0.4198044240474701 j: 660000\n","['G'] 종료: env.goal_ob_reward = True ... j = 660160  move = 29 @ 에피소드 # 37533\n","37533번째 에피소드까지 총 326번 finish 했습니다.\n","['E'] 종료: env.goal_ob_reward = True ... j = 660469  move = 27 @ 에피소드 # 37558\n","37558번째 에피소드까지 총 327번 finish 했습니다.\n","종료: done = True ... j = 661000  move = 7\n","종료: done = True ... j = 661500  move = 10\n","['O'] 종료: env.goal_ob_reward = True ... j = 662462  move = 30 @ 에피소드 # 37674\n","37674번째 에피소드까지 총 328번 finish 했습니다.\n","epiode #: 37819 loss: 0.3125660717487335 j: 665000\n","종료: done = True ... j = 665000  move = 11\n","['O'] 종료: env.goal_ob_reward = True ... j = 665256  move = 31 @ 에피소드 # 37830\n","37830번째 에피소드까지 총 329번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 665401  move = 54 @ 에피소드 # 37835\n","37835번째 에피소드까지 총 330번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 665790  move = 22 @ 에피소드 # 37851\n","37851번째 에피소드까지 총 331번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 667142  move = 24 @ 에피소드 # 37913\n","37913번째 에피소드까지 총 332번 finish 했습니다.\n","['N'] 종료: env.goal_ob_reward = True ... j = 668418  move = 44 @ 에피소드 # 37991\n","37991번째 에피소드까지 총 333번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 669139  move = 80 @ 에피소드 # 38022\n","38022번째 에피소드까지 총 334번 finish 했습니다.\n","['F'] 종료: env.goal_ob_reward = True ... j = 669459  move = 48 @ 에피소드 # 38030\n","38030번째 에피소드까지 총 335번 finish 했습니다.\n","epiode #: 38053 loss: 0.5121020078659058 j: 670000\n","['L'] 종료: env.goal_ob_reward = True ... j = 671032  move = 67 @ 에피소드 # 38109\n","38109번째 에피소드까지 총 336번 finish 했습니다.\n","['I'] 종료: env.goal_ob_reward = True ... j = 672027  move = 34 @ 에피소드 # 38172\n","38172번째 에피소드까지 총 337번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 672117  move = 66 @ 에피소드 # 38178\n","38178번째 에피소드까지 총 338번 finish 했습니다.\n","종료: done = True ... j = 672600  move = 7\n","['Q'] 종료: env.goal_ob_reward = True ... j = 672941  move = 32 @ 에피소드 # 38231\n","38231번째 에피소드까지 총 339번 finish 했습니다.\n","epiode #: 38349 loss: 0.3680707514286041 j: 675000\n","['E'] 종료: env.goal_ob_reward = True ... j = 676701  move = 98 @ 에피소드 # 38427\n","38427번째 에피소드까지 총 340번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 677279  move = 26 @ 에피소드 # 38456\n","38456번째 에피소드까지 총 341번 finish 했습니다.\n","종료: done = True ... j = 677800  move = 21\n","종료: done = True ... j = 678200  move = 25\n","['C'] 종료: env.goal_ob_reward = True ... j = 678666  move = 22 @ 에피소드 # 38528\n","38528번째 에피소드까지 총 342번 finish 했습니다.\n","종료: done = True ... j = 678900  move = 6\n","epiode #: 38594 loss: 0.3638085424900055 j: 680000\n","['O'] 종료: env.goal_ob_reward = True ... j = 682227  move = 38 @ 에피소드 # 38692\n","38692번째 에피소드까지 총 343번 finish 했습니다.\n","종료: done = True ... j = 682400  move = 26\n","['Q'] 종료: env.goal_ob_reward = True ... j = 682899  move = 30 @ 에피소드 # 38725\n","38725번째 에피소드까지 총 344번 finish 했습니다.\n","종료: done = True ... j = 683000  move = 3\n","['O'] 종료: env.goal_ob_reward = True ... j = 684238  move = 31 @ 에피소드 # 38793\n","38793번째 에피소드까지 총 345번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 684353  move = 30 @ 에피소드 # 38801\n","38801번째 에피소드까지 총 346번 finish 했습니다.\n","종료: done = True ... j = 684600  move = 6\n","epiode #: 38835 loss: 0.5586159825325012 j: 685000\n","['A'] 종료: env.goal_ob_reward = True ... j = 686027  move = 20 @ 에피소드 # 38888\n","38888번째 에피소드까지 총 347번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 686425  move = 59 @ 에피소드 # 38910\n","38910번째 에피소드까지 총 348번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 686941  move = 58 @ 에피소드 # 38944\n","38944번째 에피소드까지 총 349번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 687652  move = 54 @ 에피소드 # 38976\n","38976번째 에피소드까지 총 350번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 687916  move = 24 @ 에피소드 # 38986\n","38986번째 에피소드까지 총 351번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 688468  move = 30 @ 에피소드 # 39017\n","39017번째 에피소드까지 총 352번 finish 했습니다.\n","종료: done = True ... j = 688700  move = 46\n","['Q'] 종료: env.goal_ob_reward = True ... j = 688700  move = 46 @ 에피소드 # 39028\n","39028번째 에피소드까지 총 353번 finish 했습니다.\n","['F'] 종료: env.goal_ob_reward = True ... j = 689465  move = 48 @ 에피소드 # 39075\n","39075번째 에피소드까지 총 354번 finish 했습니다.\n","['D'] 종료: env.goal_ob_reward = True ... j = 689735  move = 33 @ 에피소드 # 39089\n","39089번째 에피소드까지 총 355번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 689921  move = 33 @ 에피소드 # 39099\n","39099번째 에피소드까지 총 356번 finish 했습니다.\n","epiode #: 39104 loss: 0.36823171377182007 j: 690000\n","['B'] 종료: env.goal_ob_reward = True ... j = 691233  move = 18 @ 에피소드 # 39173\n","39173번째 에피소드까지 총 357번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 691492  move = 24 @ 에피소드 # 39187\n","39187번째 에피소드까지 총 358번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 693327  move = 32 @ 에피소드 # 39279\n","39279번째 에피소드까지 총 359번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 694083  move = 53 @ 에피소드 # 39322\n","39322번째 에피소드까지 총 360번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 694564  move = 31 @ 에피소드 # 39351\n","39351번째 에피소드까지 총 361번 finish 했습니다.\n","['N'] 종료: env.goal_ob_reward = True ... j = 694641  move = 38 @ 에피소드 # 39354\n","39354번째 에피소드까지 총 362번 finish 했습니다.\n","epiode #: 39372 loss: 0.42535653710365295 j: 695000\n","['H'] 종료: env.goal_ob_reward = True ... j = 695527  move = 28 @ 에피소드 # 39385\n","39385번째 에피소드까지 총 363번 finish 했습니다.\n","['I'] 종료: env.goal_ob_reward = True ... j = 696689  move = 70 @ 에피소드 # 39443\n","39443번째 에피소드까지 총 364번 finish 했습니다.\n","종료: done = True ... j = 697200  move = 11\n","['M'] 종료: env.goal_ob_reward = True ... j = 697577  move = 47 @ 에피소드 # 39491\n","39491번째 에피소드까지 총 365번 finish 했습니다.\n","종료: done = True ... j = 697600  move = 23\n","종료: done = True ... j = 698100  move = 65\n","['D'] 종료: env.goal_ob_reward = True ... j = 698545  move = 25 @ 에피소드 # 39547\n","39547번째 에피소드까지 총 366번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 698691  move = 16 @ 에피소드 # 39556\n","39556번째 에피소드까지 총 367번 finish 했습니다.\n","종료: done = True ... j = 699100  move = 82\n","['O'] 종료: env.goal_ob_reward = True ... j = 699100  move = 82 @ 에피소드 # 39584\n","39584번째 에피소드까지 총 368번 finish 했습니다.\n","epiode #: 39645 loss: 0.5266405940055847 j: 700000\n","['P'] 종료: env.goal_ob_reward = True ... j = 700533  move = 36 @ 에피소드 # 39684\n","39684번째 에피소드까지 총 369번 finish 했습니다.\n","['M'] 종료: env.goal_ob_reward = True ... j = 700612  move = 79 @ 에피소드 # 39685\n","39685번째 에피소드까지 총 370번 finish 했습니다.\n","종료: done = True ... j = 701500  move = 31\n","종료: done = True ... j = 702000  move = 5\n","종료: done = True ... j = 702200  move = 15\n","['C'] 종료: env.goal_ob_reward = True ... j = 702642  move = 50 @ 에피소드 # 39788\n","39788번째 에피소드까지 총 371번 finish 했습니다.\n","['I'] 종료: env.goal_ob_reward = True ... j = 702968  move = 32 @ 에피소드 # 39809\n","39809번째 에피소드까지 총 372번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 703257  move = 34 @ 에피소드 # 39822\n","39822번째 에피소드까지 총 373번 finish 했습니다.\n","epiode #: 39916 loss: 0.5521215796470642 j: 705000\n","['L'] 종료: env.goal_ob_reward = True ... j = 705436  move = 24 @ 에피소드 # 39939\n","39939번째 에피소드까지 총 374번 finish 했습니다.\n","▶ 모델 저장됨!!! @ 에피소드 40000\n","종료: done = True ... j = 707600  move = 7\n","['C'] 종료: env.goal_ob_reward = True ... j = 707673  move = 54 @ 에피소드 # 40052\n","40052번째 에피소드까지 총 375번 finish 했습니다.\n","['D'] 종료: env.goal_ob_reward = True ... j = 708359  move = 26 @ 에피소드 # 40090\n","40090번째 에피소드까지 총 376번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 708794  move = 43 @ 에피소드 # 40113\n","40113번째 에피소드까지 총 377번 finish 했습니다.\n","종료: done = True ... j = 709200  move = 5\n","epiode #: 40176 loss: 0.222941055893898 j: 710000\n","['M'] 종료: env.goal_ob_reward = True ... j = 710566  move = 79 @ 에피소드 # 40199\n","40199번째 에피소드까지 총 378번 finish 했습니다.\n","종료: done = True ... j = 711100  move = 14\n","종료: done = True ... j = 711400  move = 4\n","['A'] 종료: env.goal_ob_reward = True ... j = 711458  move = 40 @ 에피소드 # 40253\n","40253번째 에피소드까지 총 379번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 711653  move = 32 @ 에피소드 # 40266\n","40266번째 에피소드까지 총 380번 finish 했습니다.\n","['J'] 종료: env.goal_ob_reward = True ... j = 712337  move = 28 @ 에피소드 # 40304\n","40304번째 에피소드까지 총 381번 finish 했습니다.\n","['J'] 종료: env.goal_ob_reward = True ... j = 712395  move = 30 @ 에피소드 # 40308\n","40308번째 에피소드까지 총 382번 finish 했습니다.\n","['E'] 종료: env.goal_ob_reward = True ... j = 712824  move = 58 @ 에피소드 # 40330\n","40330번째 에피소드까지 총 383번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 712987  move = 36 @ 에피소드 # 40343\n","40343번째 에피소드까지 총 384번 finish 했습니다.\n","종료: done = True ... j = 713100  move = 7\n","종료: done = True ... j = 713300  move = 16\n","['A'] 종료: env.goal_ob_reward = True ... j = 713608  move = 18 @ 에피소드 # 40375\n","40375번째 에피소드까지 총 385번 finish 했습니다.\n","['C'] 종료: env.goal_ob_reward = True ... j = 713744  move = 88 @ 에피소드 # 40378\n","40378번째 에피소드까지 총 386번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 714488  move = 27 @ 에피소드 # 40419\n","40419번째 에피소드까지 총 387번 finish 했습니다.\n","epiode #: 40439 loss: 0.42692792415618896 j: 715000\n","['J'] 종료: env.goal_ob_reward = True ... j = 715125  move = 77 @ 에피소드 # 40441\n","40441번째 에피소드까지 총 388번 finish 했습니다.\n","['L'] 종료: env.goal_ob_reward = True ... j = 716059  move = 40 @ 에피소드 # 40505\n","40505번째 에피소드까지 총 389번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 716594  move = 18 @ 에피소드 # 40528\n","40528번째 에피소드까지 총 390번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 717744  move = 40 @ 에피소드 # 40585\n","40585번째 에피소드까지 총 391번 finish 했습니다.\n","종료: done = True ... j = 718200  move = 48\n","['K'] 종료: env.goal_ob_reward = True ... j = 718449  move = 32 @ 에피소드 # 40622\n","40622번째 에피소드까지 총 392번 finish 했습니다.\n","종료: done = True ... j = 719300  move = 8\n","epiode #: 40711 loss: 0.40038055181503296 j: 720000\n","종료: done = True ... j = 720000  move = 34\n","['A'] 종료: env.goal_ob_reward = True ... j = 720804  move = 30 @ 에피소드 # 40753\n","40753번째 에피소드까지 총 393번 finish 했습니다.\n","종료: done = True ... j = 722300  move = 5\n","['A'] 종료: env.goal_ob_reward = True ... j = 722956  move = 44 @ 에피소드 # 40883\n","40883번째 에피소드까지 총 394번 finish 했습니다.\n","['F'] 종료: env.goal_ob_reward = True ... j = 723977  move = 30 @ 에피소드 # 40933\n","40933번째 에피소드까지 총 395번 finish 했습니다.\n","epiode #: 40992 loss: 0.5584686398506165 j: 725000\n","종료: done = True ... j = 725600  move = 7\n","종료: done = True ... j = 727300  move = 8\n","['M'] 종료: env.goal_ob_reward = True ... j = 727559  move = 36 @ 에피소드 # 41137\n","41137번째 에피소드까지 총 396번 finish 했습니다.\n","['F'] 종료: env.goal_ob_reward = True ... j = 728910  move = 31 @ 에피소드 # 41218\n","41218번째 에피소드까지 총 397번 finish 했습니다.\n","epiode #: 41273 loss: 0.28431183099746704 j: 730000\n","['L'] 종료: env.goal_ob_reward = True ... j = 730080  move = 72 @ 에피소드 # 41275\n","41275번째 에피소드까지 총 398번 finish 했습니다.\n","['H'] 종료: env.goal_ob_reward = True ... j = 730449  move = 24 @ 에피소드 # 41297\n","41297번째 에피소드까지 총 399번 finish 했습니다.\n","종료: done = True ... j = 730700  move = 24\n","종료: done = True ... j = 731200  move = 4\n","종료: done = True ... j = 732600  move = 65\n","종료: done = True ... j = 732900  move = 21\n","종료: done = True ... j = 734400  move = 24\n","종료: done = True ... j = 734500  move = 3\n","['P'] 종료: env.goal_ob_reward = True ... j = 734551  move = 35 @ 에피소드 # 41529\n","41529번째 에피소드까지 총 400번 finish 했습니다.\n","epiode #: 41552 loss: 0.6124728918075562 j: 735000\n","['F'] 종료: env.goal_ob_reward = True ... j = 735025  move = 85 @ 에피소드 # 41552\n","41552번째 에피소드까지 총 401번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 735497  move = 47 @ 에피소드 # 41570\n","41570번째 에피소드까지 총 402번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 735922  move = 32 @ 에피소드 # 41586\n","41586번째 에피소드까지 총 403번 finish 했습니다.\n","종료: done = True ... j = 737000  move = 9\n","['H'] 종료: env.goal_ob_reward = True ... j = 737288  move = 28 @ 에피소드 # 41660\n","41660번째 에피소드까지 총 404번 finish 했습니다.\n","종료: done = True ... j = 737400  move = 47\n","['Q'] 종료: env.goal_ob_reward = True ... j = 738442  move = 80 @ 에피소드 # 41716\n","41716번째 에피소드까지 총 405번 finish 했습니다.\n","종료: done = True ... j = 738900  move = 23\n","['Q'] 종료: env.goal_ob_reward = True ... j = 739179  move = 24 @ 에피소드 # 41757\n","41757번째 에피소드까지 총 406번 finish 했습니다.\n","epiode #: 41802 loss: 0.35004723072052 j: 740000\n","['D'] 종료: env.goal_ob_reward = True ... j = 740013  move = 32 @ 에피소드 # 41802\n","41802번째 에피소드까지 총 407번 finish 했습니다.\n","종료: done = True ... j = 740300  move = 6\n","종료: done = True ... j = 740600  move = 10\n","['N'] 종료: env.goal_ob_reward = True ... j = 740945  move = 26 @ 에피소드 # 41862\n","41862번째 에피소드까지 총 408번 finish 했습니다.\n","종료: done = True ... j = 741100  move = 26\n","종료: done = True ... j = 741300  move = 7\n","['B'] 종료: env.goal_ob_reward = True ... j = 743581  move = 46 @ 에피소드 # 41990\n","41990번째 에피소드까지 총 409번 finish 했습니다.\n","['J'] 종료: env.goal_ob_reward = True ... j = 744513  move = 35 @ 에피소드 # 42036\n","42036번째 에피소드까지 총 410번 finish 했습니다.\n","epiode #: 42067 loss: 0.3526560068130493 j: 745000\n","['Q'] 종료: env.goal_ob_reward = True ... j = 745533  move = 38 @ 에피소드 # 42089\n","42089번째 에피소드까지 총 411번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 746015  move = 21 @ 에피소드 # 42118\n","42118번째 에피소드까지 총 412번 finish 했습니다.\n","종료: done = True ... j = 746100  move = 7\n","['B'] 종료: env.goal_ob_reward = True ... j = 746820  move = 75 @ 에피소드 # 42152\n","42152번째 에피소드까지 총 413번 finish 했습니다.\n","['N'] 종료: env.goal_ob_reward = True ... j = 748266  move = 31 @ 에피소드 # 42226\n","42226번째 에피소드까지 총 414번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 749241  move = 30 @ 에피소드 # 42294\n","42294번째 에피소드까지 총 415번 finish 했습니다.\n","epiode #: 42328 loss: 0.2947588860988617 j: 750000\n","['Q'] 종료: env.goal_ob_reward = True ... j = 751246  move = 22 @ 에피소드 # 42384\n","42384번째 에피소드까지 총 416번 finish 했습니다.\n","종료: done = True ... j = 751400  move = 10\n","종료: done = True ... j = 752400  move = 5\n","종료: done = True ... j = 753800  move = 9\n","epiode #: 42581 loss: 0.30308598279953003 j: 755000\n","['A'] 종료: env.goal_ob_reward = True ... j = 755319  move = 18 @ 에피소드 # 42602\n","42602번째 에피소드까지 총 417번 finish 했습니다.\n","['F'] 종료: env.goal_ob_reward = True ... j = 756339  move = 57 @ 에피소드 # 42647\n","42647번째 에피소드까지 총 418번 finish 했습니다.\n","['C'] 종료: env.goal_ob_reward = True ... j = 757663  move = 22 @ 에피소드 # 42715\n","42715번째 에피소드까지 총 419번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 758211  move = 30 @ 에피소드 # 42748\n","42748번째 에피소드까지 총 420번 finish 했습니다.\n","['C'] 종료: env.goal_ob_reward = True ... j = 758353  move = 30 @ 에피소드 # 42756\n","42756번째 에피소드까지 총 421번 finish 했습니다.\n","종료: done = True ... j = 759000  move = 7\n","epiode #: 42854 loss: 0.49243149161338806 j: 760000\n","['P'] 종료: env.goal_ob_reward = True ... j = 760613  move = 26 @ 에피소드 # 42881\n","42881번째 에피소드까지 총 422번 finish 했습니다.\n","['F'] 종료: env.goal_ob_reward = True ... j = 760833  move = 72 @ 에피소드 # 42892\n","42892번째 에피소드까지 총 423번 finish 했습니다.\n","종료: done = True ... j = 761000  move = 20\n","종료: done = True ... j = 762000  move = 12\n","종료: done = True ... j = 763000  move = 21\n","종료: done = True ... j = 763200  move = 43\n","['Q'] 종료: env.goal_ob_reward = True ... j = 764479  move = 46 @ 에피소드 # 43078\n","43078번째 에피소드까지 총 424번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 764733  move = 18 @ 에피소드 # 43102\n","43102번째 에피소드까지 총 425번 finish 했습니다.\n","epiode #: 43112 loss: 0.19349011778831482 j: 765000\n","['J'] 종료: env.goal_ob_reward = True ... j = 766257  move = 46 @ 에피소드 # 43180\n","43180번째 에피소드까지 총 426번 finish 했습니다.\n","['N'] 종료: env.goal_ob_reward = True ... j = 766489  move = 32 @ 에피소드 # 43189\n","43189번째 에피소드까지 총 427번 finish 했습니다.\n","['E'] 종료: env.goal_ob_reward = True ... j = 766851  move = 35 @ 에피소드 # 43203\n","43203번째 에피소드까지 총 428번 finish 했습니다.\n","종료: done = True ... j = 767100  move = 26\n","['M'] 종료: env.goal_ob_reward = True ... j = 767176  move = 32 @ 에피소드 # 43222\n","43222번째 에피소드까지 총 429번 finish 했습니다.\n","['N'] 종료: env.goal_ob_reward = True ... j = 768377  move = 30 @ 에피소드 # 43283\n","43283번째 에피소드까지 총 430번 finish 했습니다.\n","['K'] 종료: env.goal_ob_reward = True ... j = 768422  move = 26 @ 에피소드 # 43287\n","43287번째 에피소드까지 총 431번 finish 했습니다.\n","['I'] 종료: env.goal_ob_reward = True ... j = 768924  move = 42 @ 에피소드 # 43314\n","43314번째 에피소드까지 총 432번 finish 했습니다.\n","epiode #: 43369 loss: 0.3078072667121887 j: 770000\n","종료: done = True ... j = 770200  move = 17\n","종료: done = True ... j = 770500  move = 10\n","['O'] 종료: env.goal_ob_reward = True ... j = 770834  move = 30 @ 에피소드 # 43416\n","43416번째 에피소드까지 총 433번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 771116  move = 48 @ 에피소드 # 43433\n","43433번째 에피소드까지 총 434번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 771418  move = 43 @ 에피소드 # 43441\n","43441번째 에피소드까지 총 435번 finish 했습니다.\n","종료: done = True ... j = 772000  move = 9\n","['Q'] 종료: env.goal_ob_reward = True ... j = 772624  move = 30 @ 에피소드 # 43519\n","43519번째 에피소드까지 총 436번 finish 했습니다.\n","['G'] 종료: env.goal_ob_reward = True ... j = 772922  move = 26 @ 에피소드 # 43541\n","43541번째 에피소드까지 총 437번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 773606  move = 28 @ 에피소드 # 43576\n","43576번째 에피소드까지 총 438번 finish 했습니다.\n","epiode #: 43642 loss: 0.363097608089447 j: 775000\n","['Q'] 종료: env.goal_ob_reward = True ... j = 775314  move = 16 @ 에피소드 # 43665\n","43665번째 에피소드까지 총 439번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 776938  move = 29 @ 에피소드 # 43756\n","43756번째 에피소드까지 총 440번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 777504  move = 20 @ 에피소드 # 43785\n","43785번째 에피소드까지 총 441번 finish 했습니다.\n","epiode #: 43912 loss: 0.2624984383583069 j: 780000\n","['Q'] 종료: env.goal_ob_reward = True ... j = 780148  move = 29 @ 에피소드 # 43915\n","43915번째 에피소드까지 총 442번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 781123  move = 20 @ 에피소드 # 43978\n","43978번째 에피소드까지 총 443번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 781490  move = 24 @ 에피소드 # 43990\n","43990번째 에피소드까지 총 444번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 782725  move = 46 @ 에피소드 # 44056\n","44056번째 에피소드까지 총 445번 finish 했습니다.\n","종료: done = True ... j = 783200  move = 14\n","['E'] 종료: env.goal_ob_reward = True ... j = 783638  move = 34 @ 에피소드 # 44091\n","44091번째 에피소드까지 총 446번 finish 했습니다.\n","종료: done = True ... j = 783700  move = 6\n","['J'] 종료: env.goal_ob_reward = True ... j = 783809  move = 30 @ 에피소드 # 44106\n","44106번째 에피소드까지 총 447번 finish 했습니다.\n","종료: done = True ... j = 783900  move = 5\n","종료: done = True ... j = 784400  move = 63\n","epiode #: 44166 loss: 0.3545464277267456 j: 785000\n","종료: done = True ... j = 785500  move = 29\n","['O'] 종료: env.goal_ob_reward = True ... j = 786112  move = 56 @ 에피소드 # 44215\n","44215번째 에피소드까지 총 448번 finish 했습니다.\n","['D'] 종료: env.goal_ob_reward = True ... j = 786241  move = 24 @ 에피소드 # 44225\n","44225번째 에피소드까지 총 449번 finish 했습니다.\n","종료: done = True ... j = 787800  move = 3\n","['Q'] 종료: env.goal_ob_reward = True ... j = 788625  move = 41 @ 에피소드 # 44348\n","44348번째 에피소드까지 총 450번 finish 했습니다.\n","종료: done = True ... j = 789000  move = 30\n","['Q'] 종료: env.goal_ob_reward = True ... j = 789494  move = 20 @ 에피소드 # 44383\n","44383번째 에피소드까지 총 451번 finish 했습니다.\n","epiode #: 44409 loss: 0.7473791241645813 j: 790000\n","['Q'] 종료: env.goal_ob_reward = True ... j = 790582  move = 26 @ 에피소드 # 44446\n","44446번째 에피소드까지 총 452번 finish 했습니다.\n","종료: done = True ... j = 791000  move = 26\n","['Q'] 종료: env.goal_ob_reward = True ... j = 791041  move = 22 @ 에피소드 # 44463\n","44463번째 에피소드까지 총 453번 finish 했습니다.\n","['G'] 종료: env.goal_ob_reward = True ... j = 792717  move = 65 @ 에피소드 # 44548\n","44548번째 에피소드까지 총 454번 finish 했습니다.\n","종료: done = True ... j = 794500  move = 11\n","epiode #: 44674 loss: 0.591442346572876 j: 795000\n","['D'] 종료: env.goal_ob_reward = True ... j = 795081  move = 30 @ 에피소드 # 44679\n","44679번째 에피소드까지 총 455번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 795707  move = 37 @ 에피소드 # 44709\n","44709번째 에피소드까지 총 456번 finish 했습니다.\n","['L'] 종료: env.goal_ob_reward = True ... j = 795813  move = 71 @ 에피소드 # 44711\n","44711번째 에피소드까지 총 457번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 796118  move = 16 @ 에피소드 # 44728\n","44728번째 에피소드까지 총 458번 finish 했습니다.\n","['C'] 종료: env.goal_ob_reward = True ... j = 796434  move = 42 @ 에피소드 # 44743\n","44743번째 에피소드까지 총 459번 finish 했습니다.\n","['D'] 종료: env.goal_ob_reward = True ... j = 796960  move = 29 @ 에피소드 # 44777\n","44777번째 에피소드까지 총 460번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 797206  move = 20 @ 에피소드 # 44794\n","44794번째 에피소드까지 총 461번 finish 했습니다.\n","종료: done = True ... j = 797300  move = 34\n","['D'] 종료: env.goal_ob_reward = True ... j = 797344  move = 26 @ 에피소드 # 44805\n","44805번째 에피소드까지 총 462번 finish 했습니다.\n","['G'] 종료: env.goal_ob_reward = True ... j = 798788  move = 54 @ 에피소드 # 44891\n","44891번째 에피소드까지 총 463번 finish 했습니다.\n","epiode #: 44962 loss: 0.41400572657585144 j: 800000\n","['G'] 종료: env.goal_ob_reward = True ... j = 801212  move = 42 @ 에피소드 # 45026\n","45026번째 에피소드까지 총 464번 finish 했습니다.\n","['D'] 종료: env.goal_ob_reward = True ... j = 801626  move = 32 @ 에피소드 # 45046\n","45046번째 에피소드까지 총 465번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 801650  move = 24 @ 에피소드 # 45047\n","45047번째 에피소드까지 총 466번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 802572  move = 30 @ 에피소드 # 45097\n","45097번째 에피소드까지 총 467번 finish 했습니다.\n","['C'] 종료: env.goal_ob_reward = True ... j = 802854  move = 37 @ 에피소드 # 45112\n","45112번째 에피소드까지 총 468번 finish 했습니다.\n","종료: done = True ... j = 803000  move = 7\n","['J'] 종료: env.goal_ob_reward = True ... j = 803152  move = 30 @ 에피소드 # 45123\n","45123번째 에피소드까지 총 469번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 803696  move = 40 @ 에피소드 # 45146\n","45146번째 에피소드까지 총 470번 finish 했습니다.\n","['G'] 종료: env.goal_ob_reward = True ... j = 804316  move = 36 @ 에피소드 # 45180\n","45180번째 에피소드까지 총 471번 finish 했습니다.\n","['D'] 종료: env.goal_ob_reward = True ... j = 804573  move = 32 @ 에피소드 # 45199\n","45199번째 에피소드까지 총 472번 finish 했습니다.\n","epiode #: 45225 loss: 0.44139227271080017 j: 805000\n","종료: done = True ... j = 807800  move = 7\n","['Q'] 종료: env.goal_ob_reward = True ... j = 808640  move = 26 @ 에피소드 # 45407\n","45407번째 에피소드까지 총 473번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 809016  move = 28 @ 에피소드 # 45426\n","45426번째 에피소드까지 총 474번 finish 했습니다.\n","종료: done = True ... j = 809200  move = 28\n","종료: done = True ... j = 809800  move = 93\n","종료: done = True ... j = 809900  move = 3\n","epiode #: 45491 loss: 0.44419974088668823 j: 810000\n","종료: done = True ... j = 810400  move = 25\n","종료: done = True ... j = 810500  move = 14\n","종료: done = True ... j = 810600  move = 8\n","['J'] 종료: env.goal_ob_reward = True ... j = 811326  move = 44 @ 에피소드 # 45567\n","45567번째 에피소드까지 총 475번 finish 했습니다.\n","종료: done = True ... j = 812900  move = 5\n","종료: done = True ... j = 813000  move = 26\n","종료: done = True ... j = 813900  move = 5\n","epiode #: 45749 loss: 0.391630083322525 j: 815000\n","['Q'] 종료: env.goal_ob_reward = True ... j = 815261  move = 72 @ 에피소드 # 45756\n","45756번째 에피소드까지 총 476번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 816294  move = 22 @ 에피소드 # 45826\n","45826번째 에피소드까지 총 477번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 816861  move = 29 @ 에피소드 # 45855\n","45855번째 에피소드까지 총 478번 finish 했습니다.\n","종료: done = True ... j = 817100  move = 22\n","['Q'] 종료: env.goal_ob_reward = True ... j = 818357  move = 22 @ 에피소드 # 45940\n","45940번째 에피소드까지 총 479번 finish 했습니다.\n","['M'] 종료: env.goal_ob_reward = True ... j = 818524  move = 43 @ 에피소드 # 45948\n","45948번째 에피소드까지 총 480번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 819230  move = 56 @ 에피소드 # 45995\n","45995번째 에피소드까지 총 481번 finish 했습니다.\n","종료: done = True ... j = 819300  move = 3\n","['C'] 종료: env.goal_ob_reward = True ... j = 819581  move = 60 @ 에피소드 # 46013\n","46013번째 에피소드까지 총 482번 finish 했습니다.\n","epiode #: 46036 loss: 0.5067647099494934 j: 820000\n","['A'] 종료: env.goal_ob_reward = True ... j = 821521  move = 59 @ 에피소드 # 46102\n","46102번째 에피소드까지 총 483번 finish 했습니다.\n","['N'] 종료: env.goal_ob_reward = True ... j = 821702  move = 54 @ 에피소드 # 46112\n","46112번째 에피소드까지 총 484번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 822535  move = 28 @ 에피소드 # 46152\n","46152번째 에피소드까지 총 485번 finish 했습니다.\n","종료: done = True ... j = 822700  move = 21\n","['G'] 종료: env.goal_ob_reward = True ... j = 823621  move = 36 @ 에피소드 # 46211\n","46211번째 에피소드까지 총 486번 finish 했습니다.\n","['J'] 종료: env.goal_ob_reward = True ... j = 823685  move = 41 @ 에피소드 # 46215\n","46215번째 에피소드까지 총 487번 finish 했습니다.\n","['F'] 종료: env.goal_ob_reward = True ... j = 824547  move = 34 @ 에피소드 # 46257\n","46257번째 에피소드까지 총 488번 finish 했습니다.\n","['C'] 종료: env.goal_ob_reward = True ... j = 824682  move = 28 @ 에피소드 # 46266\n","46266번째 에피소드까지 총 489번 finish 했습니다.\n","epiode #: 46284 loss: 0.6024764180183411 j: 825000\n","종료: done = True ... j = 825400  move = 31\n","['Q'] 종료: env.goal_ob_reward = True ... j = 825741  move = 16 @ 에피소드 # 46323\n","46323번째 에피소드까지 총 490번 finish 했습니다.\n","['F'] 종료: env.goal_ob_reward = True ... j = 826898  move = 26 @ 에피소드 # 46381\n","46381번째 에피소드까지 총 491번 finish 했습니다.\n","종료: done = True ... j = 827000  move = 62\n","['F'] 종료: env.goal_ob_reward = True ... j = 827625  move = 32 @ 에피소드 # 46423\n","46423번째 에피소드까지 총 492번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 828459  move = 16 @ 에피소드 # 46463\n","46463번째 에피소드까지 총 493번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 828926  move = 22 @ 에피소드 # 46477\n","46477번째 에피소드까지 총 494번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 829652  move = 28 @ 에피소드 # 46512\n","46512번째 에피소드까지 총 495번 finish 했습니다.\n","epiode #: 46531 loss: 0.7632120251655579 j: 830000\n","['Q'] 종료: env.goal_ob_reward = True ... j = 831337  move = 22 @ 에피소드 # 46587\n","46587번째 에피소드까지 총 496번 finish 했습니다.\n","['D'] 종료: env.goal_ob_reward = True ... j = 831918  move = 32 @ 에피소드 # 46616\n","46616번째 에피소드까지 총 497번 finish 했습니다.\n","['H'] 종료: env.goal_ob_reward = True ... j = 832382  move = 30 @ 에피소드 # 46648\n","46648번째 에피소드까지 총 498번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 833234  move = 20 @ 에피소드 # 46691\n","46691번째 에피소드까지 총 499번 finish 했습니다.\n","['D'] 종료: env.goal_ob_reward = True ... j = 833653  move = 28 @ 에피소드 # 46715\n","46715번째 에피소드까지 총 500번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 833817  move = 34 @ 에피소드 # 46724\n","46724번째 에피소드까지 총 501번 finish 했습니다.\n","epiode #: 46783 loss: 0.6114531755447388 j: 835000\n","['A'] 종료: env.goal_ob_reward = True ... j = 835095  move = 26 @ 에피소드 # 46789\n","46789번째 에피소드까지 총 502번 finish 했습니다.\n","종료: done = True ... j = 835200  move = 26\n","['I'] 종료: env.goal_ob_reward = True ... j = 835200  move = 26 @ 에피소드 # 46792\n","46792번째 에피소드까지 총 503번 finish 했습니다.\n","['D'] 종료: env.goal_ob_reward = True ... j = 835307  move = 37 @ 에피소드 # 46798\n","46798번째 에피소드까지 총 504번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 835496  move = 56 @ 에피소드 # 46806\n","46806번째 에피소드까지 총 505번 finish 했습니다.\n","종료: done = True ... j = 836600  move = 4\n","['Q'] 종료: env.goal_ob_reward = True ... j = 838430  move = 18 @ 에피소드 # 46966\n","46966번째 에피소드까지 총 506번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 838957  move = 30 @ 에피소드 # 46991\n","46991번째 에피소드까지 총 507번 finish 했습니다.\n","epiode #: 47043 loss: 0.4632275402545929 j: 840000\n","['K'] 종료: env.goal_ob_reward = True ... j = 840107  move = 32 @ 에피소드 # 47047\n","47047번째 에피소드까지 총 508번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 840442  move = 22 @ 에피소드 # 47064\n","47064번째 에피소드까지 총 509번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 840919  move = 24 @ 에피소드 # 47083\n","47083번째 에피소드까지 총 510번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 841001  move = 20 @ 에피소드 # 47085\n","47085번째 에피소드까지 총 511번 finish 했습니다.\n","['L'] 종료: env.goal_ob_reward = True ... j = 841128  move = 31 @ 에피소드 # 47093\n","47093번째 에피소드까지 총 512번 finish 했습니다.\n","['K'] 종료: env.goal_ob_reward = True ... j = 842948  move = 34 @ 에피소드 # 47196\n","47196번째 에피소드까지 총 513번 finish 했습니다.\n","종료: done = True ... j = 843700  move = 28\n","['A'] 종료: env.goal_ob_reward = True ... j = 844583  move = 36 @ 에피소드 # 47271\n","47271번째 에피소드까지 총 514번 finish 했습니다.\n","['D'] 종료: env.goal_ob_reward = True ... j = 844676  move = 36 @ 에피소드 # 47277\n","47277번째 에피소드까지 총 515번 finish 했습니다.\n","종료: done = True ... j = 844800  move = 12\n","종료: done = True ... j = 844900  move = 5\n","epiode #: 47298 loss: 0.31431844830513 j: 845000\n","종료: done = True ... j = 845900  move = 35\n","종료: done = True ... j = 846100  move = 19\n","['C'] 종료: env.goal_ob_reward = True ... j = 846681  move = 26 @ 에피소드 # 47369\n","47369번째 에피소드까지 총 516번 finish 했습니다.\n","['K'] 종료: env.goal_ob_reward = True ... j = 847478  move = 43 @ 에피소드 # 47407\n","47407번째 에피소드까지 총 517번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 847713  move = 46 @ 에피소드 # 47415\n","47415번째 에피소드까지 총 518번 finish 했습니다.\n","epiode #: 47529 loss: 0.18451343476772308 j: 850000\n","종료: done = True ... j = 850300  move = 12\n","종료: done = True ... j = 850600  move = 29\n","['Q'] 종료: env.goal_ob_reward = True ... j = 852149  move = 43 @ 에피소드 # 47645\n","47645번째 에피소드까지 총 519번 finish 했습니다.\n","종료: done = True ... j = 853200  move = 44\n","['G'] 종료: env.goal_ob_reward = True ... j = 854109  move = 28 @ 에피소드 # 47761\n","47761번째 에피소드까지 총 520번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 854824  move = 58 @ 에피소드 # 47790\n","47790번째 에피소드까지 총 521번 finish 했습니다.\n","epiode #: 47799 loss: 0.49492761492729187 j: 855000\n","['Q'] 종료: env.goal_ob_reward = True ... j = 855577  move = 18 @ 에피소드 # 47836\n","47836번째 에피소드까지 총 522번 finish 했습니다.\n","['L'] 종료: env.goal_ob_reward = True ... j = 855616  move = 39 @ 에피소드 # 47837\n","47837번째 에피소드까지 총 523번 finish 했습니다.\n","종료: done = True ... j = 856900  move = 29\n","['F'] 종료: env.goal_ob_reward = True ... j = 857267  move = 52 @ 에피소드 # 47913\n","47913번째 에피소드까지 총 524번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 857575  move = 56 @ 에피소드 # 47928\n","47928번째 에피소드까지 총 525번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 857945  move = 34 @ 에피소드 # 47947\n","47947번째 에피소드까지 총 526번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 857967  move = 22 @ 에피소드 # 47948\n","47948번째 에피소드까지 총 527번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 859778  move = 16 @ 에피소드 # 48033\n","48033번째 에피소드까지 총 528번 finish 했습니다.\n","epiode #: 48042 loss: 0.2993706464767456 j: 860000\n","['H'] 종료: env.goal_ob_reward = True ... j = 860027  move = 56 @ 에피소드 # 48042\n","48042번째 에피소드까지 총 529번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 860047  move = 20 @ 에피소드 # 48043\n","48043번째 에피소드까지 총 530번 finish 했습니다.\n","종료: done = True ... j = 860300  move = 34\n","['O'] 종료: env.goal_ob_reward = True ... j = 860936  move = 28 @ 에피소드 # 48104\n","48104번째 에피소드까지 총 531번 finish 했습니다.\n","['D'] 종료: env.goal_ob_reward = True ... j = 861617  move = 33 @ 에피소드 # 48138\n","48138번째 에피소드까지 총 532번 finish 했습니다.\n","종료: done = True ... j = 863800  move = 66\n","['A'] 종료: env.goal_ob_reward = True ... j = 864010  move = 74 @ 에피소드 # 48258\n","48258번째 에피소드까지 총 533번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 864127  move = 30 @ 에피소드 # 48264\n","48264번째 에피소드까지 총 534번 finish 했습니다.\n","종료: done = True ... j = 864300  move = 10\n","['A'] 종료: env.goal_ob_reward = True ... j = 864720  move = 32 @ 에피소드 # 48299\n","48299번째 에피소드까지 총 535번 finish 했습니다.\n","epiode #: 48310 loss: 0.553291916847229 j: 865000\n","['O'] 종료: env.goal_ob_reward = True ... j = 865253  move = 43 @ 에피소드 # 48320\n","48320번째 에피소드까지 총 536번 finish 했습니다.\n","['I'] 종료: env.goal_ob_reward = True ... j = 866163  move = 46 @ 에피소드 # 48360\n","48360번째 에피소드까지 총 537번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 866329  move = 19 @ 에피소드 # 48369\n","48369번째 에피소드까지 총 538번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 866797  move = 28 @ 에피소드 # 48397\n","48397번째 에피소드까지 총 539번 finish 했습니다.\n","['N'] 종료: env.goal_ob_reward = True ... j = 868058  move = 27 @ 에피소드 # 48455\n","48455번째 에피소드까지 총 540번 finish 했습니다.\n","종료: done = True ... j = 868200  move = 19\n","epiode #: 48563 loss: 0.4366951584815979 j: 870000\n","종료: done = True ... j = 871900  move = 32\n","['O'] 종료: env.goal_ob_reward = True ... j = 872678  move = 34 @ 에피소드 # 48713\n","48713번째 에피소드까지 총 541번 finish 했습니다.\n","종료: done = True ... j = 872900  move = 4\n","['B'] 종료: env.goal_ob_reward = True ... j = 874972  move = 71 @ 에피소드 # 48836\n","48836번째 에피소드까지 총 542번 finish 했습니다.\n","epiode #: 48837 loss: 0.272342711687088 j: 875000\n","종료: done = True ... j = 875800  move = 88\n","['Q'] 종료: env.goal_ob_reward = True ... j = 875851  move = 22 @ 에피소드 # 48875\n","48875번째 에피소드까지 총 543번 finish 했습니다.\n","종료: done = True ... j = 876200  move = 7\n","['G'] 종료: env.goal_ob_reward = True ... j = 877003  move = 28 @ 에피소드 # 48941\n","48941번째 에피소드까지 총 544번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 878110  move = 16 @ 에피소드 # 48987\n","48987번째 에피소드까지 총 545번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 878473  move = 30 @ 에피소드 # 49007\n","49007번째 에피소드까지 총 546번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 879296  move = 56 @ 에피소드 # 49040\n","49040번째 에피소드까지 총 547번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 879939  move = 36 @ 에피소드 # 49082\n","49082번째 에피소드까지 총 548번 finish 했습니다.\n","epiode #: 49088 loss: 0.3682142496109009 j: 880000\n","종료: done = True ... j = 880100  move = 15\n","['M'] 종료: env.goal_ob_reward = True ... j = 881191  move = 51 @ 에피소드 # 49161\n","49161번째 에피소드까지 총 549번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 882359  move = 28 @ 에피소드 # 49218\n","49218번째 에피소드까지 총 550번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 882782  move = 58 @ 에피소드 # 49239\n","49239번째 에피소드까지 총 551번 finish 했습니다.\n","epiode #: 49355 loss: 0.40081268548965454 j: 885000\n","종료: done = True ... j = 885100  move = 7\n","종료: done = True ... j = 885600  move = 5\n","종료: done = True ... j = 886100  move = 3\n","['I'] 종료: env.goal_ob_reward = True ... j = 886124  move = 24 @ 에피소드 # 49412\n","49412번째 에피소드까지 총 552번 finish 했습니다.\n","종료: done = True ... j = 886400  move = 39\n","종료: done = True ... j = 888300  move = 8\n","['O'] 종료: env.goal_ob_reward = True ... j = 889874  move = 37 @ 에피소드 # 49623\n","49623번째 에피소드까지 총 553번 finish 했습니다.\n","종료: done = True ... j = 889900  move = 10\n","epiode #: 49633 loss: 0.5243685245513916 j: 890000\n","['I'] 종료: env.goal_ob_reward = True ... j = 890720  move = 24 @ 에피소드 # 49675\n","49675번째 에피소드까지 총 554번 finish 했습니다.\n","종료: done = True ... j = 892100  move = 9\n","종료: done = True ... j = 892500  move = 5\n","['J'] 종료: env.goal_ob_reward = True ... j = 892930  move = 38 @ 에피소드 # 49778\n","49778번째 에피소드까지 총 555번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 893167  move = 42 @ 에피소드 # 49793\n","49793번째 에피소드까지 총 556번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 893580  move = 27 @ 에피소드 # 49815\n","49815번째 에피소드까지 총 557번 finish 했습니다.\n","종료: done = True ... j = 894100  move = 7\n","epiode #: 49888 loss: 0.5167343616485596 j: 895000\n","['A'] 종료: env.goal_ob_reward = True ... j = 895017  move = 38 @ 에피소드 # 49888\n","49888번째 에피소드까지 총 558번 finish 했습니다.\n","종료: done = True ... j = 896700  move = 7\n","▶ 모델 저장됨!!! @ 에피소드 50000\n","['O'] 종료: env.goal_ob_reward = True ... j = 897114  move = 30 @ 에피소드 # 50002\n","50002번째 에피소드까지 총 559번 finish 했습니다.\n","종료: done = True ... j = 897300  move = 35\n","['E'] 종료: env.goal_ob_reward = True ... j = 897483  move = 55 @ 에피소드 # 50028\n","50028번째 에피소드까지 총 560번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 897548  move = 39 @ 에피소드 # 50030\n","50030번째 에피소드까지 총 561번 finish 했습니다.\n","['I'] 종료: env.goal_ob_reward = True ... j = 897829  move = 38 @ 에피소드 # 50045\n","50045번째 에피소드까지 총 562번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 898801  move = 54 @ 에피소드 # 50080\n","50080번째 에피소드까지 총 563번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 899518  move = 64 @ 에피소드 # 50127\n","50127번째 에피소드까지 총 564번 finish 했습니다.\n","['D'] 종료: env.goal_ob_reward = True ... j = 899904  move = 32 @ 에피소드 # 50145\n","50145번째 에피소드까지 총 565번 finish 했습니다.\n","epiode #: 50148 loss: 0.2248617559671402 j: 900000\n","['B'] 종료: env.goal_ob_reward = True ... j = 900492  move = 50 @ 에피소드 # 50170\n","50170번째 에피소드까지 총 566번 finish 했습니다.\n","종료: done = True ... j = 900500  move = 8\n","['C'] 종료: env.goal_ob_reward = True ... j = 900847  move = 57 @ 에피소드 # 50187\n","50187번째 에피소드까지 총 567번 finish 했습니다.\n","종료: done = True ... j = 901100  move = 5\n","종료: done = True ... j = 902200  move = 29\n","['M'] 종료: env.goal_ob_reward = True ... j = 903454  move = 39 @ 에피소드 # 50337\n","50337번째 에피소드까지 총 568번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 904254  move = 42 @ 에피소드 # 50372\n","50372번째 에피소드까지 총 569번 finish 했습니다.\n","종료: done = True ... j = 904300  move = 18\n","['O'] 종료: env.goal_ob_reward = True ... j = 904604  move = 30 @ 에피소드 # 50395\n","50395번째 에피소드까지 총 570번 finish 했습니다.\n","epiode #: 50418 loss: 0.5539630055427551 j: 905000\n","['N'] 종료: env.goal_ob_reward = True ... j = 905501  move = 59 @ 에피소드 # 50440\n","50440번째 에피소드까지 총 571번 finish 했습니다.\n","종료: done = True ... j = 906400  move = 31\n","종료: done = True ... j = 907000  move = 14\n","['H'] 종료: env.goal_ob_reward = True ... j = 907929  move = 32 @ 에피소드 # 50576\n","50576번째 에피소드까지 총 572번 finish 했습니다.\n","종료: done = True ... j = 908000  move = 31\n","['G'] 종료: env.goal_ob_reward = True ... j = 908680  move = 62 @ 에피소드 # 50617\n","50617번째 에피소드까지 총 573번 finish 했습니다.\n","['C'] 종료: env.goal_ob_reward = True ... j = 909320  move = 68 @ 에피소드 # 50643\n","50643번째 에피소드까지 총 574번 finish 했습니다.\n","종료: done = True ... j = 909600  move = 5\n","epiode #: 50672 loss: 0.5096397995948792 j: 910000\n","['J'] 종료: env.goal_ob_reward = True ... j = 910465  move = 36 @ 에피소드 # 50690\n","50690번째 에피소드까지 총 575번 finish 했습니다.\n","종료: done = True ... j = 911100  move = 18\n","['C'] 종료: env.goal_ob_reward = True ... j = 911434  move = 42 @ 에피소드 # 50729\n","50729번째 에피소드까지 총 576번 finish 했습니다.\n","['G'] 종료: env.goal_ob_reward = True ... j = 911858  move = 26 @ 에피소드 # 50748\n","50748번째 에피소드까지 총 577번 finish 했습니다.\n","['G'] 종료: env.goal_ob_reward = True ... j = 912812  move = 44 @ 에피소드 # 50806\n","50806번째 에피소드까지 총 578번 finish 했습니다.\n","종료: done = True ... j = 913800  move = 3\n","['O'] 종료: env.goal_ob_reward = True ... j = 914253  move = 31 @ 에피소드 # 50863\n","50863번째 에피소드까지 총 579번 finish 했습니다.\n","['D'] 종료: env.goal_ob_reward = True ... j = 914472  move = 32 @ 에피소드 # 50874\n","50874번째 에피소드까지 총 580번 finish 했습니다.\n","종료: done = True ... j = 914600  move = 41\n","epiode #: 50911 loss: 0.44251739978790283 j: 915000\n","종료: done = True ... j = 915200  move = 7\n","['G'] 종료: env.goal_ob_reward = True ... j = 916358  move = 77 @ 에피소드 # 50982\n","50982번째 에피소드까지 총 581번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 917687  move = 36 @ 에피소드 # 51049\n","51049번째 에피소드까지 총 582번 finish 했습니다.\n","종료: done = True ... j = 918300  move = 7\n","['K'] 종료: env.goal_ob_reward = True ... j = 918670  move = 34 @ 에피소드 # 51095\n","51095번째 에피소드까지 총 583번 finish 했습니다.\n","종료: done = True ... j = 918800  move = 9\n","['Q'] 종료: env.goal_ob_reward = True ... j = 919441  move = 40 @ 에피소드 # 51129\n","51129번째 에피소드까지 총 584번 finish 했습니다.\n","['E'] 종료: env.goal_ob_reward = True ... j = 919744  move = 78 @ 에피소드 # 51140\n","51140번째 에피소드까지 총 585번 finish 했습니다.\n","epiode #: 51151 loss: 0.293486088514328 j: 920000\n","['B'] 종료: env.goal_ob_reward = True ... j = 921031  move = 47 @ 에피소드 # 51211\n","51211번째 에피소드까지 총 586번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 921637  move = 36 @ 에피소드 # 51235\n","51235번째 에피소드까지 총 587번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 921865  move = 98 @ 에피소드 # 51241\n","51241번째 에피소드까지 총 588번 finish 했습니다.\n","['J'] 종료: env.goal_ob_reward = True ... j = 922333  move = 38 @ 에피소드 # 51267\n","51267번째 에피소드까지 총 589번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 922743  move = 18 @ 에피소드 # 51289\n","51289번째 에피소드까지 총 590번 finish 했습니다.\n","종료: done = True ... j = 922900  move = 69\n","['Q'] 종료: env.goal_ob_reward = True ... j = 923023  move = 54 @ 에피소드 # 51307\n","51307번째 에피소드까지 총 591번 finish 했습니다.\n","['D'] 종료: env.goal_ob_reward = True ... j = 924052  move = 50 @ 에피소드 # 51361\n","51361번째 에피소드까지 총 592번 finish 했습니다.\n","종료: done = True ... j = 924100  move = 9\n","epiode #: 51414 loss: 0.19440799951553345 j: 925000\n","종료: done = True ... j = 925100  move = 25\n","['A'] 종료: env.goal_ob_reward = True ... j = 926302  move = 24 @ 에피소드 # 51481\n","51481번째 에피소드까지 총 593번 finish 했습니다.\n","종료: done = True ... j = 926900  move = 21\n","종료: done = True ... j = 927200  move = 6\n","['A'] 종료: env.goal_ob_reward = True ... j = 928710  move = 20 @ 에피소드 # 51609\n","51609번째 에피소드까지 총 594번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 928785  move = 30 @ 에피소드 # 51612\n","51612번째 에피소드까지 총 595번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 929027  move = 33 @ 에피소드 # 51624\n","51624번째 에피소드까지 총 596번 finish 했습니다.\n","['L'] 종료: env.goal_ob_reward = True ... j = 929824  move = 40 @ 에피소드 # 51660\n","51660번째 에피소드까지 총 597번 finish 했습니다.\n","epiode #: 51669 loss: 0.3433992266654968 j: 930000\n","['Q'] 종료: env.goal_ob_reward = True ... j = 930835  move = 80 @ 에피소드 # 51718\n","51718번째 에피소드까지 총 598번 finish 했습니다.\n","종료: done = True ... j = 931300  move = 3\n","['D'] 종료: env.goal_ob_reward = True ... j = 931328  move = 28 @ 에피소드 # 51743\n","51743번째 에피소드까지 총 599번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 931365  move = 22 @ 에피소드 # 51746\n","51746번째 에피소드까지 총 600번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 931821  move = 24 @ 에피소드 # 51768\n","51768번째 에피소드까지 총 601번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 932095  move = 87 @ 에피소드 # 51777\n","51777번째 에피소드까지 총 602번 finish 했습니다.\n","종료: done = True ... j = 932300  move = 7\n","['A'] 종료: env.goal_ob_reward = True ... j = 933103  move = 30 @ 에피소드 # 51843\n","51843번째 에피소드까지 총 603번 finish 했습니다.\n","['C'] 종료: env.goal_ob_reward = True ... j = 933497  move = 36 @ 에피소드 # 51864\n","51864번째 에피소드까지 총 604번 finish 했습니다.\n","epiode #: 51940 loss: 0.557898223400116 j: 935000\n","종료: done = True ... j = 935500  move = 28\n","['B'] 종료: env.goal_ob_reward = True ... j = 935927  move = 42 @ 에피소드 # 51986\n","51986번째 에피소드까지 총 605번 finish 했습니다.\n","종료: done = True ... j = 936400  move = 3\n","['D'] 종료: env.goal_ob_reward = True ... j = 936872  move = 47 @ 에피소드 # 52044\n","52044번째 에피소드까지 총 606번 finish 했습니다.\n","종료: done = True ... j = 936900  move = 5\n","['Q'] 종료: env.goal_ob_reward = True ... j = 937040  move = 50 @ 에피소드 # 52053\n","52053번째 에피소드까지 총 607번 finish 했습니다.\n","종료: done = True ... j = 938800  move = 21\n","['F'] 종료: env.goal_ob_reward = True ... j = 939042  move = 39 @ 에피소드 # 52155\n","52155번째 에피소드까지 총 608번 finish 했습니다.\n","epiode #: 52207 loss: 0.4287627339363098 j: 940000\n","종료: done = True ... j = 940600  move = 3\n","종료: done = True ... j = 941300  move = 8\n","['D'] 종료: env.goal_ob_reward = True ... j = 942043  move = 83 @ 에피소드 # 52323\n","52323번째 에피소드까지 총 609번 finish 했습니다.\n","종료: done = True ... j = 942700  move = 16\n","['N'] 종료: env.goal_ob_reward = True ... j = 943345  move = 27 @ 에피소드 # 52404\n","52404번째 에피소드까지 총 610번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 943420  move = 61 @ 에피소드 # 52406\n","52406번째 에피소드까지 총 611번 finish 했습니다.\n","['H'] 종료: env.goal_ob_reward = True ... j = 943911  move = 39 @ 에피소드 # 52430\n","52430번째 에피소드까지 총 612번 finish 했습니다.\n","['E'] 종료: env.goal_ob_reward = True ... j = 944042  move = 44 @ 에피소드 # 52438\n","52438번째 에피소드까지 총 613번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 944105  move = 18 @ 에피소드 # 52443\n","52443번째 에피소드까지 총 614번 finish 했습니다.\n","종료: done = True ... j = 944200  move = 8\n","epiode #: 52495 loss: 0.2864302694797516 j: 945000\n","종료: done = True ... j = 945000  move = 19\n","종료: done = True ... j = 946300  move = 56\n","['O'] 종료: env.goal_ob_reward = True ... j = 946582  move = 32 @ 에피소드 # 52584\n","52584번째 에피소드까지 총 615번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 946763  move = 31 @ 에피소드 # 52592\n","52592번째 에피소드까지 총 616번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 946979  move = 38 @ 에피소드 # 52606\n","52606번째 에피소드까지 총 617번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 947096  move = 36 @ 에피소드 # 52616\n","52616번째 에피소드까지 총 618번 finish 했습니다.\n","종료: done = True ... j = 947600  move = 31\n","종료: done = True ... j = 948500  move = 6\n","['A'] 종료: env.goal_ob_reward = True ... j = 949782  move = 50 @ 에피소드 # 52764\n","52764번째 에피소드까지 총 619번 finish 했습니다.\n","epiode #: 52773 loss: 0.540529727935791 j: 950000\n","['D'] 종료: env.goal_ob_reward = True ... j = 950184  move = 55 @ 에피소드 # 52781\n","52781번째 에피소드까지 총 620번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 951515  move = 42 @ 에피소드 # 52842\n","52842번째 에피소드까지 총 621번 finish 했습니다.\n","['J'] 종료: env.goal_ob_reward = True ... j = 951712  move = 26 @ 에피소드 # 52861\n","52861번째 에피소드까지 총 622번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 952658  move = 30 @ 에피소드 # 52901\n","52901번째 에피소드까지 총 623번 finish 했습니다.\n","['K'] 종료: env.goal_ob_reward = True ... j = 953953  move = 26 @ 에피소드 # 52965\n","52965번째 에피소드까지 총 624번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 954098  move = 34 @ 에피소드 # 52969\n","52969번째 에피소드까지 총 625번 finish 했습니다.\n","['D'] 종료: env.goal_ob_reward = True ... j = 954857  move = 37 @ 에피소드 # 53011\n","53011번째 에피소드까지 총 626번 finish 했습니다.\n","epiode #: 53016 loss: 0.5876620411872864 j: 955000\n","['B'] 종료: env.goal_ob_reward = True ... j = 956516  move = 21 @ 에피소드 # 53083\n","53083번째 에피소드까지 총 627번 finish 했습니다.\n","['C'] 종료: env.goal_ob_reward = True ... j = 956735  move = 43 @ 에피소드 # 53094\n","53094번째 에피소드까지 총 628번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 957091  move = 34 @ 에피소드 # 53125\n","53125번째 에피소드까지 총 629번 finish 했습니다.\n","종료: done = True ... j = 959700  move = 4\n","['B'] 종료: env.goal_ob_reward = True ... j = 959961  move = 69 @ 에피소드 # 53279\n","53279번째 에피소드까지 총 630번 finish 했습니다.\n","epiode #: 53282 loss: 0.6127394437789917 j: 960000\n","['C'] 종료: env.goal_ob_reward = True ... j = 960379  move = 38 @ 에피소드 # 53297\n","53297번째 에피소드까지 총 631번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 960947  move = 56 @ 에피소드 # 53326\n","53326번째 에피소드까지 총 632번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 961330  move = 34 @ 에피소드 # 53347\n","53347번째 에피소드까지 총 633번 finish 했습니다.\n","['D'] 종료: env.goal_ob_reward = True ... j = 961717  move = 63 @ 에피소드 # 53367\n","53367번째 에피소드까지 총 634번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 961958  move = 26 @ 에피소드 # 53380\n","53380번째 에피소드까지 총 635번 finish 했습니다.\n","['D'] 종료: env.goal_ob_reward = True ... j = 962356  move = 22 @ 에피소드 # 53398\n","53398번째 에피소드까지 총 636번 finish 했습니다.\n","['D'] 종료: env.goal_ob_reward = True ... j = 962572  move = 67 @ 에피소드 # 53406\n","53406번째 에피소드까지 총 637번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 962926  move = 18 @ 에피소드 # 53431\n","53431번째 에피소드까지 총 638번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 964008  move = 28 @ 에피소드 # 53486\n","53486번째 에피소드까지 총 639번 finish 했습니다.\n","종료: done = True ... j = 964200  move = 12\n","['D'] 종료: env.goal_ob_reward = True ... j = 964854  move = 30 @ 에피소드 # 53527\n","53527번째 에피소드까지 총 640번 finish 했습니다.\n","epiode #: 53536 loss: 0.6179605722427368 j: 965000\n","['F'] 종료: env.goal_ob_reward = True ... j = 965736  move = 33 @ 에피소드 # 53575\n","53575번째 에피소드까지 총 641번 finish 했습니다.\n","종료: done = True ... j = 965800  move = 7\n","종료: done = True ... j = 967100  move = 39\n","['A'] 종료: env.goal_ob_reward = True ... j = 967630  move = 20 @ 에피소드 # 53687\n","53687번째 에피소드까지 총 642번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 967757  move = 25 @ 에피소드 # 53693\n","53693번째 에피소드까지 총 643번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 968885  move = 20 @ 에피소드 # 53761\n","53761번째 에피소드까지 총 644번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 969077  move = 66 @ 에피소드 # 53771\n","53771번째 에피소드까지 총 645번 finish 했습니다.\n","epiode #: 53820 loss: 0.6885024905204773 j: 970000\n","['A'] 종료: env.goal_ob_reward = True ... j = 970337  move = 52 @ 에피소드 # 53838\n","53838번째 에피소드까지 총 646번 finish 했습니다.\n","['D'] 종료: env.goal_ob_reward = True ... j = 970722  move = 32 @ 에피소드 # 53855\n","53855번째 에피소드까지 총 647번 finish 했습니다.\n","종료: done = True ... j = 971000  move = 44\n","['D'] 종료: env.goal_ob_reward = True ... j = 971000  move = 44 @ 에피소드 # 53870\n","53870번째 에피소드까지 총 648번 finish 했습니다.\n","['H'] 종료: env.goal_ob_reward = True ... j = 972479  move = 68 @ 에피소드 # 53950\n","53950번째 에피소드까지 총 649번 finish 했습니다.\n","종료: done = True ... j = 973200  move = 85\n","['P'] 종료: env.goal_ob_reward = True ... j = 973259  move = 25 @ 에피소드 # 53993\n","53993번째 에피소드까지 총 650번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 974346  move = 31 @ 에피소드 # 54050\n","54050번째 에피소드까지 총 651번 finish 했습니다.\n","종료: done = True ... j = 974400  move = 26\n","['H'] 종료: env.goal_ob_reward = True ... j = 974400  move = 26 @ 에피소드 # 54054\n","54054번째 에피소드까지 총 652번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 974619  move = 23 @ 에피소드 # 54065\n","54065번째 에피소드까지 총 653번 finish 했습니다.\n","종료: done = True ... j = 974800  move = 11\n","epiode #: 54086 loss: 0.776416003704071 j: 975000\n","['D'] 종료: env.goal_ob_reward = True ... j = 975307  move = 46 @ 에피소드 # 54108\n","54108번째 에피소드까지 총 654번 finish 했습니다.\n","종료: done = True ... j = 975500  move = 12\n","['Q'] 종료: env.goal_ob_reward = True ... j = 975830  move = 20 @ 에피소드 # 54136\n","54136번째 에피소드까지 총 655번 finish 했습니다.\n","['I'] 종료: env.goal_ob_reward = True ... j = 976505  move = 34 @ 에피소드 # 54175\n","54175번째 에피소드까지 총 656번 finish 했습니다.\n","종료: done = True ... j = 976600  move = 13\n","['I'] 종료: env.goal_ob_reward = True ... j = 977118  move = 30 @ 에피소드 # 54198\n","54198번째 에피소드까지 총 657번 finish 했습니다.\n","종료: done = True ... j = 977700  move = 14\n","['J'] 종료: env.goal_ob_reward = True ... j = 978276  move = 32 @ 에피소드 # 54245\n","54245번째 에피소드까지 총 658번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 978563  move = 26 @ 에피소드 # 54259\n","54259번째 에피소드까지 총 659번 finish 했습니다.\n","종료: done = True ... j = 979500  move = 17\n","종료: done = True ... j = 979600  move = 7\n","epiode #: 54339 loss: 0.3657965362071991 j: 980000\n","['P'] 종료: env.goal_ob_reward = True ... j = 980494  move = 41 @ 에피소드 # 54359\n","54359번째 에피소드까지 총 660번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 980567  move = 28 @ 에피소드 # 54364\n","54364번째 에피소드까지 총 661번 finish 했습니다.\n","['I'] 종료: env.goal_ob_reward = True ... j = 981264  move = 24 @ 에피소드 # 54401\n","54401번째 에피소드까지 총 662번 finish 했습니다.\n","종료: done = True ... j = 982300  move = 24\n","['Q'] 종료: env.goal_ob_reward = True ... j = 982486  move = 56 @ 에피소드 # 54469\n","54469번째 에피소드까지 총 663번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 983069  move = 39 @ 에피소드 # 54488\n","54488번째 에피소드까지 총 664번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 983961  move = 20 @ 에피소드 # 54539\n","54539번째 에피소드까지 총 665번 finish 했습니다.\n","['I'] 종료: env.goal_ob_reward = True ... j = 984123  move = 46 @ 에피소드 # 54543\n","54543번째 에피소드까지 총 666번 finish 했습니다.\n","종료: done = True ... j = 984500  move = 14\n","['B'] 종료: env.goal_ob_reward = True ... j = 984651  move = 40 @ 에피소드 # 54569\n","54569번째 에피소드까지 총 667번 finish 했습니다.\n","epiode #: 54593 loss: 0.22983519732952118 j: 985000\n","['D'] 종료: env.goal_ob_reward = True ... j = 985231  move = 36 @ 에피소드 # 54606\n","54606번째 에피소드까지 총 668번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 985390  move = 38 @ 에피소드 # 54613\n","54613번째 에피소드까지 총 669번 finish 했습니다.\n","['I'] 종료: env.goal_ob_reward = True ... j = 985611  move = 42 @ 에피소드 # 54619\n","54619번째 에피소드까지 총 670번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 986995  move = 38 @ 에피소드 # 54695\n","54695번째 에피소드까지 총 671번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 987195  move = 28 @ 에피소드 # 54707\n","54707번째 에피소드까지 총 672번 finish 했습니다.\n","['H'] 종료: env.goal_ob_reward = True ... j = 987601  move = 61 @ 에피소드 # 54724\n","54724번째 에피소드까지 총 673번 finish 했습니다.\n","['D'] 종료: env.goal_ob_reward = True ... j = 987723  move = 50 @ 에피소드 # 54729\n","54729번째 에피소드까지 총 674번 finish 했습니다.\n","['D'] 종료: env.goal_ob_reward = True ... j = 987934  move = 44 @ 에피소드 # 54740\n","54740번째 에피소드까지 총 675번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 987981  move = 16 @ 에피소드 # 54746\n","54746번째 에피소드까지 총 676번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 988834  move = 65 @ 에피소드 # 54788\n","54788번째 에피소드까지 총 677번 finish 했습니다.\n","['I'] 종료: env.goal_ob_reward = True ... j = 989451  move = 36 @ 에피소드 # 54819\n","54819번째 에피소드까지 총 678번 finish 했습니다.\n","epiode #: 54852 loss: 0.23749502003192902 j: 990000\n","['P'] 종료: env.goal_ob_reward = True ... j = 990232  move = 25 @ 에피소드 # 54862\n","54862번째 에피소드까지 총 679번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 990382  move = 26 @ 에피소드 # 54873\n","54873번째 에피소드까지 총 680번 finish 했습니다.\n","종료: done = True ... j = 990700  move = 8\n","['P'] 종료: env.goal_ob_reward = True ... j = 991063  move = 30 @ 에피소드 # 54922\n","54922번째 에피소드까지 총 681번 finish 했습니다.\n","['D'] 종료: env.goal_ob_reward = True ... j = 991944  move = 37 @ 에피소드 # 54964\n","54964번째 에피소드까지 총 682번 finish 했습니다.\n","종료: done = True ... j = 993000  move = 8\n","['A'] 종료: env.goal_ob_reward = True ... j = 993522  move = 46 @ 에피소드 # 55043\n","55043번째 에피소드까지 총 683번 finish 했습니다.\n","epiode #: 55135 loss: 0.5243481397628784 j: 995000\n","종료: done = True ... j = 995100  move = 24\n","['O'] 종료: env.goal_ob_reward = True ... j = 995100  move = 24 @ 에피소드 # 55137\n","55137번째 에피소드까지 총 684번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 995237  move = 27 @ 에피소드 # 55143\n","55143번째 에피소드까지 총 685번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 995658  move = 38 @ 에피소드 # 55169\n","55169번째 에피소드까지 총 686번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 995689  move = 25 @ 에피소드 # 55171\n","55171번째 에피소드까지 총 687번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 996489  move = 21 @ 에피소드 # 55214\n","55214번째 에피소드까지 총 688번 finish 했습니다.\n","종료: done = True ... j = 996700  move = 17\n","['O'] 종료: env.goal_ob_reward = True ... j = 997085  move = 29 @ 에피소드 # 55245\n","55245번째 에피소드까지 총 689번 finish 했습니다.\n","['C'] 종료: env.goal_ob_reward = True ... j = 998230  move = 26 @ 에피소드 # 55304\n","55304번째 에피소드까지 총 690번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 999135  move = 20 @ 에피소드 # 55354\n","55354번째 에피소드까지 총 691번 finish 했습니다.\n","['M'] 종료: env.goal_ob_reward = True ... j = 999503  move = 56 @ 에피소드 # 55373\n","55373번째 에피소드까지 총 692번 finish 했습니다.\n","epiode #: 55398 loss: 0.450449138879776 j: 1000000\n","종료: done = True ... j = 1000800  move = 5\n","['C'] 종료: env.goal_ob_reward = True ... j = 1000871  move = 22 @ 에피소드 # 55446\n","55446번째 에피소드까지 총 693번 finish 했습니다.\n","['E'] 종료: env.goal_ob_reward = True ... j = 1002537  move = 49 @ 에피소드 # 55553\n","55553번째 에피소드까지 총 694번 finish 했습니다.\n","종료: done = True ... j = 1003400  move = 29\n","종료: done = True ... j = 1003700  move = 39\n","['I'] 종료: env.goal_ob_reward = True ... j = 1004544  move = 42 @ 에피소드 # 55656\n","55656번째 에피소드까지 총 695번 finish 했습니다.\n","['M'] 종료: env.goal_ob_reward = True ... j = 1004699  move = 76 @ 에피소드 # 55663\n","55663번째 에피소드까지 총 696번 finish 했습니다.\n","epiode #: 55683 loss: 0.6560762524604797 j: 1005000\n","['A'] 종료: env.goal_ob_reward = True ... j = 1005659  move = 55 @ 에피소드 # 55720\n","55720번째 에피소드까지 총 697번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 1006412  move = 38 @ 에피소드 # 55768\n","55768번째 에피소드까지 총 698번 finish 했습니다.\n","종료: done = True ... j = 1007000  move = 24\n","종료: done = True ... j = 1009600  move = 22\n","epiode #: 55973 loss: 0.47554895281791687 j: 1010000\n","['A'] 종료: env.goal_ob_reward = True ... j = 1010415  move = 16 @ 에피소드 # 56000\n","56000번째 에피소드까지 총 699번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 1011814  move = 34 @ 에피소드 # 56085\n","56085번째 에피소드까지 총 700번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 1014635  move = 26 @ 에피소드 # 56218\n","56218번째 에피소드까지 총 701번 finish 했습니다.\n","epiode #: 56236 loss: 0.5327498316764832 j: 1015000\n","종료: done = True ... j = 1015500  move = 7\n","['K'] 종료: env.goal_ob_reward = True ... j = 1017657  move = 67 @ 에피소드 # 56367\n","56367번째 에피소드까지 총 702번 finish 했습니다.\n","epiode #: 56488 loss: 0.5118498206138611 j: 1020000\n","종료: done = True ... j = 1020900  move = 36\n","['O'] 종료: env.goal_ob_reward = True ... j = 1021001  move = 30 @ 에피소드 # 56539\n","56539번째 에피소드까지 총 703번 finish 했습니다.\n","['L'] 종료: env.goal_ob_reward = True ... j = 1022174  move = 26 @ 에피소드 # 56606\n","56606번째 에피소드까지 총 704번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 1022838  move = 30 @ 에피소드 # 56632\n","56632번째 에피소드까지 총 705번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1022997  move = 80 @ 에피소드 # 56634\n","56634번째 에피소드까지 총 706번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1024405  move = 28 @ 에피소드 # 56719\n","56719번째 에피소드까지 총 707번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1024795  move = 66 @ 에피소드 # 56737\n","56737번째 에피소드까지 총 708번 finish 했습니다.\n","epiode #: 56747 loss: 0.3285585045814514 j: 1025000\n","['A'] 종료: env.goal_ob_reward = True ... j = 1025487  move = 20 @ 에피소드 # 56769\n","56769번째 에피소드까지 총 709번 finish 했습니다.\n","['L'] 종료: env.goal_ob_reward = True ... j = 1025523  move = 28 @ 에피소드 # 56771\n","56771번째 에피소드까지 총 710번 finish 했습니다.\n","['H'] 종료: env.goal_ob_reward = True ... j = 1026203  move = 28 @ 에피소드 # 56807\n","56807번째 에피소드까지 총 711번 finish 했습니다.\n","['H'] 종료: env.goal_ob_reward = True ... j = 1026575  move = 26 @ 에피소드 # 56822\n","56822번째 에피소드까지 총 712번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 1027038  move = 40 @ 에피소드 # 56847\n","56847번째 에피소드까지 총 713번 finish 했습니다.\n","종료: done = True ... j = 1029400  move = 47\n","epiode #: 56996 loss: 0.4136516749858856 j: 1030000\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1030424  move = 40 @ 에피소드 # 57019\n","57019번째 에피소드까지 총 714번 finish 했습니다.\n","종료: done = True ... j = 1032500  move = 7\n","종료: done = True ... j = 1033000  move = 14\n","['P'] 종료: env.goal_ob_reward = True ... j = 1033107  move = 33 @ 에피소드 # 57177\n","57177번째 에피소드까지 총 715번 finish 했습니다.\n","epiode #: 57279 loss: 0.34411701560020447 j: 1035000\n","종료: done = True ... j = 1035200  move = 76\n","종료: done = True ... j = 1036200  move = 4\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1037072  move = 20 @ 에피소드 # 57383\n","57383번째 에피소드까지 총 716번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 1038194  move = 33 @ 에피소드 # 57443\n","57443번째 에피소드까지 총 717번 finish 했습니다.\n","['D'] 종료: env.goal_ob_reward = True ... j = 1038564  move = 34 @ 에피소드 # 57462\n","57462번째 에피소드까지 총 718번 finish 했습니다.\n","['M'] 종료: env.goal_ob_reward = True ... j = 1038712  move = 74 @ 에피소드 # 57465\n","57465번째 에피소드까지 총 719번 finish 했습니다.\n","종료: done = True ... j = 1039200  move = 20\n","epiode #: 57534 loss: 0.4831995964050293 j: 1040000\n","종료: done = True ... j = 1041200  move = 8\n","['P'] 종료: env.goal_ob_reward = True ... j = 1041576  move = 33 @ 에피소드 # 57619\n","57619번째 에피소드까지 총 720번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1043277  move = 36 @ 에피소드 # 57702\n","57702번째 에피소드까지 총 721번 finish 했습니다.\n","종료: done = True ... j = 1043600  move = 5\n","종료: done = True ... j = 1044100  move = 8\n","epiode #: 57790 loss: 0.39885085821151733 j: 1045000\n","['K'] 종료: env.goal_ob_reward = True ... j = 1045035  move = 64 @ 에피소드 # 57790\n","57790번째 에피소드까지 총 722번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 1046851  move = 50 @ 에피소드 # 57885\n","57885번째 에피소드까지 총 723번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1048101  move = 50 @ 에피소드 # 57945\n","57945번째 에피소드까지 총 724번 finish 했습니다.\n","['M'] 종료: env.goal_ob_reward = True ... j = 1048402  move = 45 @ 에피소드 # 57957\n","57957번째 에피소드까지 총 725번 finish 했습니다.\n","['J'] 종료: env.goal_ob_reward = True ... j = 1048997  move = 34 @ 에피소드 # 57985\n","57985번째 에피소드까지 총 726번 finish 했습니다.\n","종료: done = True ... j = 1049000  move = 3\n","종료: done = True ... j = 1049300  move = 7\n","epiode #: 58048 loss: 0.46165263652801514 j: 1050000\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1050783  move = 66 @ 에피소드 # 58086\n","58086번째 에피소드까지 총 727번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 1050845  move = 21 @ 에피소드 # 58088\n","58088번째 에피소드까지 총 728번 finish 했습니다.\n","['K'] 종료: env.goal_ob_reward = True ... j = 1051463  move = 34 @ 에피소드 # 58122\n","58122번째 에피소드까지 총 729번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1051788  move = 26 @ 에피소드 # 58138\n","58138번째 에피소드까지 총 730번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 1052953  move = 42 @ 에피소드 # 58193\n","58193번째 에피소드까지 총 731번 finish 했습니다.\n","종료: done = True ... j = 1053200  move = 6\n","['E'] 종료: env.goal_ob_reward = True ... j = 1053810  move = 36 @ 에피소드 # 58242\n","58242번째 에피소드까지 총 732번 finish 했습니다.\n","epiode #: 58316 loss: 0.13625650107860565 j: 1055000\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1055066  move = 20 @ 에피소드 # 58320\n","58320번째 에피소드까지 총 733번 finish 했습니다.\n","종료: done = True ... j = 1055700  move = 4\n","종료: done = True ... j = 1055800  move = 12\n","['A'] 종료: env.goal_ob_reward = True ... j = 1055833  move = 22 @ 에피소드 # 58357\n","58357번째 에피소드까지 총 734번 finish 했습니다.\n","종료: done = True ... j = 1056100  move = 17\n","['L'] 종료: env.goal_ob_reward = True ... j = 1056409  move = 26 @ 에피소드 # 58388\n","58388번째 에피소드까지 총 735번 finish 했습니다.\n","['L'] 종료: env.goal_ob_reward = True ... j = 1057128  move = 47 @ 에피소드 # 58428\n","58428번째 에피소드까지 총 736번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 1057879  move = 34 @ 에피소드 # 58467\n","58467번째 에피소드까지 총 737번 finish 했습니다.\n","종료: done = True ... j = 1058600  move = 7\n","종료: done = True ... j = 1059800  move = 18\n","epiode #: 58578 loss: 0.3581102192401886 j: 1060000\n","종료: done = True ... j = 1060000  move = 7\n","['C'] 종료: env.goal_ob_reward = True ... j = 1061580  move = 26 @ 에피소드 # 58667\n","58667번째 에피소드까지 총 738번 finish 했습니다.\n","종료: done = True ... j = 1062100  move = 9\n","종료: done = True ... j = 1063100  move = 3\n","종료: done = True ... j = 1063500  move = 25\n","['K'] 종료: env.goal_ob_reward = True ... j = 1064384  move = 33 @ 에피소드 # 58818\n","58818번째 에피소드까지 총 739번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1064429  move = 45 @ 에피소드 # 58819\n","58819번째 에피소드까지 총 740번 finish 했습니다.\n","epiode #: 58850 loss: 0.30024445056915283 j: 1065000\n","종료: done = True ... j = 1065500  move = 3\n","종료: done = True ... j = 1065600  move = 16\n","종료: done = True ... j = 1066900  move = 37\n","종료: done = True ... j = 1067800  move = 6\n","['G'] 종료: env.goal_ob_reward = True ... j = 1069451  move = 96 @ 에피소드 # 59090\n","59090번째 에피소드까지 총 741번 finish 했습니다.\n","epiode #: 59123 loss: 0.396230548620224 j: 1070000\n","['C'] 종료: env.goal_ob_reward = True ... j = 1070053  move = 34 @ 에피소드 # 59127\n","59127번째 에피소드까지 총 742번 finish 했습니다.\n","종료: done = True ... j = 1070700  move = 4\n","['E'] 종료: env.goal_ob_reward = True ... j = 1071098  move = 36 @ 에피소드 # 59178\n","59178번째 에피소드까지 총 743번 finish 했습니다.\n","종료: done = True ... j = 1071300  move = 8\n","['D'] 종료: env.goal_ob_reward = True ... j = 1071351  move = 28 @ 에피소드 # 59200\n","59200번째 에피소드까지 총 744번 finish 했습니다.\n","['M'] 종료: env.goal_ob_reward = True ... j = 1071913  move = 38 @ 에피소드 # 59228\n","59228번째 에피소드까지 총 745번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 1072052  move = 93 @ 에피소드 # 59230\n","59230번째 에피소드까지 총 746번 finish 했습니다.\n","종료: done = True ... j = 1072100  move = 7\n","['P'] 종료: env.goal_ob_reward = True ... j = 1072541  move = 27 @ 에피소드 # 59255\n","59255번째 에피소드까지 총 747번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 1073530  move = 64 @ 에피소드 # 59309\n","59309번째 에피소드까지 총 748번 finish 했습니다.\n","['L'] 종료: env.goal_ob_reward = True ... j = 1074451  move = 32 @ 에피소드 # 59371\n","59371번째 에피소드까지 총 749번 finish 했습니다.\n","epiode #: 59406 loss: 0.45194944739341736 j: 1075000\n","['M'] 종료: env.goal_ob_reward = True ... j = 1075468  move = 31 @ 에피소드 # 59432\n","59432번째 에피소드까지 총 750번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 1077155  move = 27 @ 에피소드 # 59518\n","59518번째 에피소드까지 총 751번 finish 했습니다.\n","['I'] 종료: env.goal_ob_reward = True ... j = 1079345  move = 42 @ 에피소드 # 59629\n","59629번째 에피소드까지 총 752번 finish 했습니다.\n","['F'] 종료: env.goal_ob_reward = True ... j = 1079437  move = 32 @ 에피소드 # 59633\n","59633번째 에피소드까지 총 753번 finish 했습니다.\n","epiode #: 59670 loss: 0.25775495171546936 j: 1080000\n","['O'] 종료: env.goal_ob_reward = True ... j = 1080519  move = 47 @ 에피소드 # 59691\n","59691번째 에피소드까지 총 754번 finish 했습니다.\n","종료: done = True ... j = 1080700  move = 5\n","['O'] 종료: env.goal_ob_reward = True ... j = 1081267  move = 60 @ 에피소드 # 59719\n","59719번째 에피소드까지 총 755번 finish 했습니다.\n","['G'] 종료: env.goal_ob_reward = True ... j = 1082149  move = 37 @ 에피소드 # 59765\n","59765번째 에피소드까지 총 756번 finish 했습니다.\n","['L'] 종료: env.goal_ob_reward = True ... j = 1082512  move = 36 @ 에피소드 # 59786\n","59786번째 에피소드까지 총 757번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 1082542  move = 30 @ 에피소드 # 59787\n","59787번째 에피소드까지 총 758번 finish 했습니다.\n","종료: done = True ... j = 1083600  move = 6\n","['C'] 종료: env.goal_ob_reward = True ... j = 1084859  move = 22 @ 에피소드 # 59893\n","59893번째 에피소드까지 총 759번 finish 했습니다.\n","epiode #: 59902 loss: 0.6128903031349182 j: 1085000\n","['N'] 종료: env.goal_ob_reward = True ... j = 1085955  move = 26 @ 에피소드 # 59953\n","59953번째 에피소드까지 총 760번 finish 했습니다.\n","▶ 모델 저장됨!!! @ 에피소드 60000\n","종료: done = True ... j = 1087300  move = 7\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1087425  move = 24 @ 에피소드 # 60035\n","60035번째 에피소드까지 총 761번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 1087753  move = 33 @ 에피소드 # 60051\n","60051번째 에피소드까지 총 762번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1088225  move = 20 @ 에피소드 # 60077\n","60077번째 에피소드까지 총 763번 finish 했습니다.\n","['E'] 종료: env.goal_ob_reward = True ... j = 1088329  move = 37 @ 에피소드 # 60082\n","60082번째 에피소드까지 총 764번 finish 했습니다.\n","종료: done = True ... j = 1089200  move = 34\n","['F'] 종료: env.goal_ob_reward = True ... j = 1089650  move = 44 @ 에피소드 # 60141\n","60141번째 에피소드까지 총 765번 finish 했습니다.\n","['I'] 종료: env.goal_ob_reward = True ... j = 1089790  move = 74 @ 에피소드 # 60145\n","60145번째 에피소드까지 총 766번 finish 했습니다.\n","epiode #: 60153 loss: 0.48652181029319763 j: 1090000\n","['B'] 종료: env.goal_ob_reward = True ... j = 1091482  move = 28 @ 에피소드 # 60225\n","60225번째 에피소드까지 총 767번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 1092826  move = 36 @ 에피소드 # 60303\n","60303번째 에피소드까지 총 768번 finish 했습니다.\n","['H'] 종료: env.goal_ob_reward = True ... j = 1093178  move = 33 @ 에피소드 # 60325\n","60325번째 에피소드까지 총 769번 finish 했습니다.\n","['C'] 종료: env.goal_ob_reward = True ... j = 1093823  move = 22 @ 에피소드 # 60367\n","60367번째 에피소드까지 총 770번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 1094956  move = 68 @ 에피소드 # 60422\n","60422번째 에피소드까지 총 771번 finish 했습니다.\n","epiode #: 60426 loss: 0.33501768112182617 j: 1095000\n","['D'] 종료: env.goal_ob_reward = True ... j = 1095277  move = 32 @ 에피소드 # 60439\n","60439번째 에피소드까지 총 772번 finish 했습니다.\n","['I'] 종료: env.goal_ob_reward = True ... j = 1095473  move = 26 @ 에피소드 # 60454\n","60454번째 에피소드까지 총 773번 finish 했습니다.\n","종료: done = True ... j = 1095500  move = 8\n","['H'] 종료: env.goal_ob_reward = True ... j = 1096755  move = 24 @ 에피소드 # 60514\n","60514번째 에피소드까지 총 774번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1097069  move = 34 @ 에피소드 # 60524\n","60524번째 에피소드까지 총 775번 finish 했습니다.\n","종료: done = True ... j = 1099100  move = 24\n","['H'] 종료: env.goal_ob_reward = True ... j = 1099365  move = 28 @ 에피소드 # 60657\n","60657번째 에피소드까지 총 776번 finish 했습니다.\n","epiode #: 60694 loss: 0.3251785337924957 j: 1100000\n","['A'] 종료: env.goal_ob_reward = True ... j = 1100133  move = 44 @ 에피소드 # 60700\n","60700번째 에피소드까지 총 777번 finish 했습니다.\n","['C'] 종료: env.goal_ob_reward = True ... j = 1100293  move = 41 @ 에피소드 # 60709\n","60709번째 에피소드까지 총 778번 finish 했습니다.\n","['C'] 종료: env.goal_ob_reward = True ... j = 1100325  move = 22 @ 에피소드 # 60711\n","60711번째 에피소드까지 총 779번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 1102423  move = 61 @ 에피소드 # 60813\n","60813번째 에피소드까지 총 780번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 1104147  move = 32 @ 에피소드 # 60902\n","60902번째 에피소드까지 총 781번 finish 했습니다.\n","epiode #: 60954 loss: 0.4566982090473175 j: 1105000\n","종료: done = True ... j = 1106100  move = 27\n","['P'] 종료: env.goal_ob_reward = True ... j = 1107964  move = 28 @ 에피소드 # 61134\n","61134번째 에피소드까지 총 782번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 1109005  move = 40 @ 에피소드 # 61189\n","61189번째 에피소드까지 총 783번 finish 했습니다.\n","종료: done = True ... j = 1109100  move = 5\n","종료: done = True ... j = 1109200  move = 7\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1109584  move = 21 @ 에피소드 # 61225\n","61225번째 에피소드까지 총 784번 finish 했습니다.\n","['H'] 종료: env.goal_ob_reward = True ... j = 1109909  move = 50 @ 에피소드 # 61243\n","61243번째 에피소드까지 총 785번 finish 했습니다.\n","epiode #: 61249 loss: 0.3975367546081543 j: 1110000\n","종료: done = True ... j = 1110400  move = 12\n","['N'] 종료: env.goal_ob_reward = True ... j = 1110751  move = 30 @ 에피소드 # 61283\n","61283번째 에피소드까지 총 786번 finish 했습니다.\n","['H'] 종료: env.goal_ob_reward = True ... j = 1112779  move = 45 @ 에피소드 # 61379\n","61379번째 에피소드까지 총 787번 finish 했습니다.\n","종료: done = True ... j = 1114200  move = 64\n","종료: done = True ... j = 1114800  move = 24\n","epiode #: 61506 loss: 0.3720691502094269 j: 1115000\n","['C'] 종료: env.goal_ob_reward = True ... j = 1115412  move = 36 @ 에피소드 # 61535\n","61535번째 에피소드까지 총 788번 finish 했습니다.\n","['I'] 종료: env.goal_ob_reward = True ... j = 1115769  move = 32 @ 에피소드 # 61562\n","61562번째 에피소드까지 총 789번 finish 했습니다.\n","종료: done = True ... j = 1116100  move = 24\n","종료: done = True ... j = 1116600  move = 13\n","종료: done = True ... j = 1116700  move = 7\n","['D'] 종료: env.goal_ob_reward = True ... j = 1117073  move = 43 @ 에피소드 # 61623\n","61623번째 에피소드까지 총 790번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 1117379  move = 25 @ 에피소드 # 61637\n","61637번째 에피소드까지 총 791번 finish 했습니다.\n","종료: done = True ... j = 1117400  move = 10\n","['D'] 종료: env.goal_ob_reward = True ... j = 1118051  move = 85 @ 에피소드 # 61667\n","61667번째 에피소드까지 총 792번 finish 했습니다.\n","종료: done = True ... j = 1118200  move = 10\n","종료: done = True ... j = 1118500  move = 18\n","종료: done = True ... j = 1118700  move = 27\n","종료: done = True ... j = 1119000  move = 5\n","['A'] 종료: env.goal_ob_reward = True ... j = 1119246  move = 18 @ 에피소드 # 61736\n","61736번째 에피소드까지 총 793번 finish 했습니다.\n","epiode #: 61779 loss: 0.43617942929267883 j: 1120000\n","종료: done = True ... j = 1120900  move = 5\n","['O'] 종료: env.goal_ob_reward = True ... j = 1121670  move = 61 @ 에피소드 # 61859\n","61859번째 에피소드까지 총 794번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1121868  move = 24 @ 에피소드 # 61870\n","61870번째 에피소드까지 총 795번 finish 했습니다.\n","['H'] 종료: env.goal_ob_reward = True ... j = 1123096  move = 26 @ 에피소드 # 61932\n","61932번째 에피소드까지 총 796번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 1123426  move = 62 @ 에피소드 # 61952\n","61952번째 에피소드까지 총 797번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 1124266  move = 20 @ 에피소드 # 62005\n","62005번째 에피소드까지 총 798번 finish 했습니다.\n","epiode #: 62046 loss: 0.5233169198036194 j: 1125000\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1126638  move = 24 @ 에피소드 # 62148\n","62148번째 에피소드까지 총 799번 finish 했습니다.\n","종료: done = True ... j = 1127100  move = 14\n","['H'] 종료: env.goal_ob_reward = True ... j = 1129454  move = 33 @ 에피소드 # 62287\n","62287번째 에피소드까지 총 800번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1129486  move = 24 @ 에피소드 # 62290\n","62290번째 에피소드까지 총 801번 finish 했습니다.\n","종료: done = True ... j = 1129600  move = 36\n","epiode #: 62311 loss: 0.4693281352519989 j: 1130000\n","종료: done = True ... j = 1130500  move = 7\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1130960  move = 24 @ 에피소드 # 62349\n","62349번째 에피소드까지 총 802번 finish 했습니다.\n","종료: done = True ... j = 1131000  move = 7\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1131158  move = 60 @ 에피소드 # 62359\n","62359번째 에피소드까지 총 803번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 1132066  move = 30 @ 에피소드 # 62415\n","62415번째 에피소드까지 총 804번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1134450  move = 22 @ 에피소드 # 62544\n","62544번째 에피소드까지 총 805번 finish 했습니다.\n","epiode #: 62572 loss: 0.5415984392166138 j: 1135000\n","['O'] 종료: env.goal_ob_reward = True ... j = 1137244  move = 33 @ 에피소드 # 62691\n","62691번째 에피소드까지 총 806번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 1137442  move = 22 @ 에피소드 # 62699\n","62699번째 에피소드까지 총 807번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 1137662  move = 32 @ 에피소드 # 62706\n","62706번째 에피소드까지 총 808번 finish 했습니다.\n","종료: done = True ... j = 1138200  move = 5\n","종료: done = True ... j = 1138800  move = 28\n","['I'] 종료: env.goal_ob_reward = True ... j = 1138986  move = 26 @ 에피소드 # 62793\n","62793번째 에피소드까지 총 809번 finish 했습니다.\n","['G'] 종료: env.goal_ob_reward = True ... j = 1139407  move = 38 @ 에피소드 # 62818\n","62818번째 에피소드까지 총 810번 finish 했습니다.\n","종료: done = True ... j = 1139500  move = 50\n","epiode #: 62846 loss: 0.5055075883865356 j: 1140000\n","종료: done = True ... j = 1140400  move = 28\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1141131  move = 22 @ 에피소드 # 62889\n","62889번째 에피소드까지 총 811번 finish 했습니다.\n","['H'] 종료: env.goal_ob_reward = True ... j = 1141635  move = 32 @ 에피소드 # 62915\n","62915번째 에피소드까지 총 812번 finish 했습니다.\n","['G'] 종료: env.goal_ob_reward = True ... j = 1141781  move = 47 @ 에피소드 # 62924\n","62924번째 에피소드까지 총 813번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 1142091  move = 24 @ 에피소드 # 62939\n","62939번째 에피소드까지 총 814번 finish 했습니다.\n","['D'] 종료: env.goal_ob_reward = True ... j = 1144952  move = 60 @ 에피소드 # 63091\n","63091번째 에피소드까지 총 815번 finish 했습니다.\n","epiode #: 63096 loss: 0.23370037972927094 j: 1145000\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1145243  move = 36 @ 에피소드 # 63115\n","63115번째 에피소드까지 총 816번 finish 했습니다.\n","['F'] 종료: env.goal_ob_reward = True ... j = 1146537  move = 56 @ 에피소드 # 63189\n","63189번째 에피소드까지 총 817번 finish 했습니다.\n","종료: done = True ... j = 1146700  move = 15\n","['E'] 종료: env.goal_ob_reward = True ... j = 1147788  move = 40 @ 에피소드 # 63259\n","63259번째 에피소드까지 총 818번 finish 했습니다.\n","['N'] 종료: env.goal_ob_reward = True ... j = 1147995  move = 30 @ 에피소드 # 63272\n","63272번째 에피소드까지 총 819번 finish 했습니다.\n","종료: done = True ... j = 1148500  move = 7\n","종료: done = True ... j = 1149100  move = 7\n","종료: done = True ... j = 1149600  move = 87\n","epiode #: 63375 loss: 0.41234061121940613 j: 1150000\n","['G'] 종료: env.goal_ob_reward = True ... j = 1150074  move = 26 @ 에피소드 # 63377\n","63377번째 에피소드까지 총 820번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 1151590  move = 24 @ 에피소드 # 63456\n","63456번째 에피소드까지 총 821번 finish 했습니다.\n","종료: done = True ... j = 1152000  move = 5\n","['C'] 종료: env.goal_ob_reward = True ... j = 1152453  move = 24 @ 에피소드 # 63503\n","63503번째 에피소드까지 총 822번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 1152843  move = 36 @ 에피소드 # 63518\n","63518번째 에피소드까지 총 823번 finish 했습니다.\n","종료: done = True ... j = 1154100  move = 32\n","['B'] 종료: env.goal_ob_reward = True ... j = 1154270  move = 38 @ 에피소드 # 63590\n","63590번째 에피소드까지 총 824번 finish 했습니다.\n","epiode #: 63632 loss: 0.24654701352119446 j: 1155000\n","종료: done = True ... j = 1155100  move = 14\n","['A'] 종료: env.goal_ob_reward = True ... j = 1156975  move = 74 @ 에피소드 # 63730\n","63730번째 에피소드까지 총 825번 finish 했습니다.\n","종료: done = True ... j = 1157100  move = 33\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1158158  move = 22 @ 에피소드 # 63784\n","63784번째 에피소드까지 총 826번 finish 했습니다.\n","종료: done = True ... j = 1158900  move = 7\n","epiode #: 63871 loss: 0.6674346923828125 j: 1160000\n","종료: done = True ... j = 1160400  move = 31\n","종료: done = True ... j = 1161300  move = 34\n","['A'] 종료: env.goal_ob_reward = True ... j = 1161514  move = 20 @ 에피소드 # 63946\n","63946번째 에피소드까지 총 827번 finish 했습니다.\n","종료: done = True ... j = 1162500  move = 38\n","['L'] 종료: env.goal_ob_reward = True ... j = 1162500  move = 38 @ 에피소드 # 63989\n","63989번째 에피소드까지 총 828번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 1163634  move = 18 @ 에피소드 # 64051\n","64051번째 에피소드까지 총 829번 finish 했습니다.\n","epiode #: 64146 loss: 0.5214970111846924 j: 1165000\n","['J'] 종료: env.goal_ob_reward = True ... j = 1165277  move = 50 @ 에피소드 # 64161\n","64161번째 에피소드까지 총 830번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1165438  move = 30 @ 에피소드 # 64173\n","64173번째 에피소드까지 총 831번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 1166557  move = 18 @ 에피소드 # 64229\n","64229번째 에피소드까지 총 832번 finish 했습니다.\n","종료: done = True ... j = 1167200  move = 8\n","['L'] 종료: env.goal_ob_reward = True ... j = 1167808  move = 24 @ 에피소드 # 64306\n","64306번째 에피소드까지 총 833번 finish 했습니다.\n","종료: done = True ... j = 1168600  move = 9\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1169076  move = 18 @ 에피소드 # 64365\n","64365번째 에피소드까지 총 834번 finish 했습니다.\n","epiode #: 64426 loss: 0.29523965716362 j: 1170000\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1171168  move = 44 @ 에피소드 # 64502\n","64502번째 에피소드까지 총 835번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1171269  move = 38 @ 에피소드 # 64507\n","64507번째 에피소드까지 총 836번 finish 했습니다.\n","종료: done = True ... j = 1171900  move = 6\n","['O'] 종료: env.goal_ob_reward = True ... j = 1172294  move = 34 @ 에피소드 # 64556\n","64556번째 에피소드까지 총 837번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1173321  move = 36 @ 에피소드 # 64614\n","64614번째 에피소드까지 총 838번 finish 했습니다.\n","['M'] 종료: env.goal_ob_reward = True ... j = 1173408  move = 35 @ 에피소드 # 64617\n","64617번째 에피소드까지 총 839번 finish 했습니다.\n","종료: done = True ... j = 1173900  move = 33\n","종료: done = True ... j = 1174200  move = 39\n","종료: done = True ... j = 1174400  move = 6\n","['P'] 종료: env.goal_ob_reward = True ... j = 1174974  move = 59 @ 에피소드 # 64700\n","64700번째 에피소드까지 총 840번 finish 했습니다.\n","epiode #: 64703 loss: 0.42966872453689575 j: 1175000\n","종료: done = True ... j = 1175000  move = 10\n","['L'] 종료: env.goal_ob_reward = True ... j = 1175577  move = 30 @ 에피소드 # 64741\n","64741번째 에피소드까지 총 841번 finish 했습니다.\n","종료: done = True ... j = 1175600  move = 23\n","종료: done = True ... j = 1176000  move = 19\n","종료: done = True ... j = 1179500  move = 11\n","['B'] 종료: env.goal_ob_reward = True ... j = 1179523  move = 18 @ 에피소드 # 64943\n","64943번째 에피소드까지 총 842번 finish 했습니다.\n","epiode #: 64967 loss: 0.39132818579673767 j: 1180000\n","종료: done = True ... j = 1181100  move = 7\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1181376  move = 18 @ 에피소드 # 65041\n","65041번째 에피소드까지 총 843번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 1181699  move = 38 @ 에피소드 # 65056\n","65056번째 에피소드까지 총 844번 finish 했습니다.\n","종료: done = True ... j = 1183700  move = 9\n","epiode #: 65259 loss: 0.35951271653175354 j: 1185000\n","['B'] 종료: env.goal_ob_reward = True ... j = 1188291  move = 26 @ 에피소드 # 65449\n","65449번째 에피소드까지 총 845번 finish 했습니다.\n","epiode #: 65557 loss: 0.47483396530151367 j: 1190000\n","종료: done = True ... j = 1191000  move = 5\n","종료: done = True ... j = 1191500  move = 7\n","['P'] 종료: env.goal_ob_reward = True ... j = 1191560  move = 60 @ 에피소드 # 65634\n","65634번째 에피소드까지 총 846번 finish 했습니다.\n","종료: done = True ... j = 1192000  move = 14\n","['H'] 종료: env.goal_ob_reward = True ... j = 1192725  move = 42 @ 에피소드 # 65690\n","65690번째 에피소드까지 총 847번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 1193177  move = 94 @ 에피소드 # 65706\n","65706번째 에피소드까지 총 848번 finish 했습니다.\n","['M'] 종료: env.goal_ob_reward = True ... j = 1193245  move = 28 @ 에피소드 # 65708\n","65708번째 에피소드까지 총 849번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 1193623  move = 34 @ 에피소드 # 65730\n","65730번째 에피소드까지 총 850번 finish 했습니다.\n","종료: done = True ... j = 1193700  move = 7\n","['A'] 종료: env.goal_ob_reward = True ... j = 1193734  move = 24 @ 에피소드 # 65738\n","65738번째 에피소드까지 총 851번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 1193852  move = 34 @ 에피소드 # 65743\n","65743번째 에피소드까지 총 852번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 1193917  move = 39 @ 에피소드 # 65747\n","65747번째 에피소드까지 총 853번 finish 했습니다.\n","epiode #: 65804 loss: 0.35854098200798035 j: 1195000\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1195008  move = 46 @ 에피소드 # 65804\n","65804번째 에피소드까지 총 854번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 1195853  move = 24 @ 에피소드 # 65857\n","65857번째 에피소드까지 총 855번 finish 했습니다.\n","종료: done = True ... j = 1195900  move = 11\n","epiode #: 66100 loss: 0.42768383026123047 j: 1200000\n","종료: done = True ... j = 1200800  move = 5\n","종료: done = True ... j = 1202900  move = 43\n","['P'] 종료: env.goal_ob_reward = True ... j = 1202900  move = 43 @ 에피소드 # 66279\n","66279번째 에피소드까지 총 856번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1203709  move = 43 @ 에피소드 # 66323\n","66323번째 에피소드까지 총 857번 finish 했습니다.\n","epiode #: 66373 loss: 0.30379876494407654 j: 1205000\n","종료: done = True ... j = 1205500  move = 14\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1205796  move = 22 @ 에피소드 # 66419\n","66419번째 에피소드까지 총 858번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 1205856  move = 30 @ 에피소드 # 66424\n","66424번째 에피소드까지 총 859번 finish 했습니다.\n","종료: done = True ... j = 1208300  move = 7\n","종료: done = True ... j = 1208600  move = 8\n","종료: done = True ... j = 1209100  move = 3\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1209532  move = 28 @ 에피소드 # 66607\n","66607번째 에피소드까지 총 860번 finish 했습니다.\n","['E'] 종료: env.goal_ob_reward = True ... j = 1209812  move = 33 @ 에피소드 # 66624\n","66624번째 에피소드까지 총 861번 finish 했습니다.\n","epiode #: 66630 loss: 0.32086262106895447 j: 1210000\n","['B'] 종료: env.goal_ob_reward = True ... j = 1210449  move = 32 @ 에피소드 # 66655\n","66655번째 에피소드까지 총 862번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1210885  move = 24 @ 에피소드 # 66683\n","66683번째 에피소드까지 총 863번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 1211550  move = 34 @ 에피소드 # 66720\n","66720번째 에피소드까지 총 864번 finish 했습니다.\n","['J'] 종료: env.goal_ob_reward = True ... j = 1211590  move = 29 @ 에피소드 # 66722\n","66722번째 에피소드까지 총 865번 finish 했습니다.\n","종료: done = True ... j = 1212200  move = 9\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1212850  move = 20 @ 에피소드 # 66778\n","66778번째 에피소드까지 총 866번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 1212979  move = 31 @ 에피소드 # 66784\n","66784번째 에피소드까지 총 867번 finish 했습니다.\n","종료: done = True ... j = 1213000  move = 8\n","종료: done = True ... j = 1213100  move = 12\n","종료: done = True ... j = 1213400  move = 28\n","종료: done = True ... j = 1214200  move = 6\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1214762  move = 40 @ 에피소드 # 66891\n","66891번째 에피소드까지 총 868번 finish 했습니다.\n","종료: done = True ... j = 1214900  move = 19\n","epiode #: 66906 loss: 0.446115106344223 j: 1215000\n","['J'] 종료: env.goal_ob_reward = True ... j = 1215345  move = 30 @ 에피소드 # 66923\n","66923번째 에피소드까지 총 869번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 1215447  move = 22 @ 에피소드 # 66928\n","66928번째 에피소드까지 총 870번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 1216336  move = 50 @ 에피소드 # 66973\n","66973번째 에피소드까지 총 871번 finish 했습니다.\n","종료: done = True ... j = 1216600  move = 22\n","종료: done = True ... j = 1216900  move = 16\n","['J'] 종료: env.goal_ob_reward = True ... j = 1217653  move = 44 @ 에피소드 # 67036\n","67036번째 에피소드까지 총 872번 finish 했습니다.\n","종료: done = True ... j = 1217800  move = 61\n","['H'] 종료: env.goal_ob_reward = True ... j = 1218681  move = 24 @ 에피소드 # 67081\n","67081번째 에피소드까지 총 873번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1218843  move = 79 @ 에피소드 # 67088\n","67088번째 에피소드까지 총 874번 finish 했습니다.\n","['C'] 종료: env.goal_ob_reward = True ... j = 1219644  move = 22 @ 에피소드 # 67132\n","67132번째 에피소드까지 총 875번 finish 했습니다.\n","epiode #: 67148 loss: 0.4039715826511383 j: 1220000\n","종료: done = True ... j = 1220200  move = 14\n","종료: done = True ... j = 1221400  move = 69\n","['N'] 종료: env.goal_ob_reward = True ... j = 1223254  move = 42 @ 에피소드 # 67307\n","67307번째 에피소드까지 총 876번 finish 했습니다.\n","종료: done = True ... j = 1224300  move = 10\n","epiode #: 67381 loss: 0.30683597922325134 j: 1225000\n","종료: done = True ... j = 1226900  move = 8\n","종료: done = True ... j = 1227000  move = 14\n","['A'] 종료: env.goal_ob_reward = True ... j = 1227450  move = 26 @ 에피소드 # 67530\n","67530번째 에피소드까지 총 877번 finish 했습니다.\n","종료: done = True ... j = 1228100  move = 13\n","['O'] 종료: env.goal_ob_reward = True ... j = 1229123  move = 32 @ 에피소드 # 67610\n","67610번째 에피소드까지 총 878번 finish 했습니다.\n","epiode #: 67644 loss: 0.5259080529212952 j: 1230000\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1231017  move = 30 @ 에피소드 # 67695\n","67695번째 에피소드까지 총 879번 finish 했습니다.\n","종료: done = True ... j = 1231100  move = 23\n","['A'] 종료: env.goal_ob_reward = True ... j = 1231375  move = 34 @ 에피소드 # 67713\n","67713번째 에피소드까지 총 880번 finish 했습니다.\n","['C'] 종료: env.goal_ob_reward = True ... j = 1231582  move = 58 @ 에피소드 # 67724\n","67724번째 에피소드까지 총 881번 finish 했습니다.\n","종료: done = True ... j = 1231600  move = 8\n","종료: done = True ... j = 1232300  move = 20\n","['H'] 종료: env.goal_ob_reward = True ... j = 1232536  move = 26 @ 에피소드 # 67789\n","67789번째 에피소드까지 총 882번 finish 했습니다.\n","종료: done = True ... j = 1232800  move = 5\n","['G'] 종료: env.goal_ob_reward = True ... j = 1233867  move = 40 @ 에피소드 # 67862\n","67862번째 에피소드까지 총 883번 finish 했습니다.\n","종료: done = True ... j = 1234100  move = 26\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1234623  move = 16 @ 에피소드 # 67903\n","67903번째 에피소드까지 총 884번 finish 했습니다.\n","epiode #: 67924 loss: 0.5868204236030579 j: 1235000\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1235989  move = 22 @ 에피소드 # 67978\n","67978번째 에피소드까지 총 885번 finish 했습니다.\n","종료: done = True ... j = 1236400  move = 38\n","['O'] 종료: env.goal_ob_reward = True ... j = 1236593  move = 38 @ 에피소드 # 68016\n","68016번째 에피소드까지 총 886번 finish 했습니다.\n","['M'] 종료: env.goal_ob_reward = True ... j = 1237144  move = 55 @ 에피소드 # 68040\n","68040번째 에피소드까지 총 887번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 1239634  move = 24 @ 에피소드 # 68168\n","68168번째 에피소드까지 총 888번 finish 했습니다.\n","epiode #: 68197 loss: 0.40363985300064087 j: 1240000\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1240139  move = 34 @ 에피소드 # 68204\n","68204번째 에피소드까지 총 889번 finish 했습니다.\n","종료: done = True ... j = 1240400  move = 5\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1240828  move = 24 @ 에피소드 # 68234\n","68234번째 에피소드까지 총 890번 finish 했습니다.\n","종료: done = True ... j = 1241400  move = 34\n","종료: done = True ... j = 1242300  move = 39\n","['E'] 종료: env.goal_ob_reward = True ... j = 1242548  move = 78 @ 에피소드 # 68326\n","68326번째 에피소드까지 총 891번 finish 했습니다.\n","종료: done = True ... j = 1243600  move = 5\n","['P'] 종료: env.goal_ob_reward = True ... j = 1243677  move = 77 @ 에피소드 # 68376\n","68376번째 에피소드까지 총 892번 finish 했습니다.\n","['N'] 종료: env.goal_ob_reward = True ... j = 1243719  move = 32 @ 에피소드 # 68378\n","68378번째 에피소드까지 총 893번 finish 했습니다.\n","종료: done = True ... j = 1244400  move = 78\n","epiode #: 68457 loss: 0.5055604577064514 j: 1245000\n","['O'] 종료: env.goal_ob_reward = True ... j = 1245517  move = 28 @ 에피소드 # 68482\n","68482번째 에피소드까지 총 894번 finish 했습니다.\n","종료: done = True ... j = 1246700  move = 9\n","['D'] 종료: env.goal_ob_reward = True ... j = 1247391  move = 38 @ 에피소드 # 68597\n","68597번째 에피소드까지 총 895번 finish 했습니다.\n","['N'] 종료: env.goal_ob_reward = True ... j = 1247997  move = 30 @ 에피소드 # 68624\n","68624번째 에피소드까지 총 896번 finish 했습니다.\n","종료: done = True ... j = 1248000  move = 3\n","종료: done = True ... j = 1248200  move = 19\n","['O'] 종료: env.goal_ob_reward = True ... j = 1248972  move = 30 @ 에피소드 # 68677\n","68677번째 에피소드까지 총 897번 finish 했습니다.\n","epiode #: 68731 loss: 0.5880206823348999 j: 1250000\n","['G'] 종료: env.goal_ob_reward = True ... j = 1250454  move = 80 @ 에피소드 # 68759\n","68759번째 에피소드까지 총 898번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 1250988  move = 43 @ 에피소드 # 68785\n","68785번째 에피소드까지 총 899번 finish 했습니다.\n","종료: done = True ... j = 1252300  move = 8\n","종료: done = True ... j = 1252700  move = 9\n","종료: done = True ... j = 1253100  move = 10\n","['H'] 종료: env.goal_ob_reward = True ... j = 1253640  move = 38 @ 에피소드 # 68946\n","68946번째 에피소드까지 총 900번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 1254039  move = 40 @ 에피소드 # 68968\n","68968번째 에피소드까지 총 901번 finish 했습니다.\n","종료: done = True ... j = 1254900  move = 18\n","epiode #: 69011 loss: 0.19374065101146698 j: 1255000\n","['A'] 종료: env.goal_ob_reward = True ... j = 1255711  move = 18 @ 에피소드 # 69051\n","69051번째 에피소드까지 총 902번 finish 했습니다.\n","['N'] 종료: env.goal_ob_reward = True ... j = 1255917  move = 24 @ 에피소드 # 69057\n","69057번째 에피소드까지 총 903번 finish 했습니다.\n","종료: done = True ... j = 1256300  move = 11\n","종료: done = True ... j = 1256700  move = 8\n","['N'] 종료: env.goal_ob_reward = True ... j = 1257206  move = 28 @ 에피소드 # 69147\n","69147번째 에피소드까지 총 904번 finish 했습니다.\n","종료: done = True ... j = 1257800  move = 4\n","종료: done = True ... j = 1258000  move = 8\n","['H'] 종료: env.goal_ob_reward = True ... j = 1258853  move = 40 @ 에피소드 # 69229\n","69229번째 에피소드까지 총 905번 finish 했습니다.\n","['H'] 종료: env.goal_ob_reward = True ... j = 1259219  move = 28 @ 에피소드 # 69245\n","69245번째 에피소드까지 총 906번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 1259562  move = 45 @ 에피소드 # 69258\n","69258번째 에피소드까지 총 907번 finish 했습니다.\n","epiode #: 69276 loss: 0.29803431034088135 j: 1260000\n","종료: done = True ... j = 1262500  move = 68\n","['P'] 종료: env.goal_ob_reward = True ... j = 1264877  move = 38 @ 에피소드 # 69524\n","69524번째 에피소드까지 총 908번 finish 했습니다.\n","epiode #: 69530 loss: 0.43571737408638 j: 1265000\n","종료: done = True ... j = 1265600  move = 23\n","종료: done = True ... j = 1266000  move = 5\n","종료: done = True ... j = 1266300  move = 7\n","['A'] 종료: env.goal_ob_reward = True ... j = 1266413  move = 22 @ 에피소드 # 69616\n","69616번째 에피소드까지 총 909번 finish 했습니다.\n","['N'] 종료: env.goal_ob_reward = True ... j = 1268840  move = 28 @ 에피소드 # 69752\n","69752번째 에피소드까지 총 910번 finish 했습니다.\n","epiode #: 69816 loss: 0.5357584357261658 j: 1270000\n","종료: done = True ... j = 1270500  move = 54\n","['P'] 종료: env.goal_ob_reward = True ... j = 1271358  move = 34 @ 에피소드 # 69892\n","69892번째 에피소드까지 총 911번 finish 했습니다.\n","종료: done = True ... j = 1273000  move = 25\n","▶ 모델 저장됨!!! @ 에피소드 70000\n","['O'] 종료: env.goal_ob_reward = True ... j = 1274099  move = 31 @ 에피소드 # 70016\n","70016번째 에피소드까지 총 912번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1274522  move = 39 @ 에피소드 # 70040\n","70040번째 에피소드까지 총 913번 finish 했습니다.\n","epiode #: 70066 loss: 0.33694523572921753 j: 1275000\n","['M'] 종료: env.goal_ob_reward = True ... j = 1275835  move = 37 @ 에피소드 # 70104\n","70104번째 에피소드까지 총 914번 finish 했습니다.\n","['H'] 종료: env.goal_ob_reward = True ... j = 1276886  move = 45 @ 에피소드 # 70164\n","70164번째 에피소드까지 총 915번 finish 했습니다.\n","종료: done = True ... j = 1277100  move = 6\n","['G'] 종료: env.goal_ob_reward = True ... j = 1278048  move = 38 @ 에피소드 # 70236\n","70236번째 에피소드까지 총 916번 finish 했습니다.\n","['D'] 종료: env.goal_ob_reward = True ... j = 1278642  move = 50 @ 에피소드 # 70264\n","70264번째 에피소드까지 총 917번 finish 했습니다.\n","epiode #: 70333 loss: 0.3682275414466858 j: 1280000\n","['G'] 종료: env.goal_ob_reward = True ... j = 1280049  move = 30 @ 에피소드 # 70337\n","70337번째 에피소드까지 총 918번 finish 했습니다.\n","종료: done = True ... j = 1281800  move = 58\n","종료: done = True ... j = 1281900  move = 7\n","['N'] 종료: env.goal_ob_reward = True ... j = 1282094  move = 32 @ 에피소드 # 70450\n","70450번째 에피소드까지 총 919번 finish 했습니다.\n","종료: done = True ... j = 1283100  move = 3\n","종료: done = True ... j = 1283200  move = 5\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1284184  move = 20 @ 에피소드 # 70558\n","70558번째 에피소드까지 총 920번 finish 했습니다.\n","['H'] 종료: env.goal_ob_reward = True ... j = 1284358  move = 28 @ 에피소드 # 70565\n","70565번째 에피소드까지 총 921번 finish 했습니다.\n","['K'] 종료: env.goal_ob_reward = True ... j = 1284438  move = 34 @ 에피소드 # 70568\n","70568번째 에피소드까지 총 922번 finish 했습니다.\n","종료: done = True ... j = 1284500  move = 21\n","epiode #: 70599 loss: 0.47016653418540955 j: 1285000\n","['K'] 종료: env.goal_ob_reward = True ... j = 1285112  move = 26 @ 에피소드 # 70604\n","70604번째 에피소드까지 총 923번 finish 했습니다.\n","종료: done = True ... j = 1285500  move = 10\n","종료: done = True ... j = 1287500  move = 7\n","['B'] 종료: env.goal_ob_reward = True ... j = 1287883  move = 28 @ 에피소드 # 70738\n","70738번째 에피소드까지 총 924번 finish 했습니다.\n","종료: done = True ... j = 1288100  move = 30\n","['P'] 종료: env.goal_ob_reward = True ... j = 1289587  move = 39 @ 에피소드 # 70838\n","70838번째 에피소드까지 총 925번 finish 했습니다.\n","종료: done = True ... j = 1289800  move = 11\n","epiode #: 70863 loss: 0.49017688632011414 j: 1290000\n","['A'] 종료: env.goal_ob_reward = True ... j = 1290716  move = 28 @ 에피소드 # 70897\n","70897번째 에피소드까지 총 926번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1291651  move = 24 @ 에피소드 # 70943\n","70943번째 에피소드까지 총 927번 finish 했습니다.\n","['J'] 종료: env.goal_ob_reward = True ... j = 1292304  move = 37 @ 에피소드 # 70966\n","70966번째 에피소드까지 총 928번 finish 했습니다.\n","['I'] 종료: env.goal_ob_reward = True ... j = 1292727  move = 37 @ 에피소드 # 70988\n","70988번째 에피소드까지 총 929번 finish 했습니다.\n","['I'] 종료: env.goal_ob_reward = True ... j = 1293071  move = 54 @ 에피소드 # 71006\n","71006번째 에피소드까지 총 930번 finish 했습니다.\n","['I'] 종료: env.goal_ob_reward = True ... j = 1293182  move = 34 @ 에피소드 # 71011\n","71011번째 에피소드까지 총 931번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 1293247  move = 65 @ 에피소드 # 71012\n","71012번째 에피소드까지 총 932번 finish 했습니다.\n","epiode #: 71105 loss: 0.19948109984397888 j: 1295000\n","종료: done = True ... j = 1295100  move = 10\n","종료: done = True ... j = 1295500  move = 49\n","['O'] 종료: env.goal_ob_reward = True ... j = 1295715  move = 60 @ 에피소드 # 71151\n","71151번째 에피소드까지 총 933번 finish 했습니다.\n","종료: done = True ... j = 1296000  move = 38\n","종료: done = True ... j = 1297100  move = 7\n","종료: done = True ... j = 1297700  move = 43\n","['N'] 종료: env.goal_ob_reward = True ... j = 1298001  move = 32 @ 에피소드 # 71281\n","71281번째 에피소드까지 총 934번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 1298563  move = 20 @ 에피소드 # 71308\n","71308번째 에피소드까지 총 935번 finish 했습니다.\n","종료: done = True ... j = 1298700  move = 19\n","종료: done = True ... j = 1299300  move = 10\n","epiode #: 71389 loss: 0.42907553911209106 j: 1300000\n","종료: done = True ... j = 1300700  move = 5\n","종료: done = True ... j = 1300900  move = 43\n","종료: done = True ... j = 1301900  move = 14\n","['A'] 종료: env.goal_ob_reward = True ... j = 1302583  move = 58 @ 에피소드 # 71532\n","71532번째 에피소드까지 총 936번 finish 했습니다.\n","['N'] 종료: env.goal_ob_reward = True ... j = 1303158  move = 81 @ 에피소드 # 71562\n","71562번째 에피소드까지 총 937번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 1303413  move = 65 @ 에피소드 # 71572\n","71572번째 에피소드까지 총 938번 finish 했습니다.\n","종료: done = True ... j = 1303500  move = 15\n","epiode #: 71661 loss: 0.4126313030719757 j: 1305000\n","종료: done = True ... j = 1306400  move = 39\n","['I'] 종료: env.goal_ob_reward = True ... j = 1306437  move = 32 @ 에피소드 # 71733\n","71733번째 에피소드까지 총 939번 finish 했습니다.\n","종료: done = True ... j = 1307400  move = 86\n","['A'] 종료: env.goal_ob_reward = True ... j = 1307416  move = 16 @ 에피소드 # 71790\n","71790번째 에피소드까지 총 940번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1307930  move = 40 @ 에피소드 # 71820\n","71820번째 에피소드까지 총 941번 finish 했습니다.\n","종료: done = True ... j = 1309100  move = 26\n","종료: done = True ... j = 1309300  move = 7\n","['H'] 종료: env.goal_ob_reward = True ... j = 1309539  move = 29 @ 에피소드 # 71894\n","71894번째 에피소드까지 총 942번 finish 했습니다.\n","epiode #: 71917 loss: 0.4990142583847046 j: 1310000\n","['E'] 종료: env.goal_ob_reward = True ... j = 1310210  move = 34 @ 에피소드 # 71926\n","71926번째 에피소드까지 총 943번 finish 했습니다.\n","['M'] 종료: env.goal_ob_reward = True ... j = 1310441  move = 62 @ 에피소드 # 71937\n","71937번째 에피소드까지 총 944번 finish 했습니다.\n","종료: done = True ... j = 1310800  move = 7\n","['B'] 종료: env.goal_ob_reward = True ... j = 1311448  move = 20 @ 에피소드 # 71979\n","71979번째 에피소드까지 총 945번 finish 했습니다.\n","종료: done = True ... j = 1312000  move = 43\n","['A'] 종료: env.goal_ob_reward = True ... j = 1312843  move = 96 @ 에피소드 # 72047\n","72047번째 에피소드까지 총 946번 finish 했습니다.\n","['G'] 종료: env.goal_ob_reward = True ... j = 1314177  move = 37 @ 에피소드 # 72119\n","72119번째 에피소드까지 총 947번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1314215  move = 38 @ 에피소드 # 72120\n","72120번째 에피소드까지 총 948번 finish 했습니다.\n","epiode #: 72170 loss: 0.4651411771774292 j: 1315000\n","['J'] 종료: env.goal_ob_reward = True ... j = 1315012  move = 48 @ 에피소드 # 72170\n","72170번째 에피소드까지 총 949번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 1315284  move = 32 @ 에피소드 # 72178\n","72178번째 에피소드까지 총 950번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1317449  move = 18 @ 에피소드 # 72298\n","72298번째 에피소드까지 총 951번 finish 했습니다.\n","['J'] 종료: env.goal_ob_reward = True ... j = 1317662  move = 44 @ 에피소드 # 72306\n","72306번째 에피소드까지 총 952번 finish 했습니다.\n","종료: done = True ... j = 1318900  move = 14\n","종료: done = True ... j = 1319800  move = 17\n","epiode #: 72418 loss: 0.22239509224891663 j: 1320000\n","종료: done = True ... j = 1321800  move = 26\n","['A'] 종료: env.goal_ob_reward = True ... j = 1321889  move = 18 @ 에피소드 # 72515\n","72515번째 에피소드까지 총 953번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 1322461  move = 46 @ 에피소드 # 72540\n","72540번째 에피소드까지 총 954번 finish 했습니다.\n","['N'] 종료: env.goal_ob_reward = True ... j = 1323106  move = 32 @ 에피소드 # 72576\n","72576번째 에피소드까지 총 955번 finish 했습니다.\n","['N'] 종료: env.goal_ob_reward = True ... j = 1323216  move = 41 @ 에피소드 # 72583\n","72583번째 에피소드까지 총 956번 finish 했습니다.\n","종료: done = True ... j = 1324000  move = 17\n","종료: done = True ... j = 1324200  move = 8\n","종료: done = True ... j = 1324400  move = 23\n","['P'] 종료: env.goal_ob_reward = True ... j = 1324589  move = 64 @ 에피소드 # 72676\n","72676번째 에피소드까지 총 957번 finish 했습니다.\n","epiode #: 72700 loss: 0.578500509262085 j: 1325000\n","종료: done = True ... j = 1325100  move = 19\n","종료: done = True ... j = 1325300  move = 3\n","종료: done = True ... j = 1326200  move = 21\n","['C'] 종료: env.goal_ob_reward = True ... j = 1326579  move = 26 @ 에피소드 # 72786\n","72786번째 에피소드까지 총 958번 finish 했습니다.\n","['M'] 종료: env.goal_ob_reward = True ... j = 1327549  move = 69 @ 에피소드 # 72842\n","72842번째 에피소드까지 총 959번 finish 했습니다.\n","종료: done = True ... j = 1327800  move = 5\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1329108  move = 26 @ 에피소드 # 72932\n","72932번째 에피소드까지 총 960번 finish 했습니다.\n","종료: done = True ... j = 1329200  move = 25\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1329271  move = 16 @ 에피소드 # 72939\n","72939번째 에피소드까지 총 961번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1329912  move = 46 @ 에피소드 # 72975\n","72975번째 에피소드까지 총 962번 finish 했습니다.\n","epiode #: 72978 loss: 0.5397102236747742 j: 1330000\n","['L'] 종료: env.goal_ob_reward = True ... j = 1333149  move = 28 @ 에피소드 # 73117\n","73117번째 에피소드까지 총 963번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 1333319  move = 16 @ 에피소드 # 73127\n","73127번째 에피소드까지 총 964번 finish 했습니다.\n","['F'] 종료: env.goal_ob_reward = True ... j = 1334290  move = 92 @ 에피소드 # 73175\n","73175번째 에피소드까지 총 965번 finish 했습니다.\n","epiode #: 73209 loss: 0.567150890827179 j: 1335000\n","종료: done = True ... j = 1336800  move = 7\n","종료: done = True ... j = 1337400  move = 5\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1337586  move = 22 @ 에피소드 # 73358\n","73358번째 에피소드까지 총 966번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 1338009  move = 46 @ 에피소드 # 73379\n","73379번째 에피소드까지 총 967번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1338546  move = 30 @ 에피소드 # 73418\n","73418번째 에피소드까지 총 968번 finish 했습니다.\n","['H'] 종료: env.goal_ob_reward = True ... j = 1339203  move = 31 @ 에피소드 # 73460\n","73460번째 에피소드까지 총 969번 finish 했습니다.\n","epiode #: 73504 loss: 0.13005171716213226 j: 1340000\n","['O'] 종료: env.goal_ob_reward = True ... j = 1340992  move = 34 @ 에피소드 # 73553\n","73553번째 에피소드까지 총 970번 finish 했습니다.\n","['D'] 종료: env.goal_ob_reward = True ... j = 1341327  move = 32 @ 에피소드 # 73571\n","73571번째 에피소드까지 총 971번 finish 했습니다.\n","['N'] 종료: env.goal_ob_reward = True ... j = 1341646  move = 49 @ 에피소드 # 73593\n","73593번째 에피소드까지 총 972번 finish 했습니다.\n","['F'] 종료: env.goal_ob_reward = True ... j = 1342088  move = 57 @ 에피소드 # 73617\n","73617번째 에피소드까지 총 973번 finish 했습니다.\n","종료: done = True ... j = 1343500  move = 14\n","종료: done = True ... j = 1344800  move = 3\n","epiode #: 73779 loss: 0.389957070350647 j: 1345000\n","['K'] 종료: env.goal_ob_reward = True ... j = 1345288  move = 34 @ 에피소드 # 73791\n","73791번째 에피소드까지 총 974번 finish 했습니다.\n","['N'] 종료: env.goal_ob_reward = True ... j = 1345736  move = 56 @ 에피소드 # 73811\n","73811번째 에피소드까지 총 975번 finish 했습니다.\n","종료: done = True ... j = 1346100  move = 23\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1346470  move = 16 @ 에피소드 # 73854\n","73854번째 에피소드까지 총 976번 finish 했습니다.\n","종료: done = True ... j = 1348300  move = 8\n","종료: done = True ... j = 1349100  move = 39\n","종료: done = True ... j = 1349800  move = 87\n","epiode #: 74038 loss: 0.3427843451499939 j: 1350000\n","['I'] 종료: env.goal_ob_reward = True ... j = 1350108  move = 45 @ 에피소드 # 74044\n","74044번째 에피소드까지 총 977번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1350186  move = 48 @ 에피소드 # 74047\n","74047번째 에피소드까지 총 978번 finish 했습니다.\n","종료: done = True ... j = 1351700  move = 9\n","['A'] 종료: env.goal_ob_reward = True ... j = 1351845  move = 48 @ 에피소드 # 74127\n","74127번째 에피소드까지 총 979번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 1352734  move = 50 @ 에피소드 # 74167\n","74167번째 에피소드까지 총 980번 finish 했습니다.\n","종료: done = True ... j = 1352800  move = 23\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1353240  move = 34 @ 에피소드 # 74199\n","74199번째 에피소드까지 총 981번 finish 했습니다.\n","종료: done = True ... j = 1353700  move = 54\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1354092  move = 46 @ 에피소드 # 74253\n","74253번째 에피소드까지 총 982번 finish 했습니다.\n","종료: done = True ... j = 1354300  move = 7\n","epiode #: 74303 loss: 0.41121843457221985 j: 1355000\n","종료: done = True ... j = 1356000  move = 7\n","['D'] 종료: env.goal_ob_reward = True ... j = 1356226  move = 32 @ 에피소드 # 74384\n","74384번째 에피소드까지 총 983번 finish 했습니다.\n","종료: done = True ... j = 1356600  move = 7\n","['B'] 종료: env.goal_ob_reward = True ... j = 1357273  move = 21 @ 에피소드 # 74447\n","74447번째 에피소드까지 총 984번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 1358185  move = 35 @ 에피소드 # 74506\n","74506번째 에피소드까지 총 985번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1359783  move = 26 @ 에피소드 # 74589\n","74589번째 에피소드까지 총 986번 finish 했습니다.\n","epiode #: 74599 loss: 0.20926468074321747 j: 1360000\n","['G'] 종료: env.goal_ob_reward = True ... j = 1360655  move = 24 @ 에피소드 # 74639\n","74639번째 에피소드까지 총 987번 finish 했습니다.\n","종료: done = True ... j = 1362200  move = 11\n","종료: done = True ... j = 1363300  move = 15\n","epiode #: 74862 loss: 0.41144630312919617 j: 1365000\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1365557  move = 20 @ 에피소드 # 74894\n","74894번째 에피소드까지 총 988번 finish 했습니다.\n","종료: done = True ... j = 1366500  move = 3\n","['F'] 종료: env.goal_ob_reward = True ... j = 1367075  move = 36 @ 에피소드 # 74962\n","74962번째 에피소드까지 총 989번 finish 했습니다.\n","['C'] 종료: env.goal_ob_reward = True ... j = 1367258  move = 37 @ 에피소드 # 74974\n","74974번째 에피소드까지 총 990번 finish 했습니다.\n","['K'] 종료: env.goal_ob_reward = True ... j = 1367367  move = 40 @ 에피소드 # 74979\n","74979번째 에피소드까지 총 991번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 1367759  move = 20 @ 에피소드 # 75005\n","75005번째 에피소드까지 총 992번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 1368233  move = 50 @ 에피소드 # 75023\n","75023번째 에피소드까지 총 993번 finish 했습니다.\n","종료: done = True ... j = 1369800  move = 11\n","epiode #: 75100 loss: 0.4946889281272888 j: 1370000\n","종료: done = True ... j = 1371400  move = 88\n","['F'] 종료: env.goal_ob_reward = True ... j = 1372260  move = 64 @ 에피소드 # 75209\n","75209번째 에피소드까지 총 994번 finish 했습니다.\n","['C'] 종료: env.goal_ob_reward = True ... j = 1373048  move = 29 @ 에피소드 # 75251\n","75251번째 에피소드까지 총 995번 finish 했습니다.\n","['C'] 종료: env.goal_ob_reward = True ... j = 1373893  move = 22 @ 에피소드 # 75298\n","75298번째 에피소드까지 총 996번 finish 했습니다.\n","종료: done = True ... j = 1374500  move = 4\n","종료: done = True ... j = 1374700  move = 5\n","epiode #: 75356 loss: 0.4633244276046753 j: 1375000\n","종료: done = True ... j = 1375000  move = 11\n","['C'] 종료: env.goal_ob_reward = True ... j = 1375238  move = 64 @ 에피소드 # 75367\n","75367번째 에피소드까지 총 997번 finish 했습니다.\n","종료: done = True ... j = 1375300  move = 8\n","종료: done = True ... j = 1377300  move = 11\n","종료: done = True ... j = 1379600  move = 10\n","['C'] 종료: env.goal_ob_reward = True ... j = 1379787  move = 63 @ 에피소드 # 75621\n","75621번째 에피소드까지 총 998번 finish 했습니다.\n","['F'] 종료: env.goal_ob_reward = True ... j = 1379941  move = 30 @ 에피소드 # 75630\n","75630번째 에피소드까지 총 999번 finish 했습니다.\n","epiode #: 75633 loss: 0.4135584533214569 j: 1380000\n","종료: done = True ... j = 1380000  move = 20\n","['P'] 종료: env.goal_ob_reward = True ... j = 1380468  move = 45 @ 에피소드 # 75661\n","75661번째 에피소드까지 총 1000번 finish 했습니다.\n","['N'] 종료: env.goal_ob_reward = True ... j = 1381707  move = 28 @ 에피소드 # 75715\n","75715번째 에피소드까지 총 1001번 finish 했습니다.\n","['N'] 종료: env.goal_ob_reward = True ... j = 1382674  move = 78 @ 에피소드 # 75763\n","75763번째 에피소드까지 총 1002번 finish 했습니다.\n","['K'] 종료: env.goal_ob_reward = True ... j = 1383171  move = 32 @ 에피소드 # 75785\n","75785번째 에피소드까지 총 1003번 finish 했습니다.\n","['K'] 종료: env.goal_ob_reward = True ... j = 1383414  move = 22 @ 에피소드 # 75800\n","75800번째 에피소드까지 총 1004번 finish 했습니다.\n","epiode #: 75881 loss: 0.3509630262851715 j: 1385000\n","종료: done = True ... j = 1385000  move = 7\n","종료: done = True ... j = 1385100  move = 30\n","종료: done = True ... j = 1385200  move = 15\n","종료: done = True ... j = 1387500  move = 44\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1387918  move = 40 @ 에피소드 # 76026\n","76026번째 에피소드까지 총 1005번 finish 했습니다.\n","종료: done = True ... j = 1388000  move = 8\n","['G'] 종료: env.goal_ob_reward = True ... j = 1388063  move = 30 @ 에피소드 # 76033\n","76033번째 에피소드까지 총 1006번 finish 했습니다.\n","['L'] 종료: env.goal_ob_reward = True ... j = 1388236  move = 63 @ 에피소드 # 76044\n","76044번째 에피소드까지 총 1007번 finish 했습니다.\n","['H'] 종료: env.goal_ob_reward = True ... j = 1389433  move = 28 @ 에피소드 # 76114\n","76114번째 에피소드까지 총 1008번 finish 했습니다.\n","epiode #: 76137 loss: 0.4445202648639679 j: 1390000\n","['K'] 종료: env.goal_ob_reward = True ... j = 1390605  move = 58 @ 에피소드 # 76170\n","76170번째 에피소드까지 총 1009번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 1391210  move = 60 @ 에피소드 # 76200\n","76200번째 에피소드까지 총 1010번 finish 했습니다.\n","['F'] 종료: env.goal_ob_reward = True ... j = 1391989  move = 61 @ 에피소드 # 76243\n","76243번째 에피소드까지 총 1011번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 1392052  move = 20 @ 에피소드 # 76245\n","76245번째 에피소드까지 총 1012번 finish 했습니다.\n","['G'] 종료: env.goal_ob_reward = True ... j = 1392229  move = 50 @ 에피소드 # 76253\n","76253번째 에피소드까지 총 1013번 finish 했습니다.\n","epiode #: 76411 loss: 0.5564689040184021 j: 1395000\n","['B'] 종료: env.goal_ob_reward = True ... j = 1395009  move = 22 @ 에피소드 # 76411\n","76411번째 에피소드까지 총 1014번 finish 했습니다.\n","['M'] 종료: env.goal_ob_reward = True ... j = 1396852  move = 34 @ 에피소드 # 76517\n","76517번째 에피소드까지 총 1015번 finish 했습니다.\n","종료: done = True ... j = 1397500  move = 27\n","종료: done = True ... j = 1398500  move = 43\n","['J'] 종료: env.goal_ob_reward = True ... j = 1398789  move = 36 @ 에피소드 # 76624\n","76624번째 에피소드까지 총 1016번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 1399837  move = 26 @ 에피소드 # 76676\n","76676번째 에피소드까지 총 1017번 finish 했습니다.\n","epiode #: 76685 loss: 0.5351080298423767 j: 1400000\n","['J'] 종료: env.goal_ob_reward = True ... j = 1402957  move = 44 @ 에피소드 # 76845\n","76845번째 에피소드까지 총 1018번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1403545  move = 38 @ 에피소드 # 76873\n","76873번째 에피소드까지 총 1019번 finish 했습니다.\n","종료: done = True ... j = 1403600  move = 18\n","종료: done = True ... j = 1404200  move = 9\n","['D'] 종료: env.goal_ob_reward = True ... j = 1404751  move = 31 @ 에피소드 # 76939\n","76939번째 에피소드까지 총 1020번 finish 했습니다.\n","epiode #: 76953 loss: 0.5398502349853516 j: 1405000\n","['A'] 종료: env.goal_ob_reward = True ... j = 1406431  move = 34 @ 에피소드 # 77038\n","77038번째 에피소드까지 총 1021번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1407442  move = 38 @ 에피소드 # 77091\n","77091번째 에피소드까지 총 1022번 finish 했습니다.\n","['F'] 종료: env.goal_ob_reward = True ... j = 1407468  move = 26 @ 에피소드 # 77092\n","77092번째 에피소드까지 총 1023번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 1407588  move = 33 @ 에피소드 # 77098\n","77098번째 에피소드까지 총 1024번 finish 했습니다.\n","['M'] 종료: env.goal_ob_reward = True ... j = 1407699  move = 43 @ 에피소드 # 77103\n","77103번째 에피소드까지 총 1025번 finish 했습니다.\n","종료: done = True ... j = 1407900  move = 46\n","['A'] 종료: env.goal_ob_reward = True ... j = 1408132  move = 34 @ 에피소드 # 77129\n","77129번째 에피소드까지 총 1026번 finish 했습니다.\n","['C'] 종료: env.goal_ob_reward = True ... j = 1408254  move = 22 @ 에피소드 # 77135\n","77135번째 에피소드까지 총 1027번 finish 했습니다.\n","['I'] 종료: env.goal_ob_reward = True ... j = 1408645  move = 42 @ 에피소드 # 77154\n","77154번째 에피소드까지 총 1028번 finish 했습니다.\n","['D'] 종료: env.goal_ob_reward = True ... j = 1409180  move = 50 @ 에피소드 # 77188\n","77188번째 에피소드까지 총 1029번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 1409975  move = 26 @ 에피소드 # 77228\n","77228번째 에피소드까지 총 1030번 finish 했습니다.\n","epiode #: 77230 loss: 0.4568220376968384 j: 1410000\n","['H'] 종료: env.goal_ob_reward = True ... j = 1410171  move = 34 @ 에피소드 # 77233\n","77233번째 에피소드까지 총 1031번 finish 했습니다.\n","['O'] 종료: env.goal_ob_reward = True ... j = 1411770  move = 26 @ 에피소드 # 77319\n","77319번째 에피소드까지 총 1032번 finish 했습니다.\n","['I'] 종료: env.goal_ob_reward = True ... j = 1412138  move = 36 @ 에피소드 # 77343\n","77343번째 에피소드까지 총 1033번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1412890  move = 26 @ 에피소드 # 77385\n","77385번째 에피소드까지 총 1034번 finish 했습니다.\n","종료: done = True ... j = 1413700  move = 22\n","종료: done = True ... j = 1414600  move = 31\n","epiode #: 77500 loss: 0.7369039058685303 j: 1415000\n","종료: done = True ... j = 1415500  move = 8\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1416367  move = 32 @ 에피소드 # 77576\n","77576번째 에피소드까지 총 1035번 finish 했습니다.\n","종료: done = True ... j = 1416800  move = 6\n","['P'] 종료: env.goal_ob_reward = True ... j = 1416892  move = 30 @ 에피소드 # 77607\n","77607번째 에피소드까지 총 1036번 finish 했습니다.\n","['K'] 종료: env.goal_ob_reward = True ... j = 1416952  move = 47 @ 에피소드 # 77611\n","77611번째 에피소드까지 총 1037번 finish 했습니다.\n","['F'] 종료: env.goal_ob_reward = True ... j = 1418137  move = 32 @ 에피소드 # 77670\n","77670번째 에피소드까지 총 1038번 finish 했습니다.\n","['K'] 종료: env.goal_ob_reward = True ... j = 1418894  move = 42 @ 에피소드 # 77707\n","77707번째 에피소드까지 총 1039번 finish 했습니다.\n","종료: done = True ... j = 1419400  move = 11\n","['P'] 종료: env.goal_ob_reward = True ... j = 1419688  move = 36 @ 에피소드 # 77761\n","77761번째 에피소드까지 총 1040번 finish 했습니다.\n","epiode #: 77777 loss: 0.5329890251159668 j: 1420000\n","['B'] 종료: env.goal_ob_reward = True ... j = 1420168  move = 28 @ 에피소드 # 77791\n","77791번째 에피소드까지 총 1041번 finish 했습니다.\n","['I'] 종료: env.goal_ob_reward = True ... j = 1420271  move = 66 @ 에피소드 # 77795\n","77795번째 에피소드까지 총 1042번 finish 했습니다.\n","['F'] 종료: env.goal_ob_reward = True ... j = 1420323  move = 52 @ 에피소드 # 77796\n","77796번째 에피소드까지 총 1043번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1421541  move = 46 @ 에피소드 # 77866\n","77866번째 에피소드까지 총 1044번 finish 했습니다.\n","종료: done = True ... j = 1421900  move = 50\n","종료: done = True ... j = 1422700  move = 25\n","['B'] 종료: env.goal_ob_reward = True ... j = 1423259  move = 26 @ 에피소드 # 77967\n","77967번째 에피소드까지 총 1045번 finish 했습니다.\n","종료: done = True ... j = 1423400  move = 16\n","['M'] 종료: env.goal_ob_reward = True ... j = 1423466  move = 66 @ 에피소드 # 77974\n","77974번째 에피소드까지 총 1046번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1424017  move = 24 @ 에피소드 # 78000\n","78000번째 에피소드까지 총 1047번 finish 했습니다.\n","종료: done = True ... j = 1424100  move = 5\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1424176  move = 45 @ 에피소드 # 78011\n","78011번째 에피소드까지 총 1048번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 1424350  move = 29 @ 에피소드 # 78023\n","78023번째 에피소드까지 총 1049번 finish 했습니다.\n","epiode #: 78055 loss: 0.6044450402259827 j: 1425000\n","['P'] 종료: env.goal_ob_reward = True ... j = 1425001  move = 32 @ 에피소드 # 78055\n","78055번째 에피소드까지 총 1050번 finish 했습니다.\n","['G'] 종료: env.goal_ob_reward = True ... j = 1425141  move = 26 @ 에피소드 # 78067\n","78067번째 에피소드까지 총 1051번 finish 했습니다.\n","['K'] 종료: env.goal_ob_reward = True ... j = 1426182  move = 31 @ 에피소드 # 78129\n","78129번째 에피소드까지 총 1052번 finish 했습니다.\n","['M'] 종료: env.goal_ob_reward = True ... j = 1426306  move = 96 @ 에피소드 # 78132\n","78132번째 에피소드까지 총 1053번 finish 했습니다.\n","종료: done = True ... j = 1427800  move = 51\n","종료: done = True ... j = 1428500  move = 7\n","epiode #: 78320 loss: 0.26358792185783386 j: 1430000\n","종료: done = True ... j = 1430200  move = 10\n","종료: done = True ... j = 1430300  move = 6\n","['A'] 종료: env.goal_ob_reward = True ... j = 1431109  move = 22 @ 에피소드 # 78380\n","78380번째 에피소드까지 총 1054번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 1432229  move = 30 @ 에피소드 # 78423\n","78423번째 에피소드까지 총 1055번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 1432956  move = 33 @ 에피소드 # 78460\n","78460번째 에피소드까지 총 1056번 finish 했습니다.\n","['P'] 종료: env.goal_ob_reward = True ... j = 1434793  move = 41 @ 에피소드 # 78557\n","78557번째 에피소드까지 총 1057번 finish 했습니다.\n","epiode #: 78569 loss: 0.3678185045719147 j: 1435000\n","종료: done = True ... j = 1435500  move = 5\n","종료: done = True ... j = 1435900  move = 3\n","['A'] 종료: env.goal_ob_reward = True ... j = 1436501  move = 40 @ 에피소드 # 78637\n","78637번째 에피소드까지 총 1058번 finish 했습니다.\n","종료: done = True ... j = 1436600  move = 40\n","['F'] 종료: env.goal_ob_reward = True ... j = 1436600  move = 40 @ 에피소드 # 78644\n","78644번째 에피소드까지 총 1059번 finish 했습니다.\n","종료: done = True ... j = 1439200  move = 3\n","epiode #: 78833 loss: 0.7603066563606262 j: 1440000\n","['A'] 종료: env.goal_ob_reward = True ... j = 1440183  move = 26 @ 에피소드 # 78839\n","78839번째 에피소드까지 총 1060번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1440697  move = 18 @ 에피소드 # 78859\n","78859번째 에피소드까지 총 1061번 finish 했습니다.\n","['E'] 종료: env.goal_ob_reward = True ... j = 1444350  move = 31 @ 에피소드 # 79055\n","79055번째 에피소드까지 총 1062번 finish 했습니다.\n","종료: done = True ... j = 1444400  move = 11\n","epiode #: 79091 loss: 0.2926276922225952 j: 1445000\n","['F'] 종료: env.goal_ob_reward = True ... j = 1445461  move = 40 @ 에피소드 # 79117\n","79117번째 에피소드까지 총 1063번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1445869  move = 38 @ 에피소드 # 79139\n","79139번째 에피소드까지 총 1064번 finish 했습니다.\n","['F'] 종료: env.goal_ob_reward = True ... j = 1446188  move = 30 @ 에피소드 # 79158\n","79158번째 에피소드까지 총 1065번 finish 했습니다.\n","['F'] 종료: env.goal_ob_reward = True ... j = 1446898  move = 25 @ 에피소드 # 79188\n","79188번째 에피소드까지 총 1066번 finish 했습니다.\n","['C'] 종료: env.goal_ob_reward = True ... j = 1447033  move = 31 @ 에피소드 # 79198\n","79198번째 에피소드까지 총 1067번 finish 했습니다.\n","['F'] 종료: env.goal_ob_reward = True ... j = 1447180  move = 44 @ 에피소드 # 79203\n","79203번째 에피소드까지 총 1068번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 1447438  move = 83 @ 에피소드 # 79216\n","79216번째 에피소드까지 총 1069번 finish 했습니다.\n","['M'] 종료: env.goal_ob_reward = True ... j = 1447762  move = 91 @ 에피소드 # 79236\n","79236번째 에피소드까지 총 1070번 finish 했습니다.\n","['L'] 종료: env.goal_ob_reward = True ... j = 1449270  move = 30 @ 에피소드 # 79311\n","79311번째 에피소드까지 총 1071번 finish 했습니다.\n","epiode #: 79358 loss: 0.3065182566642761 j: 1450000\n","['K'] 종료: env.goal_ob_reward = True ... j = 1450712  move = 36 @ 에피소드 # 79392\n","79392번째 에피소드까지 총 1072번 finish 했습니다.\n","종료: done = True ... j = 1451600  move = 27\n","종료: done = True ... j = 1451800  move = 6\n","['F'] 종료: env.goal_ob_reward = True ... j = 1451842  move = 42 @ 에피소드 # 79454\n","79454번째 에피소드까지 총 1073번 finish 했습니다.\n","['B'] 종료: env.goal_ob_reward = True ... j = 1452351  move = 24 @ 에피소드 # 79482\n","79482번째 에피소드까지 총 1074번 finish 했습니다.\n","종료: done = True ... j = 1454700  move = 9\n","['A'] 종료: env.goal_ob_reward = True ... j = 1454874  move = 63 @ 에피소드 # 79630\n","79630번째 에피소드까지 총 1075번 finish 했습니다.\n","epiode #: 79637 loss: 0.37769293785095215 j: 1455000\n","종료: done = True ... j = 1455400  move = 5\n","종료: done = True ... j = 1455500  move = 14\n","['H'] 종료: env.goal_ob_reward = True ... j = 1455932  move = 26 @ 에피소드 # 79689\n","79689번째 에피소드까지 총 1076번 finish 했습니다.\n","['A'] 종료: env.goal_ob_reward = True ... j = 1458126  move = 72 @ 에피소드 # 79809\n","79809번째 에피소드까지 총 1077번 finish 했습니다.\n","['Q'] 종료: env.goal_ob_reward = True ... j = 1458896  move = 48 @ 에피소드 # 79843\n","79843번째 에피소드까지 총 1078번 finish 했습니다.\n","종료: done = True ... j = 1459100  move = 20\n","종료: done = True ... j = 1459700  move = 8\n","['K'] 종료: env.goal_ob_reward = True ... j = 1459856  move = 47 @ 에피소드 # 79892\n","79892번째 에피소드까지 총 1079번 finish 했습니다.\n","epiode #: 79899 loss: 0.370725154876709 j: 1460000\n","종료: done = True ... j = 1460100  move = 8\n","['B'] 종료: env.goal_ob_reward = True ... j = 1460485  move = 35 @ 에피소드 # 79925\n","79925번째 에피소드까지 총 1080번 finish 했습니다.\n","['H'] 종료: env.goal_ob_reward = True ... j = 1461303  move = 40 @ 에피소드 # 79966\n","79966번째 에피소드까지 총 1081번 finish 했습니다.\n","▶ 모델 저장됨!!! @ 에피소드 79999\n","실행 종료! Start@ 16:17:44 End@ 22:09:36\n","[[ -1.  -1.  -1.  10.  -1.  -1.  -1.  -1.  -1.]\n"," [  0.   0.   0.   0.   0.   0.   0.   0.   0.]\n"," [ -1.   0.   0.   0.   0.   0.   0.   0.  -1.]\n"," [ -1.   0. -10.   0.   1.   0. -10.   0.  -1.]\n"," [ -1.   0. -10.   0. -10.   0. -10.   0.  -1.]\n"," [ -1.   0. -10.   0. -10.   0. -10.   0.  -1.]\n"," [  0.   0. -10.   0. -10.   0. -10.   0.   0.]\n"," [  0.   0.   0.   0.   0.   0.   0.   0.   0.]\n"," [  0.   0.   0.   0.   0.   0.   0.   0.   0.]\n"," [-10. -10. -10. -10.   9. -10. -10. -10. -10.]]\n"]},{"output_type":"execute_result","data":{"text/plain":["Text(0, 0.5, 'Cumulative Rewards')"]},"metadata":{},"execution_count":4},{"output_type":"display_data","data":{"text/plain":["<Figure size 720x504 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAmsAAAGzCAYAAABwyVA7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd5hTZd7G8ftH76ACFooogl1EUQEbdlDXtta17lrWvr521pW1t113XXuvq6yKDQXBBiK9gzSpw9A7Qx2GmXneP5IMqZNMJsk5zHw/1zUXycnJycOZTHKfp5pzTgAAAPCnGl4XAAAAAIkR1gAAAHyMsAYAAOBjhDUAAAAfI6wBAAD4WC2vC5AtzZs3d+3atfO6GAAAAElNmDBhtXOuRbzHqmxYa9euncaPH+91MQAAAJIys4WJHqMZFAAAwMcIawAAAD5GWAMAAPAxwhoAAICPEdYAAAB8jLAGAADgY4Q1AAAAHyOsAQAA+BhhDQAAwMcIawAAAD5GWAMAAPAxwhoAAICPEdYAAAB8jLAGAADgY4S1DNhaVKKi4lKviwEAAKogwloGHNhnkH73wnCviwEAAKogwlqG/LZio9dFAAAAVRBhDQAAwMcIawAAAD5GWAMAAPAxwhoAAICPEdYAAAB8jLAGAADgY4Q1AAAAHyOsAQAA+BhhDQAAwMcIawAAAD5GWAMAAPAxwhoAAICPEdYAAAB8jLAGAADgY4Q1AAAAHyOsAQAA+BhhDQAAwMcIawAAAD5GWAMAAPAxwhoAAICPEdYAAAB8jLAGAADgY4Q1AAAAHyOsAQAA+BhhDQAAwMcIawAAAD5GWAMAAPAxwhoAAICPEdYAAAB8jLAGAADgY4Q1AAAAHyOsAQAA+BhhDQAAwMcIawAAAD5GWAMAAPAxz8OambUxsyFmNsPMppvZX+Ls08PMCsxscvCnjxdlBQAAyLVaXhdAUrGku5xzE82ssaQJZva9c25G1H6/OOfO9qB85dpSVOx1EQAAQBXmec2ac26Zc25i8PZGSTMltfK2VKnbXuy8LgIAAKjCPA9r4cysnaTOksbEebibmU0xs2/N7OAEz7/BzMab2fhVq1ZlsaQAAAC54ZuwZmaNJH0m6Q7n3IaohydK2ts510nSC5K+jHcM59zrzrkuzrkuLVq0yG6BAQAAcsAXYc3MaisQ1D50zn0e/bhzboNzblPw9kBJtc2seY6LCQAAkHOehzUzM0lvSZrpnPtXgn32CO4nMztagXKvyV0pAQAAvOGH0aDHSrpS0q9mNjm47a+S2kqSc+5VSRdKusnMiiVtlXSpc46e/QAAoMrzPKw554ZLsiT7vCjpxdyUCAAAwD88bwYFAABAYoQ1AAAAHyOsAQAA+BhhDQAAwMcIawAAAD5GWAMAAPAxwhoAAICPEdYAAAB8jLAGAADgY4Q1AAAAHyOsAQAA+BhhDQAAwMcIa5VV7hL0AAAAlUNYAwAA8DHCGgAAgI8R1gAAAHyMsAYAAOBjhDUAAAAfI6wBAAD4GGENAADAxwhrAAAAPkZYAwAA8DHCGgAAgI8R1gAAAHyMsAYAAOBjhDUAAAAfI6wBAAD4GGENAADAxwhrAAAAPkZYAwAA8DHCWiXNXrHR6yIAAIAqjLBWSaPmrfG6CAAAoAojrFWSeV0AAABQpRHWAAAAfIywBgAA4GOENQAAAB8jrFWSC7/tXML9AAAA0kFYy6CSUsIaAADILMIaAACAjxHWAAAAfIywBgAA4GOENQAAAB8jrAEAAPgYYQ0AAMDHCGsAAAA+RlgDAADwMcIaAACAjxHWAAAAfIywBgAA4GOENQAAAB8jrGUQy7gDAIBMI6xVknldAAAAUKV5HtbMrI2ZDTGzGWY23cz+EmcfM7PnzWyumU01syO8KCsAAECu1fK6AJKKJd3lnJtoZo0lTTCz751zM8L26SWpQ/DnGEmvBP8FAACo0jyvWXPOLXPOTQze3ihppqRWUbudK+l9FzBaUjMz2zPHRQUAAMg5z8NaODNrJ6mzpDFRD7WStCjs/mLFBjqZ2Q1mNt7Mxq9atSpbxQQAAMgZ34Q1M2sk6TNJdzjnNqRzDOfc6865Ls65Li1atMhsAQEAADzgi7BmZrUVCGofOuc+j7PLEkltwu63Dm4DAACo0jwPa2Zmkt6SNNM5968Eu/WXdFVwVGhXSQXOuWU5K2SKHBOtAQCADPPDaNBjJV0p6Vczmxzc9ldJbSXJOfeqpIGSzpQ0V9IWSX/0oJwAAAA553lYc84NV5K5ZZ1zTtItuSkRAACAf3jeDAoAAIDECGsAAAA+RlgDAADwMcJaBjkxHBQAAGQWYQ0AAMDHCGsAAAA+RlgDAADwMcIaAACAjxHWMmjiwvVeFwEAAFQxhLUMyluz2esiAACAKoawVkmDpi/3uggAAKAKI6xV0vSlG7wuAgAAqMIIawAAAD5GWAMAAPAxwhoAAICPEdYAAAB8jLAGAADgY4Q1AAAAHyOsAQAA+BhhLYOc87oEAACgqiGsZdDS9Vu9LgIAAKhiCGsZ9OKQuV4XAQAAVDGENQAAAB8jrAEAAPgYYQ0AAMDHCGsAAAA+RlgDAADwMcIaAACAjxHWAAAAfIywBgAA4GOENQAAAB8jrAEAAPgYYQ0AAMDHCGsAAAA+RlgDAADwMcIaAACAjxHWAAAAfIywBgAA4GOENQAAAB8jrAEAAPgYYQ0AAMDHCGsAAAA+RlgDAADwMcIaAACAjxHWAAAAfIywBgAA4GOENQAAAB8jrAEAAPhYRsOamTUysyPNrGUmjwsAAFBdVTismdlJZvaymXWO2n6NpBWSxkpaYmaPZaaIAAAA1Vc6NWvXSfqTpLzQBjPbR9LrkupLWhLc3NvMTqlsAQEAAKqzdMLa0ZKmOOfWhW27UlItSfc559pK6ibJSbq58kUEAACovtIJay0kLY7adrKkQkkvSpJzbrykkZI6JTuYmb1tZivNbFqCx3uYWYGZTQ7+9EmjzAAAADuldMJaA0nbQ3fMrIakLpLGOue2hu23SNKeKRzvXUk9k+zzi3Pu8ODPIxUsLwAAwE4rnbC2UtJ+Yfe7KhDgRkTtV1fSViXhnBsmaW0a5QAAAKjy0glroyR1NrOLzayJpAcU6J/2fdR+B0paWsnyhXQzsylm9q2ZHZyhYwIAAPheOmHtH5KKJfWVtE5SL0mTnHNDQzuYWWsFwtr4DJRxoqS9nXOdJL0g6ctEO5rZDWY23szGr1q1KgMvDQAA4K0KhzXn3FhJZ0v6WdJMBfqcnRW12yWSChRb21ZhzrkNzrlNwdsDJdU2s+YJ9n3dOdfFOdelRYsWlX1pAAAAz9VK50nOue9VThBzzj0r6dl0CxXOzPaQtMI558zsaAUC5ppMHBsAAMDv0gprmWRmfSX1kNTczBZL+ruk2pLknHtV0oWSbjKzYgUGLFzqnHMeFRcAACCnKhzWzKyOpGaSNjjnCsO2N5J0vwJzq+VJesY5tyjZ8ZxzlyV5/EUF528DAACobtKpWXtQ0l8lHafAyNDQXGvDFAhqFtzvfDPr5JyjyRIAACBN6YwGPUXSEufcqLBt50s6XNI0BdYO/ULSXpJurHQJAQAAqrF0wlo7Sb9FbTtXgbnWrnDOvS3pIknLFAhxAAAASFM6YW1XSSuitnWXtNA596skOedKJY2R1LZyxQMAAKje0glr2yU1Dd0xs5aS9pU0PGq/LZIapV80AAAApBPWZks61szqBe//XoEm0OiwtqcC64gCAAAgTemEtU8VmLpjmJn9S9LTkooUtgyUmdWUdISkuZkoJAAAQHWVztQd/5Z0mqSTJHWRVCLpDudceC3a6Qo0lQ6rdAkBAACqsQqHNefcNjM7VYF51naXNNE5Nz9qt0JJ/yepf+WLCAAAUH2luzaok/RLOY8PkTQk3UIBAAAgoNJrg5qZSdoteHdtcNoOAAAAZEA6AwwkSWZ2mpkNlrRJgXnXVkjaaGaDzOy0TBUQAACgOksrrJnZw5IGKTDQoL4CU3e44O3TJQ0ys4cyVEYAQJZd9944tbt/gNfFABBHhcOamfVUYDH3rQpM27G/AiGtfvD20wpMiPugmZ2RuaICALLlh5lMiwn4VTo1a7cpMF3Hmc653s65Oc657cGfOc653pLOUqCm7bZMFhYAAKC6SSesHS1phHMu4Rxqwcd+kXRMugUDAABAemGtsaTFKey3NLgvAAAA0pROWFsp6bAU9jtE0qo0jg8AAICgdMLaUEkHm9lfEu1gZrdJOlTST2mWCwAAAEpvUtynJF0k6V9mdoGk9yUtUGBAwb6SrlJgKapCBUaGAgAAIE3prA06w8wukfSBpOMVCGbhTNJGSVc652ZUvogAAADVV7prg/Y3s46SbpB0gqRWwYeWSPpZ0huSZGZtnXP5mSgoAABAdZT22qDOuRWSHk30uJmNknRUZV4DAACgukt7bdAUWZaPDwAAUKVlO6wBAACgEghrAAAAPkZYAwAA8DHCGgAAgI8R1gAAAHws6bQaZnZCmsdukubzAAAAEJTKHGhDFVhKqqIszecBAAAgKJWwli9CFwD40taiEv04a4XOPmwvr4sCIEuShjXnXLsclAOIMXLuah21z66qXZOulUAij3wzQ33H5muPJvXUpd2uXhcH1cjazUWqaaamDWp7XZQqj29B+NKEhWv1hzfH6NnvZntdFMDXlq7fKknauK3Y45Kgujni0e/V6ZHvvC5GtUBYgy+t3lQkSZq3apPHJQH8paTUaRPBDKhWCGsAsBN54ItfdcjfB6u0NHFXYuecthaV5LBUgDfeGDZfI+eu9roYWUdYA4CdyKcTFkuSSl3isPbGL/N1YJ9BWrmxMFfFAjzx+MCZ+sObY7wuRtYR1uCpKYvW686PJyesJSjn+whAAl9PWSZJWl5AWEP1UNVr1whryKp1m4tUUk5zzbXvjdPnk5ZozeaiiO2WodcvKi5Vu/sH6JWh8zJ0RAC50n/KUppzkZI/vDlGv8xZ5XUxsoawhqxZv6VInR/9Xs8MnuVZGUIf9K8MnetZGYBsqqqVz+Pz1ur2vpP08NfTvS4KdhIrNmzzughZQ1hL08oNhWp3/wCvi+Fr67ZslyQNnrbc45JULR+MytND/XeOL7B1m4vU87lhms+o3qzLVG20X2wsDIx4Xb6hajTlOue0rGBr1l/nijfH6K9f/Jr118mkwu0lWhfVuuKFgq3bvS5CQoS1NA2v4u3jlXHzhxOSBlnnnFxYh7QJC9dG/LGahb56nIqKS7WyinxgZ8KDX03XuyPzvC5GSr6fsUKzlm+kGTrHFq3b4nURsqb351P106wVWTu+c65s7rpM+mT8InV78idNXrS+bFv/KUsz/tk2fO5qfTQmP6PHzLaLXh2lzo9+72kZxsxfo04Pf6cfZmTvvVUZhDVk3MBfk9ek7dN7oPbpPbBsPrUb/ztRl70xuuzxsqjmpHv7TdHRT/yoouLSbBQXqFJGzVuj9Vv8W0NQWX3HLtKf3h2fteN/On6xuj/1kybmr6vUcc5/eYSuCBulOHZB4HhzVmyUJG0s3K7b+07SlW+NrdTrVAW/LinwugiasjgQoscsWONxSeIjrCGn7vpkSsJat1nLN8bdPmh6IPyVN1AB8INpSwq0NovNORsLtyf9O5i9YsffkVW5xtGK6fncMPX5alqFnjMub60kae6KyjXdT8pfX24LTOj3WFWaeZFdhDXk1GcTF1f6GOu3FKlwOyPEkLpvf12mRWuz1zQ4YeFabSsu0dkvDNe5Lw2v9PEm5q/TorVbdO5LI9T9yR/Ltt/z6dSy29/SFzSpWcs36v1RC70uBuLYVlyifhMWR3SHQWJJF3IH0pXOH2H+mi1asGZz2f0fZ62M2efwR75X+xYN9eNdPRIeZ/O2YjWsy9vbL7z+OL7pw4lqUq+Wpj50RsaPPWfFRv3+lVG6qtvekqRFayve3+nWjyaqZeN66vO7gyRJF7w8Mu5+i9fvCJy39Z2k33Xaq8KvNX1pgQ7as0lYv1DkUuhvYWfKKMUlpXp7xAJd1a2d6tWumZFj/uv72Xrt5/lqUs9fn9Oh38uT387Uhq3FevKCQ7W8oFC7NKyturUy839PBzVraeJzLnUV+VI44R9DdPXbY7U1Sc3ZvFWbI+4Xbi/Rmf/5RePy1mrQtGU6+O+DNSWsI2919+Yv83XPp1PK7hcVl+r9UXnZb1r20d/JhsLsrKcZavactSx+M34qvpm6TG+PWJDWcytyUfTDjBU66/nh6jeh8jXcqJhEH4M7w3fJfg98qycGztKrP2duoNCq4DQbG7Pwdzkpf12FR95Gdxl47ef56js2X6WlTl2f/FF/6Ts5k0WsMMIafOm2vpPibn/uh9lxt89duUkzlm3Q37+armFzAv1EKtppdcz8NXonzS/MTFu1cVtGg9RjA2aWLVMkSS8Pnas+X03XZ+V8aTvnVOBxR/Xhc1ar3f0DtGD15uQ7x/H+qDzf/E6zLZWLovmrA/2wwvu1xTMxfx0jeBFj87aKBSvnnLo89r2+nLQkSyWK7/yXR+r4p4dk5FihT+HvZnjb7YCwhp3Kcz/Mibs91BduQ2H64eKS10fr4a9npP18SVq5sVATFq6t1DHWbNqmox7/Qc8Mys5kwgvXbNa0JRskSZsSfPiOmrdG+/QeqE6PfKffEgz8yIUvJwc+5EOdviuqz1fTK/07TSaXrVm5mvTzgpdH6ukU3n8bC7dnZZqL6uC8l0dI8lXlc5l1m4t096dTtKWocrVeExau0+pNRbrj48kVuvh8Z8SCSi8fVZzmxa5fW6cJa8iaaUs35OR1rntvvN4ZkSdJWuLxF8dZzw/X718ZValjrNsSaFb7YWbm5/uZs2KjTvzH0KTHvjusyXTOSu/CmlfeGr4gYj6slGTxWzd/TaCv2qqNsWFtWrAGuf/kpdkrQAK/e2G4uj/1U1aO7VL82vx84mLNX7VJm7YVV/pCqSIm5a/T6k1phOfgf2th8HcaXiO6dP3Wsmbt7SWl2l5SqrzVm+P+3iXpp1kr1O7+ARmdq23sgrW68b8T1G/CYn08blFKz0k0eGdz2FJhLw2JXEWmvN/uw1/PSHtx9n8O/i2t54V+DX7tS0hYQ9bcnqApM9Oig0eiP7ZpSwqyvs5gog/VXNpWXKLSBFeVp/17WM7KET65aDY/AJcVbNW+vQfop1kr9N301JoqnHOaW04IffSbGTrvpREx2ycsXKcfU3y/ZdL35YTr0Eohw+fGrouYqGU0VOaezw3TJa+lf3GRFwwc32doIlHnnIbMWhlRCxP+X4hXO3PnJ1N0xnPDdMa/h+n3r4yKG9jSrZmVpLzVm9XrP7/EzLB//ssjde6Lse+RRHZM8x3/DTN35SZ1f+onvT5sviTp4D6DdcwTP6rHP4fqqMd/kBTom9v781+1PnhB99/RgclvMzlP2cWvjdKYBWsjypzM8c/Eb3IMH7WfqIY+nT57E/PXJewe8eKQzC4t6JfRqoQ1JPX4gBmVWlorWxUO8eZsc07qOzbwARb+IbChsFhnvzBcd33qbSfRaH/53yRd8HLqH/ip2P9vg9Snf8XmlsqGN36Zn7DZOpOGzFqlUif96d3xuuGDCUn3Lyou1ZeTl+jUfw3TkDijjcvz+1dG6tr34k/Ims773Dmn90flpfHMgOKSik0UHd6JentJqWYt31j2xRwyJ0l/tniuf3+8thWXVOqLrbTU6aUhc/XHd8fpzV/mx93nhZ/iv5+2l7iyWvXPJsb2j7ro1fQD6StD52nmsg0aHOdCoCI1+clCSWjViZHzApOyFpWURszZV1rq1G/CYvUdm69/fpe89uj697M3cXCq7vpkSvKdorwxLP7vPlxotPTnUVNBRd/PJK9HTxPWkNQbv6TWQfvWjyaq9+fx16Sbv2qT5mV4fch05myblL9eH4/L16h5qc9Sfc07Y9XxgW8r/Fqp+GryUk3Mz/yo1dAVdyak+/07en7lmqQWr9uS9muv2FCogb8ui9k+e8VGdfzbt/rn4MBAlUw08abaXBfPjGUb1OeryHVeR1Sgr86tH1Ws9vqj4IWMk/T0t/H7pKVS+7q8oFBropoA9//boKTLoG0s3K6VG+M32b00ZK7++V3g97J4XfwQNClDfyuJ+mI55zRqfuCzYeS82N9DcUlphTvZhyxdH/h/R9fupxoB/vzfCQmn/Yj3d5Kp2s7KSNQnNpE1m7bp8YEz0369kSl8rpeWupjP/zeGzU+pj6aXPA9rZva2ma00s7hVARbwvJnNNbOpZnZErsuI1HwzdVlZrVa0k5/9Wac8+3Oljp+JC5tS53TfZ79GLG2VzNDfVqmogjUYVcltfSeVW4Pz1vAFGV+ofVL+Oh339JByA/nCNZv19vD4FxKXvTFaN384MWb7t8Gl0OLViCxau0V5aY46lSLfn5u2FWv60uRNU9FLqE1bUqDL4/TVWbt5W9z+UYPCanviNRFGf4mHmo2Wrt+qNxOcu3AbCrfHHTna9ckfdeRjP8Rs/2ZqbECWpIf6T9dFr47UKc/+rKMf/7Fs21/+tyNshvcRXJzFtU1Hzlutg/oMjtuB/f8+nlwWFL+cvFSDpu34/zhJf/l4sg7+++C4x52Uv05fTU486jG0msFDaQ54iRe+KvKR+I/Bs3Tde+Mq9JpTK9C8Ondl5T8D4r2nKmPFhkL9Mieye8D7o/J02RujI2pKHx84U9tL/NHcmYjnYU3Su5J6lvN4L0kdgj83SHolB2VCBbw9fEHCZgsvxVtqJ3w03Yi5qytUixFu7sqNng9myKV4cyGt21yk9VuK9Og3M3TBK/EncU1X9Dx68b6ULnlttB75ZkZMTcfKDYUJa2ai+/aEh5njnxmiHv8cGvH4gtWbVVLq5Jyr0EjjG94fr7OeH67tFQz5iZqNXxoyT11S/CL7Kaxp940Ef5fRqx9c+Vb8ztyXvDZap/87sGRTwZbtcs6lNaXMuyPzNC5vnVaG9el8d2SevkowKGLIb6sibg/9Lba5Op3m2tWbtunHmYFjjV4QW/P7ZVR5vpi0JCKED4gTRrcUFeukfw7V+S+P1F/+F+hmccf/Uq/xzFXr2ktD5umHmfGb/b+ZujRuf97PJy5RwdYd7/v8tVv0w4zAoIYnv42sAdtWnKQ/cNT/Mxd9wc57aUTZ2quL123R/8bml/WzTDSKObqm3C8RzvOpg51zw8ysXTm7nCvpfRf4zY42s2ZmtqdzLv4lXI5U9zX3QjYWbtcj35R/pViSoT/KbRVcyD3QxLVnwsdDNRh5T51V4bKc+q9haT/X727vO6ncIPrSkLn6R9SIq2RNQ/GaChet3aLC7SXqsHvjsm2H/H2wNm0rVs+D90hazkRNLEc/8aPq1Ip/HZpsfrFoJwXDW+2alvjKO7g5/DNh/MLAot0lpU4ZmvA9qdWbimL6cPafslT/uOiwpDOv/zIn/kXLzGWBEd3vj1qo90ctVLvdGpR92eXSOyPy1GP/lhHbTvv3MM18pLzr/FjhgXfD1sjwvTFBGE+2duc9/abGdHSPDn2hAQEh+RHnMPXvkiVRFyHbg8HZKVBLe+N/k/fZjDYxf51u/WiSLunSRredsl/M4+EXHIOnr9Dg6YEavtd+zswFenlhdWtRierXSf8PaFlB4Hc35LeVevDLaVq8bqsuOrK1JGl9gjkkE31def2N74eatWRaSQofP7w4uC2Gmd1gZuPNbPyqVbEjo5B5qdQuLczQh3unh7+r0P6h6TwqI95kjulO0Joqrwcf9Z8SW9sxa/nGshGm/8nAoIEvJi3W8c8MiekfFQpgg5KM6ly9aVvZl0jcD/sE5zA/aoqBVE91eU0kM4KBJlkNSdKahyzZ/2+DNCl/XYVr+eLJRlAL1bAsSqHpM/ocx+uekOqXanj/utJSp0Mfiv18mb1ik4YGa/kSdV5PpYbvlo8im+RPfnZoiqWMFL6CwLrNRRo2e8f33IxlGyJqVVMVqjVfWrBVx2VoItlMuenDCSotdXp60Ky4NWEv/JTayM+nv50VMVhDkv7zY/YHP2XSzhDWUuace90518U516VFixZeF6dKW7B6s/76xa/ZX66okqYuqVyH5Ds+jhw9+sWkxWW1LZUVfnU9I86cdLkYfZTqb++yN0brtRRGaSUyat6aiP5g//dx5CixklKXcLqRaKWlTl0e+6HCNa2JnPPi8Jg5oCrisQGxHaKj+6JNWLhO+/9tkH6evSrl/2cmnf/ySD34pTcjhJM1d30/Y4VeGjJXs1dktt9jtPLOe6La/7ywdYrH5a2Lu08q5Y5ulk82YevYOE200VamOU1Qoq4fif6eKrOMWrjoJuTQ9c+9/aYmfM7Q31bpiYEz9crQeRH9Gytj2JydsyJnZwhrSyS1CbvfOrgNHrr1o4n6aEy+nhzo7xE0ExemF9biTfK4bnORpiyK7PNUmVm2T/jHjqvYM5//Je3jhJSWOr0YZ2qD8uYTkwJX/e3uH6DXh5W/vNC0CnQ2nrE08ip/WUFhTH+wcIc9NDjhXE1SoKnpwmC/uNKoL9Z0+x2GTF1cENOsm0x0GJOk4ji1b6FO86F5vq5+e6z2/evANEpZef9LcYLTTJuwMH7ICbnhgwkVPv9l4mSeD8fkR8zvFfLvOEvVFWzZHnffkFw0fa3etE3t7h+gyWEjXRMtq5dIokC8vCC2CTfeABYpcUB8ohKjM8vzdbAGP1nH/tBAmHF565K+lxJxbkeLRUVXAcnURWFl7Qxhrb+kq4KjQrtKKvC6v1p1NvDXZbov7EpoeCW/KLMtlT5KK6L6pLz5y3wd/8yQiCYGSer86PcxUxOkO8t2NgydvbJs6oNwyaZTCF3xPjFwVtLlZZau3xq36Sn6A/cfg1MP8Ze+Pkqbi0qSNqmPT/BBHd4ZPSTV0btPJZi+Ipl4ffDGxpl49dLXR6uk1MW8TqJangqvmuAz8UJsvC/jns8lnx4kPH9UtC7ygAcHxWyL12TW6ZHvdMCDg2ImOk73dRNJJfRVpFlu4ZotKQ1M2FpOEPXKsoKtaU+T8ftXRurXxRWfAPi3CvRVfXdknq4I+1w/OwMX0pngeVgzs76SRkna38wWm9m1Znajmd0Y3GWgpPmS5kp6Q9LNHhU1QrvmDb0ugmxktB8AACAASURBVCdu/nCiPh7vzRV6OgbEmWsr2jFP/BgxEirUrFXRzujJFJeU6s1f5ic87tTF6yvVrBzvi7KiDuoTf1qCkPKWFhr46zKNnl/+PEfOubLZ2EMqOx+bV94avkD7pVBL1j7OPqFzEN3UndbyRT4SvYJHwdbtcYPtrAytN1uZOe7CfZFgofFELbgFCTqnZ8LPs1clnS9s+NzV+mhManMpPtR/uo5+PP5I4ndGLNAjX0+P+1hIqE9mMovWbtGT384sGz2aaOqa2/tO0itDy6/FL88j35Rf3kwIr4QI9dNMd63RTPHDaNDLkjzuJN2So+KkrGElRqjAf8prCsmUD0YvDATBATP1w50nxjx+zosjdHibZvrHhYfFPPbV5CW677OpatG4boVe872ReSn1f0lJkiv50LxmeU+dVW4/Hj8syVVZ+/8ttuamItZEdXauin6evUpXvz1Wlx/TttLHWhIcfJCtZsnQCMdUdXok8WCnik4Em65J+TtqmjcWFqtRvdjXnbJofcKa9fVbivRwmnO+xXPjfwN//xu2FuvJCw7VWc8Pj7tfZS8qE/UdTMaPtYwV4XlYA6qDt4Yv0KNhU5w8nOBqNlEzWGj+pkVrU5/bredzwzJWg1ERqzZuy9ocdB+Py09YCwJ/uO69cZqYv16XHR3oavxhijVA0cJH70XPuxdS3tiFZQXezIPY9YkfI+5/OGZhdqY7CauVvevT+Ms6RQ+QCrn67bExI6MzZcayDQn70L07IrXVcHJlXN5a7bOTtJIR1pDQN1OXqkE1qUGM7rReUWs2bUvYnDd8zuqIoCaVX7sUXpKVGwt164epjYIKXdmGZDqopVqrkcrM/em677P4y5nBP0ITr740JP2mLikwqCSZ8vp5dXsycZN9NkXXrD3wRXZG4U6pRP/Gn2dnb0TklEXrE07GnO7qDdly0auj1GbX+l4XIyWEtTR5vKZrTlR03cGdWajmKtyyOCOpErn2vfERtWJzV27Sfi0bSZI+nZBeHz+T9MGohXE7rmdKvNGjCcuT4pv+mncSL2nj9Rxyqejy2Pc5eZ2zX/hFj513aE5eK1eyvSxb9JyNyQbPwBvpDtzxQkVaK7zk+QAD7DwufX2U10XImnijWt9KYe3EkOh5lHLRBy5cslGciayrQEfpr+NMllsVrd6Um/5k05Zs0PtVLGxETzyaSbf1naT5WZ6QGpnh8+k3d0qENaQsvJlvepxJXLHD2S8M1y0fTdSaTdvirn+YiSbKT8JG5X44Or1+QblWkQBcHXxO/7uUVZeLBSAemkGBjIi9lBwwdZm+TWHqkNSPGOneflN1VLtdNXflJj2epYkrM21nKScA+AlhDciidJoD/vRuoM/X2s1FSTv1n/HcsIzMrwYA8C+aQdNWdUcYjJy3OmtTL1RVmew4H+r/tnZzkZ5PslAxQQ0Aqj5q1hDjD2+MUd1a5PhU5XowAQCgeuEbGXH5ZfHanUG8dQgBAMgUwhqQASU7wwRiAICdEmENyID1WVzYGQBQvRHW0lQdVjAAAADeI6wBAAD4GGENAADAxwhrkCQN/W2l2t0/QCs2pL54OQAAyD7CWpp2hi5rn4xfpM8nLk5p32veCcyaf/OHE7NZJAAAUEGEtSrs3n5TdecnU8ruD56+PGnN2QwWaAcAwFcIaxm2rMCfyzQ55/TnDybowldHRmyftqRAn45fVHZ/K7PxAwDgKyw3lWEbthZrz6ZelyKxRWsjw+TZLwz3qCQAACAV1KwBAAD4GGEtTZZgVlynnWfZofVbirwuAgAASIKwlmE70xKR0xlMAACA7xHWqqH1W4rU56tpKiou9booAAAgCQYYZNjOULP29KBZ6jt2kTZsZfFxAAD8jpq1aqi4JJAoR85b43FJAABAMoS1NCVawWBnGmCwcuM2r4sAAACSIKwBAAD4GGEtw3aGPmsAAGDnQVgDAADwMcJamhLMietb20uo8gMAYGdEWMswvzaD/vO738pu+7SIAAAgDuZZqwYe+OJXfTgm3+tiAACANFCzlmF+nLqDoAYAwM6LsJZhfm0GDddvwmKviwAAAFJEWEuTJZgW95Pxi3JcEgAAUJUR1jIsb81mr4sAAACqEMJahu0MzaAAAGDnQVjLMC/D2qn/+lnPhk3RAQAAdn6EtTT5cVLcuSs36YWf5kqSCrZs97g0AAAgEwhrGZarELe9pFRbiorjPuacU6dHvstNQQAAQFYR1tK0sTBRUMrN6//p3XE6qM/guI/t03tgbgoBAACyjrCWphUbCuNuz9WkuL/MWZ2T1wEAAN4irGUYo0EBAEAmEdbS5cMBBgAAoOohrGUYFWsAACCTCGtpomINAADkAmEt0zyoWvtu+nKt21yU+xcGAABZV8vrAqBy1m0u0g0fTNCRe+/idVEAAEAWULOWJvPJEgbbS0olSflrt3hcEgAAkA2EtTQlimq5mmcNAABUD4S1ndzPs1dJklZt3OZxSQAAQDb4IqyZWU8z+83M5prZ/XEev8bMVpnZ5ODPdV6UMxW5nhT3nn5Tc/uCAAAgpzwfYGBmNSW9JOk0SYsljTOz/s65GVG7fuycuzXnBUzAJ13WAABAFeeHmrWjJc11zs13zhVJ+p+kcz0uU1KWoNcaPdYAAEAm+SGstZK0KOz+4uC2aL83s6lm1s/M2sQ7kJndYGbjzWz8qlWrslFWAACAnPJDWEvF15LaOecOk/S9pPfi7eSce90518U516VFixY5LWBYGbJy3N6f/6pPxi1KviMAAKhS/BDWlkgKrylrHdxWxjm3xjkXGu74pqQjc1S2hHLdZ63v2Hzd+xmDCQAAqG78ENbGSepgZvuYWR1Jl0rqH76Dme0ZdvccSTNzWL64GF8AAABywfPRoM65YjO7VdJgSTUlve2cm25mj0ga75zrL+l2MztHUrGktZKu8azAAAAAOeR5WJMk59xASQOjtvUJu91bUu9clysdpQwHBQAAGeSHZtAqhawGAAAyibCWrgSd1nLRl23hms05eBUAAOAHhLU0eTUp7rQlBbq976QsvwoAAPALX/RZq1KyvDjoZW+M1sbC4qy+BgAA8A9q1gAAAHyMsJYmFnIHAAC5QFhLk1dZjYwIAED1QljLMKbuAAAAmURYy7Asjy+Q0f4KAEC1QlhLU6LQtHxDYVZft3B7SVaPDwAA/IWwlmGrNm7L6vG3FZdm9fgAAMBfCGtpojUSAADkAmENAADAxwhracpVxVppqVO7+wfk6NUAAIDfENZ8riTbw0sBAICvEdZ8jqwGAED1RlhLEwMMAABALhDW0pabtOZYEwEAgGqNsOZzC1Zv9roIAADAQ4Q1nzvnxRFeFwEAAHiIsJamXPVZK2LFAgAAqjXCWpqymdWKikv1+1dGanze2iy+CgAA2BnU8roAiFSwdbuueWesJuWv1/2f/+p1cQAAgMeoWfOZl4fM1aT89ZIkxyRrAABUe4Q1n3EJbgMAgOqJsJYmy8IIg5JSp+0lDCgAAAA70GctTdkYYNDxb9+qpHRHfRqtoAAAgJo1nxg2e1VEUJOYEBcAABDWfOOqt8d6XQQAAOBDhLU0sZA7AADIBcJamixHC7kDAIDqjbCWBUvXb/W6CAAAoIogrGXBR2Py9fSgWQkntf14XL5WbizMcakAAMDOiKk70tSsQe2Ej704ZK4kqXv73XR8hxYRjy0r2Kr7PgssI5X31FnZKyAAAKgSqFlLU8smdZPuc+VbO0Z4fjlpiUbOXa3ikh21bV2f+JEmUwAAUC5q1nLkjo8nS5KG33dS2bblGwr14ZiFemnIPK+KBQAAfI6atRyLXqZq2pINHpUEAADsDAhrWfbuiAVatHZL2f1VG7d5WBoAALCzIaylKdV51h76eoaOf2ZI2f3zXhqRrSIBAIAqiLCGrHnm94eltN8Ll3Uu9/Enzj80E8UBAGCnRFjz2M+zV3ldhAq7+/SOSfeZ/VgvXXxUGx3aqqkkqXbNxDWRv+u0V9ntfjd2i3n8D8e0jfu85o3qJC0HAAA7O8IaKuzmHvvFbPv5nh5lt9vu2kB1agXeWs9ceJgOb9NMH/85NoTF06XdrvrtsZ6a8vfT9dF1x2j6w2fE7HPu4XvFbBt4+/Fqu2uDFP8HFXPcfs2zclwAVdfZh+3pdRGQQfG+d3KJsJam6raQ+x5N6pXdrlEj8j9/X88DtPduDcvut2y8Yw66A/dsoi9vOVZHtN1FeU+dpb2a1tNDvzuo7PEe+0dOGixJdWvVVNP6tdV9v+ZqWDdydpkvbu6uB848MOY5B+3VRIPvOCFm+7B7TorZhuwJf5/k2t2nd9RNPdpX6hj39TwgQ6Xxv10b1tE3tx2nD687JqX9bzmpcue2qpj60Om6omv82v5wL/7hiHIfN5PuOWP/mO3d2++WdtmqsxM6xn6XZFINj7/0CWtIyei/nqLv/u8ETe5zmiTpxT90VovGdTXn8V4V+oIc2fsUXXPsPmX33776KEnSpAdP09gHTkn6/FbN6qtZg0DzZ/QHXf06Nctuv3rFkerd6wC13S1+bdusR3uW+zqvX3lk2e3rT9g3abkk6a7TOuqsqKvp5y45PKXnStLxHRLX4HVu20ztWzRM+LhffHDt0Z699q0nd9B9PQ/Q29d0SbhPqMY3kZt6tNcuYauTfPuX4zNWvmT633psTl7n8DbNJEk392ivQ1o11ZF775LS8+45IzNBtkuKr5drb1yV+H0TcudpHdWkXm3d3yv2glGKXZXmlcuP0Dt/PEpzH++l+3sdoLph7782uzTQTSfu+Ox8+JyDNe3hM/TR9V3VuW2zcsuxT/OG6rZvZkLdb4+V/1notcuObpN0nza71tc/L0qtj/TOirCGuEIfqEe126XsS6Tj7o3LgtLZh+2lcQ+cqto1d7yFKtJc+M4fj9Jj5x1SVku3S8M6atk4ca3MXk13PFanVg3lPXWWLjmqrSY9eJomPXhazP49D9lDfw5+EB68V5OYx+vVrhmzLaRz22Y65cDdy+6fmOIVW+N6tfTiZZ31z4s6lW07r3MrHd1u17L78a6kQ67ounfCxxIsM1shh7SKPQ/hbo4K3YmalR8+5+CYbfu1bJR+wSohXsA9+YDd9dUt8YPPX07pELPt/l6RIeQ/l+4Y8HLgnk00/4kzNfWh0ytZ0uQOa73jC/pvZ8UPA/E0rR9/6bu6tWro8fMP0UthNTyD7jg+JpzVq10z5kJpwt9Ojbh/avDv4fIE/UdTNevRnjpgz8aVOkam/XDnCRp2z0k67aDd9dQF8QczLXjyTM174kzdHnz/NKpbS3+OuojbrWFsH9peh+6pk/ZvqVo1a+jGE9tHXFDe1KN9RCvF1d3bqVGwJeH1K8sPjkPu7qG+N3RN7T9Yjrev6aK6tRJ/FqYqE11QPrzuGN19eke9+8ejyrYd3qaZnrwgMoTFW6bxphP3U7P6ifswH7RnE1173D5q1qC2xj1wasL9/IywhhjhozPv7XlAxJdIeZ67NFCLdPFRya+ETtq/ZbnhJNoH1x2jW0/aTy0aRy7ztUvDOtolzodkuD2b1o+4n6y25Iubj1XNGhWv8u7cdheZmS48snXCfW45aT+9FlZrF66ylezznziz7PafT4ytDTxgj8iwNvuxXhH3741qAnzu0sPjDgy5qlvs7+0/lx6uMw/dQ/s0z23tX6JaocNaN4348ux3YzcNubuHbjqxvS6K+v3s2TTyIiG6OaVGDVOTeonXAo5+T4b85ZQOurLr3mVhfWKci4qQ8lpYbjt5P/XuFb9W645TO+j/To0NoJJ04ZGtdfkxe0fU9ka/BxLZrVFd1atdQ7VqmOY/cabeuCrwnn38/EOV99RZESuxhCSrMWtUt5bq1a6pOjVTDwc3pFCr/dh5h6R8vHBtd22gb247Tvu1bFxWA3/p0bFhdOxfT5GZxXwm9D7zQOU9dVZZv9puKTRf7h0WapoFQ3an1k0rVO54obA8iQZitWxcVycfEAjhiUKqFLiwTjaYK/oz4YyDd4+737Q4fZAl6eh9dtWx+zXXrSd3UI/9W5Ztrx91UT2lT+RF07MXddJXtxyrPxzTttxa8/M7t9KDZx+kyX1OT/j3mkymajLTRVhLU1XusnbmoXvqtlM6yCxQm5aq5o3qKu+ps3Rxl+RhraLat2iku8/YP2YFiGif39xdn90UOZjh2Ys7RTRHHrhn5BdWomr2fRM0O17cZceXfd5TZ2nk/Sfr35d0Uqc2O0LtB9cerY+CfYH2jmqKPePgPeI21YWuuqPDhJS4L9gx+wSCQLd9d4u4Su8d1kxzcZfWevuaLnr03MgvtTq1amjwHSforEP31L09I2v8PrzuGB3Rdpe48wnG+x0cvFdTvXz5kaoVVtP67EWddPspHTTn8V4x+4f7e1gfxnCHlfMlFuq3ePZh8Tv9mpkuDf5e7zqto7q021X7NG+oGjVMfX53kE49sKW67rujxrN3rwPU8+A9yu6femBLtWpWP+a40VrvUl8fJ6jh+L/TOurR8w7RJzd2U95TZ2nXsC/Zsw4NBKjzDt9LL19+hH66q0dM+UPuOn3/slri8GP0vb6r7ji1o645dp+YLzEpUFOTqoZ1YlcenNzndE17+AzVqGExv/PWuzRQrajw0u+m7nFruUNCe995ese4FxPhLujcSpK0fwqfP1d03VvjHjhVLRrX1X8uPVwfXHt0TO3LqQe2jHneHk3r6ZBWse+x6NrDlkn6YTasW0tD7u4RUaOeyNvXHKXQaQud0o+u76oR958csV/zRnV0Tfd2Gnj7jgvLr245VoPvOEHf33liua8R/pwWjetq+H0nx91vzF931KYeEQzarXeJfc/XqRkbE6LLe+CeTSLOeXjLRLhGdWtpcp/TYoL9eYe3irgf+jyK/gxu2iDyoumQVk0jPnfDb4eLrkDodcgeZd0ByhMeUi/qkvgiPBdYGxT67v9O0On/HiZJ+uOx7VSzhunEji204MnY6ma/O6Jt7NV90/q1dV7nVuqxfwuVhjUnjrz/ZNWqaWresK7+/ruD1fO5YbrhhB1NgV/ecqzWb94uKXB13XfsIv37h9m6ucd+urfnAapdI/Ahtlez+jq/c+Qf8vEddtTOPHLuIfp0wuKIx0NXtCG7N6mr4/ZrrkfPPVjnH9G6bP//XnuMVmwo1GkH765J+et19dtjJQW+tNduLtJNPdrrph7t1blN7P/7mu7t9O7IPHVq06zs9Xr3OkDP/zhHm4tKJEn779FYL12+o5nsph7tNXXxeh0bbNJuUr+2Vm/apm777qZR89eU7dfvxm6qWcN0/ssjY153zuO9NHj6cp116J5lX/IfXneMLn9zjG4/pYPGLVgbcaw/HruP3h+1UAtWb474wC/cXqKPxuTrkW9mRBz/8DbNdP0J+ybtS9iiUeAKOrrmtXG92nrz6qN0e99JZdv+fGJkE/CbVx+laLef0kHP/zhHknTS/i005LdV+vGuEyvUjDTk7h7avUldNahTSy+Vs1+ok/lH1+/o/P/mVV100F5N9P2MFeqwe6OImpymDWqr/63H6pwXd0y6vV+L+E3TBwUvVtqHNV03rFtLU/qcrt+9OLysVqS8rgKSFK9lfpeGdfTR9cfo59mr1L1987L3a7hGdWupd68D9drP8yUFLkSWbyiUJI3ufYrWbSlScYnT11OXltuP8+tbj9O24sD7uEXjugmbt8Y9cKqa1K+l/f82qNz/T8jj5x+q647fVyf9c2hK+0uKqVEOhfFouzWqq1MP3F3fzVhRtq1h3VoxA6nMTA9FdTdIFESkQNeNSfnrJQUGW4WrV7umHj3vED345TRJ0suXH6Ezo8rXcffGynvqLL368zw99e2ssu339TxA3dvvpreuPkrvjcrTqo3b9Muc1WUXMqce2FKPnHuI9oq6sLnoyNa6t9/UuGVt1qCO+t3UXe3uHyBJmvfEmYpuyAjVYoXe49HdAgbefrw+Gb9IHXePfI9/dcuxZceN11wa8soVgZriR7+ZobeGL4h4bL+WjdShZSM9d+nhMpkeHzBDjevVTlpRkG2EtWrq90e01tXd91bLxvW0R9N6GnTH8Zq2ZIPnw5OzKdTfLiT8A6ZejZoaGjVytEm92mXNXy2b1NPtp+ynK7q21W6NKlaNXr9OTc18pKeKiksjtv9014latG6rjm63q8wCH9BXdmsnKRBu6taqoS5h/d1O7NhCX95yrM57aYSu7Lq3bjhh35gP+f13b6yDg33T7u91gFo2qatLwmo6/3xie113/L7aXhJZlpDo0ZD9buymn2ev0tXd26nd/QPKrjTDyxU9D17tmjViaryO3a95xIdn6AM1ZMjdPWLKUq92Tf3puH10yoEtNXj6cj0xcFbMPlKg302/qDAsSVd2a6emDWrr3E6t4jxLOuXAluo/ZWnKTYN3ntZRmwqLNXj6cr159VHaXFRcFtQa1qlZFoAfPudgPTFwZtxjpNpMHF1TIUmnHhQIUYlqzA5r3UwDbz9ez373m3oeskdETesT5x+qYcE5HS84opUOa91UHaJqrZo2qK1h91Z+9HT39s3VvX3y/qv3nLG/Vm4o1MPnHqJ29w9QDQvUdu0RbJae8/iZcZ+3W8M6OrhVUx2apPnwhztPkHM7mqmH33eSnhn0m36YuUJbikri1raF7NO8oc44eHedfEDifRKZ9WjPiL68iaX25T/k7h7KD1uyMJ7Pb+quTycs1oHB9/IXN3fX+S+PLKsVu7Lr3jqsVVMNnr5cZ4TVICcTGjzWqU0z/atN5GCpsQ+coqb1a0dcrPS9vquGz10lM1O/G7vpy8lL1KRebb08dF5M3+G3ru6iNrs2iNvlpHPbXTS5z2lln9nXHR95YXbQXk1iwmw67jo9MGDklpPa69r3xmvFhkINippV4OFz02tmzzRzmei57ENdunRx48ePz9rxi0tKtd8D32bt+NlW3lUH/G3KovU6pFXTtPrVVcaIuavVvkWjsi/TyggPa6m8F7+ZulS3fhSoCTu8TTN9mWAAQUVtKSpWgzhNgBX12/KNOuO5QO10dfnbeurbWXr153nat0VDzV+1Oe7/u+MD36ooeGHQuG4t/Zqgz1LB1u2qYYFaz2ih98rvOu2lXofsEVMrlI6CLdvVpH4tT2pL5q/apL9+8aveuvqomIutitq0rVgmxRzHOad//zBH5x2+l/ZNUMMaT3TNWqbey865nJ3raUsK1KBOzQr9v/3CzCY45+KOLiGspWlnCWuf/LmbLn5tlCRpwO3Haeayjaph0gVHeNv+jurtu+nL9euSAp3fuVVKH6orNxTq6Cd+VMvGdfXhdcfE1Ar5gXNOpU45D9Fe21ZcouISFzd4bCzcrvVbtuv4Z4aUG9bKMy5vrX6YuSKiHyayY82mbbr+/fG64IjWmrxofUr98JA5hLUs2F5Sqg4+C2tzHu+lv30xTR+PXxRxRTRz2Qat37I9pdFKAJBJzjnd9ekUXX5MWx25967JnwBUU4S1LPBDWKtd0/TjnT3UvHGdsqac0O/T686QAAAgdeWFNV8MMDCznpL+I6mmpDedc09FPV5X0vuSjpS0RtIlzrm8XJczXPSw9Vxqs2t9fXPb8XEnwySkAQBQtXge1syspqSXJJ0mabGkcWbW3zkXPl7/WknrnHP7mdmlkp6WdEnuS7tDrkPRgifPJIgBAFANeR7WJB0taa5zbr4kmdn/JJ0rKTysnSvpoeDtfpJeNDNzHrfhTnv4DG0vLlXd2jXUoE4tzVq+QT2f+6XSx21av7ZOPqCl6tepqQfPOihiiRIAAFC9+CGstZK0KOz+YknHJNrHOVdsZgWSdpO0OnwnM7tB0g2S1LZt5dawS0WjurWksCm3Dtgjdm6kkOUFhdq9SV1tKy7V8oJCtdqlvkpKneas2KS9mtWr8NxdAACgeqhSy0055153znVxznVp0SK1xbdzZY+m9WRmqle7pto1b6jaNWuoXu2aOrR1U4IaAABIyA9hbYmk8IW7Wge3xd3HzGpJaqrAQAMAAIAqzQ9hbZykDma2j5nVkXSppP5R+/SXdHXw9oWSfvK6vxoAAEAueN5nLdgH7VZJgxWYuuNt59x0M3tE0njnXH9Jb0n6wMzmSlqrQKADAACo8jwPa5LknBsoaWDUtj5htwslXZTrcgEAAHjND82gAAAASICwBgAA4GOENQAAAB8jrAEAAPgYYQ0AAMDHCGsAAAA+RlgDAADwMcIaAACAjxHWAAAAfIywBgAA4GOENQAAAB8z55zXZcgKM1slaWEOXqq5pNU5eJ2dEeemfJyf8nF+ysf5KR/np3ycn8S8Ojd7O+daxHugyoa1XDGz8c65Ll6Xw484N+Xj/JSP81M+zk/5OD/l4/wk5sdzQzMoAACAjxHWAAAAfIywVnmve10AH+PclI/zUz7OT/k4P+Xj/JSP85OY784NfdYAAAB8jJo1AAAAHyOsAQAA+BhhLQVm1tPMfjOzuWZ2f5zH65rZx8HHx5hZu9yX0jspnJ87zWyGmU01sx/NbG8vyumVZOcnbL/fm5kzM18NGc+2VM6PmV0cfA9NN7OPcl1GL6Xw99XWzIaY2aTg39iZXpTTC2b2tpmtNLNpCR43M3s+eO6mmtkRuS6jl1I4P5cHz8uvZjbSzDrluoxeSnZ+wvY7ysyKzezCXJUthnOOn3J+JNWUNE/SvpLqSJoi6aCofW6W9Grw9qWSPva63D47PydJahC8fRPnJ/L8BPdrLGmYpNGSunhdbj+dH0kdJE2StEvwfkuvy+2z8/O6pJuCtw+SlOd1uXN4fk6QdISkaQkeP1PSt5JMUldJY7wus8/OT/ewv6tenJ+4+9SU9JOkgZIu9Kqs1Kwld7Skuc65+c65Ikn/k3Ru1D7nSnoveLufpFPMzHJYRi8lPT/OuSHOuS3Bu6Mltc5xGb2UyvtHkh6V9LSkwlwWzgdSOT/XS3rJObdOkpxzK3NcRi+l8FKs0wAADXRJREFUcn6cpCbB200lLc1h+TzlnBsmaW05u5wr6X0XMFpSMzPbMzel816y8+OcGxn6u1L1+2xO5f0jSbdJ+kySp587hLXkWklaFHZ/cXBb3H2cc8WSCiTtlpPSeS+V8xPuWgWudKuLpOcn2DTTxjk3IJcF84lU3j8dJXU0sxFmNtrMeuasdN5L5fw8JOkKM1uswNX/bbkp2k6hop9P1Vl1+2xOysxaSTpf0itel6WW1wVA9WFmV0jqIulEr8viF2ZWQ9K/JF3jcVH8rJYCTaE9FLjyH2Zmhzrn1ntaKv+4TNK7zrlnzaybpA/M7BDnXKnXBcPOwcxOUiCsHed1WXzmOUn3OedKvW4sI6wlt0RSm7D7rYPb4u2z2MxqKdAUsSY3xfNcKudHZnaqpAckneic25ajsvlBsvPTWNIhkoYGPwz2kNTfzM5xzo3PWSm9k8r7Z7ECfWm2S1pgZrMVCG/jclNET6Vyfq6V1FOSnHOjzKyeAgtRV6fm4kRS+nyqzszsMElvSurlnKsu31up6iLpf8HP5uaSzjSzYufcl7kuCM2gyY2T1MHM9jGzOgoMIOgftU9/SVcHb18o6ScX7JlYDSQ9P2bWWdJrks6pZv2NpCTnxzlX4Jxr7pxr55xrp0C/keoS1KTU/r6+VKBWTWbWXIFm0fm5LKSHUjk/+ZJOkSQzO1BSPUmrclpK/+ov6argqNCukgqcc8u8LpRfmFlbSZ9LutI5N9vr8viNc26fsM/mfpJu9iKoSdSsJeWcKzazWyUNVmBUyNvOuelm9oik8c65/pLeUqDpYa4CnRUv9a7EuZXi+fmHpEaSPg1eoeQ7587xrNA5lOL5qbZSPD+DJZ1uZjMklUi6p7rUAKR4fu6S9IaZ/Z8Cgw2uqS4Xi2bWV4Eg3zzYZ+/vkmpLknPuVQX68J0paa6kLZL+6E1JvZHC+emjQP/ql4OfzcXOuWozdVAK58c3WG4KAADAx2gGBQAA8DHCGgAAgI8R1gAAAHyMsAYAAOBjhDUAAIA0pbogfNj+F5vZDDObbmYfpfIcwhoAmVk7M3Nm9k7Ytm7BbX/PcVnODS4ttSH4+s7MDq/gMTqEPferbJW1nNcfGnztHrl+7Wwys5pm9quZLTSzulGPOTNzUdvMzCabWb6Z1c9taYGceVfBiamTMbMOknpLOtY5d7CkO1J5HmENgCR1Df47Mmxb9+C/o3JViOAEyv0UWMB8lKT3gj/JFluO9qew22ea2e6ZKaFkZtcEg8m7mTrmTuQmBVbceCiVlUiC8739TYFVBO7NctkAT8RbEN7M2pvZIDObYGa/mNkBwYeul/SSc25d8LkpTRRPWAMgxQ9r3RSYZHVMDstxngKTdT/jnDvDOXdN8Cc/1QOYWU1JVwXvLgke76rEz8iKqyQdKGlsjl83a8yskaSHJS2Q9H6cXQ4M/kRwzn0jaaKke82sZVYLCfjH65Juc84dKeluSS8Ht3eU1DHYejDazFKqkSOsAZACYa1A0oywbd0kzXDOFeSwHKF1HOdU4hg9Je2lQKi4J7gtpzPXO+fynXOznHNbcvm6WXa1pF0VWDS+JPrB4P93VoLnvi2pgQK1CkCVFryw6a7Aqj2TFVhucc/gw7UUWNu4h6TLFFh9pFmyYxLWgGou2Peos6TRoWWKzGxvBQLP6Eoc18zsymD/rXVmVmhm88zsJTNrE7XvQ8H+TqFQ9U5Yn7N3K/jSoSbQdxVY93CdpAPNrFuS8p5hZp+b2VIzKzKz5cGr3/tC/a3MLE9SqF/f1WFljChneX3WzKy2md1qZmOC/fK2mtlMM3vKzHaLs3+oP2Fe8JzeHOwHtiV4Xr8ys0MS/J+ONrNPzWyJmW03swIzm2tmH5nZyclOZJSbg//Gq1WL22ctTF9J2yX92cz43kFVV0PSeufc4WE/oVrnxZL6O+e2O+cWSJqtQHhLekAA1Ux4yJBUKKmOpDPCtuUFd702bN+8BIeLd3yT9F8Fvti7K7Ag+ZeSTIEv/clmdlTYUyYr0DdtXvD+CO3orza8Aq/bXNLvFGi+fS/Yr6pv8OE/JXiOmdkrkgZJOl+BptPPJE1RoKbvKUmhPm/9gmVTsKzvqQLlNLN6kr6T9IICfb+GSfpaUjNJ90maYGb7lnOIdyX9S9JKSQMUqA09R9KI6OeZ2WnBMl0oaYWkLyT9pEB4vVDSxcnKG3asDpIOkjTXOZeX6vNCnHNrFWgKbSPpiIo+H9iZOOc2SFpgZhdJZZ8xnYIPf6lArVro86qjpPmpHJQffvipZj+S3gz7maFAuOkXti0/uO2dsG1PVeD4Nwefv1zSwWHba0p6PvhYnqS6Uc97VzsWI0/n/xVazPzHsG1dgts2SGoQ5zl3hJW1a9RjJulkSU3Dtl0T3P/dcsoxNLhPj6jtzwS3z5TUKmx7/eD5d5JGRT2nXXC7C36otw97rK4Coc1JeiPqeT8Ft18Wp3y7STqyAuf1+uCx3i9nH6fgmIIEj/87uM+9Xr//+eEnkz8KXBAuU6D2eLGkayXto8AF4P+3d28hVlVxHMe//9BuhkL5pJKNYYaQlplJIs4gJYUVXQRT0ykMisKHkkBKLXqo7EZ0sSjwwZKK3qILFmqhYOQFExO7iZdyHhRDMu/z7+G/trPd5zLnzBlk4Pw+cNjuNWvvtc9BDuustf7/tS19xy5JdY34wfULsB2YWUsb/RCRpuPu87N/m9kG4Cgwy91PprK9wK/u3tO1Xk+l42J335Fr94yZLQTuBoYTIzwf97CNcs5Oo+ba3GRm24HrgBnEKBgAZtYPeCadtrv7OdO+Ht+ua3rjwdJU6mPpdIG7/5Vr55iZPQpMAyaa2SR331DmNgvc/Y/cdSfM7HngDmBqoW42Gvh18Sbufgg4VMfjZ6lTdtZxTVG2HvKGBu4h0ue4+wMV/lQSPJC+U55Mr5ppGlSkiZnZQCJNxg+5jtpIYrqqR50UMxsGjAA6gZXFv6d2sg5aa0/aqNDuTUSH7AixVi0v67wVp0LHA4OB/e7+TW89SwU3ApcBf7v7t8U/uvtBYkoUyn8up4lf6kXZov4hhfIsEnWVmU1KUbI9lUVx1tPBK8pSG/RaGhWRZqHOmkhzayWik77LlWULz3s6ojQ0HQ+4+/EKdf4s1O0NWUfsUy+NwvyImKKYbGZX58qHp+OuXnyOSrL3urtKnWqfywF3P10s9FgfAzElmrcI2ArcTqxdO2Jm35vZ0m7WxZUzKB2PVK1VXXZtt5FvInIuddZEmoiZtRaCC7Ls/q/lyt5LZZ81EJEJsT7pvEgL92em01YzW59/EYvrTxHrRfKja+ftGXuhzc66GnHvIEYOpxJBEpuBm4HngF1mVjbgooJ/0nFgPc9QkF17uIF7iDQlrVkTaS4d5NZsEWvGThMRShCdmQdTvdW5ejVHZBLRlABDzOwiL5/pfkShbqPuo2vEZiTVQ+Hnmtlid+8kAikARvXSc1STvdeWKnV69XNJ73FNemFmA4AniM7bO2b2eW5krposy3pJapE6ZNfWlLFdRLpoZE2kiXgkLm1393YiCvISYHWu7FWiw/aJd+0e0O7uH9bRxn5iOu8CYE7x72bWH5idTtc18n5yslGiJe5u5V7Ej9MDwDBiIT/EaNNBYJiZTSu9bVkn07HeH7ubgX+BoWZWDAYg5Vi7M52uq/PeNXH3o+7+MhGxdjG1d1K3pOPoBprPrt1StZaIlFBnTaR5tRLfAWtzZW3p2GgE5Ovp+IJ17YmXbQW1DLgS2EOkq2iImV1FPLcTa9PK8si6vyqdPpzKTgEvprIVZjahcG8zszYzG5Qrzka9SrZWqsbdj9E1xfymmWUZzbNp3OVEAMLGCpGgdTGzhVZIPpzKxxPZ1DuBfTXeLvs/UjWxcDeya9dWrSUiJTQNKtK8skCCYmftDJGstRHvApOI7VS2mdk6IhpwAjHVdxiYUWGKtF4PEaOB6z0yglezkkgrcpeZXZFSWLxBdLzmAxvNbBPwO7G10mgiMraFSEALsatDBzAu1d1BrIfb4O4rqG4xsY6sFfjNzNYAx4DJRAdqL12jjo16FnjFzHYSKTdOpPdyC9FJfymta+uWu+82s5+BMWbWUsPnfA4zu5xI2bEPjayJ1E0jayLNqw3o8LSfY9oGaAqwqcZ1TBWlXEKziQ3NfyQWtt9LfOcsB8a6+0+NtAFnn3leOi1JE1LmubYRiSgvJE3ReniEmIL8ikhCez8wlhj9e5ronGX3OEHkT/qS6MTNIZJgTqmh/ePAbcACIu9YG5Fz7ggx4jjO3bvPZl6bx4n1iZ2pnXuIKNMvgGnuvqjO+2UbUc/twbPMAvoD76d1dCJSB0sZdUVERCpKwQl7iI7lSM9t5m5mlxKJlf9z9wFlrt0MXAu0uLsCDETqpJE1ERHplrsfBZYSo4nF0bWJ6ViSr87MphP7gS5TR02kZzSyJiIiNUkBIluJJLnXEAl35wG3AgOI7bDeytU3Yo3aYGBUmWTFIlIDBRiIiEhN0tTnmOzczK4HphPTox8AbxfqO9oLVKRhGlkTERER6cO0Zk1ERESkD1NnTURERKQPU2dNREREpA9TZ01ERESkD1NnTURERKQP+x/v3Q/dPKf0vgAAAABJRU5ErkJggg==\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 720x504 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 720x504 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["#def main(): # DQN... Total Path 학습 모델\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # GPU를 사용할 경우 ???\n","print('tensor in', device)  # GPU 사용 확인\n","# PATH = '/content/drive/MyDrive/aiffelthon/data/model_conv_colab.pt'\n","PATH = __file__ + '/model_conv_colab.pt' ## PATH 경로 쉽게 수정\n","##############################################\n","tz = pytz.timezone('Asia/Seoul')\n","cur_time = datetime.now(tz)\n","start_time = cur_time.strftime(\"%H:%M:%S\")\n","\n","### 중요 Hyperparameters #####################\n","buffer_limit  = 100000     #1. 50000\n","batch_size    = 200        #2. 32\n","learning_rate = 0.00025    #3. 0.0005\n","sync_freq = 500            #4. q 네트워크 파라미터를 q_target 네트워크에 복사하는 주기\n","train_start = 50000   # (추가)\n","##############################################\n","env = Simulator()  # 데이터셋 읽기. 그리드월드 크기 지정\n","q = Qnet()\n","q.to(device)\n","optimizer = optim.Adam(q.parameters(), lr=learning_rate)\n","\n","train_model_load = False  # 학습한 모델을 불러와서 계속 학습시키고자 하는 경우 True로 바꾼다!!\n","if train_model_load:\n","    ###############################################################\n","    ## 학습한 모델 불러오기\n","    ###############################################################\n","    checkpoint = torch.load(PATH)\n","    q.load_state_dict(checkpoint['model_state_dict'])\n","    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","    epoch = checkpoint['epoch']\n","    loss = checkpoint['loss']\n","    q.train()\n","###############################################################\n","q_target = Qnet()\n","q_target.to(device)\n","q_target.load_state_dict(q.state_dict())\n","memory = ReplayBuffer()\n","\n","### Hyperparameters #####################\n","gamma = 0.99             #5. 0.98\n","####################################################################\n","# epochs = len(env.files)  #6. 훈련용 데이터 갯수\n","epochs = 80000  # 한 군데 갔다 오는 경우에 사용. 반복 횟수는 각자 지정\n","####################################################################\n","losses = []\n","cum_rewards =[]\n","moves = []\n","max_moves = 100          #7.\n","print_interval = 5000    #8.\n","j = 0\n","goal_ob_reward_count = 0 #9. epoch를 반복하면서 finish 카운팅\n","epsilon = 0.3            #10. annealing 대신 고정\n","loss = 0.0\n","##############################################\n","# __file__ = '/content/drive/MyDrive/aiffelthon/data' \n","### 액션 저장하는 txt파일 만들기 #######################\n","f = open(__file__ + '/ogz_conv_gif' + '.txt', 'w')\n","########################################################\n","\n","for n_epi in range(epochs):\n","    # n_epi = n_epi % 39999\n","    # epsilon = max(0.1, 1.00 - 0.1*(n_epi/2000)) # Linear annealing from 100% to 10%\n","    gridmap = env.reset(n_epi)  # 에피소드 시작시 12개 값 초기화\n","        # self.epi = epi                                            #1. 에피소드 번호 받기\n","        # self.items = list(self.files.iloc[self.epi])[0]           #2. 에피소드의 목적지 받기: [ 'H', 'L', 'M']\n","        # self.cumulative_reward = 0                                #3. 누적 보상값 = 0\n","        # self.terminal_location = None                             #4. 최초 목적지\n","        # self.local_target = []                                    #5. 목적지 리스트 초기화\n","        # self.actions = []                                         #6. 지나온 경로 리스트 초기화\n","        # self.grid = np.ones((self.height, self.width), dtype=\"float16\")  #7. 그리드월드 전체 그리드값(1)로 초기화\n","        # self.set_box()                                            #8. 선반 위치(0), 목적지(2) 그리드값 설정.  목적지 리스트 생성\n","        # self.set_obstacle()                                       #9. 장애물 그리드값(0) 설정\n","        # self.curloc = [9, 4]                                      #10. 현재 위치를 출발점으로 세팅\n","        # self.grid[int(self.curloc[0])][int(self.curloc[1])] = -1  #11. 현재 위치(출발점) 그리드값(-1) 세팅\n","        # self.done = False                                         #12. 경로 찾기 종료 여부 = False\n","        # return self.grid\n","\n","    # 초기 input은 (시작화면*4장)으로 들어감\n","    #####################################################################################\n","    history1 = np.stack((gridmap,gridmap,gridmap,gridmap), axis = 0) # 초기 state로 히스토리 초기화 (4,10,9)\n","    history1 = np.reshape([history1], (1,4,10,9)) # (배치, 채널, 가로, 세로) 로 reshape\n","    history1 = torch.from_numpy(history1).float() # 텐서로 변환   \n","    #####################################################################################\n","\n","    done = False\n","    mov = 0\n","\n","    while (not done):  # 최종 목적지 [9,4] 도착 또는 max_moves (=350) 초과하면 종료\n","        j += 1\n","        mov += 1\n","        # 상태 state1에서 action 결정\n","        #####################################################################################\n","        if env.curloc == [9,4]:  # 출발점에서는 무조건 위로 올라간다 (action=0)\n","            action = 0\n","        elif env.curloc[0] == 0 and env.curloc[1] in [0,1,2,3,4,5,6,7,8]:  # (0,0)~(0,8)에서는 무조건 아래로\n","            action = 1\n","        elif env.curloc[0] in [2,3,4,5] and env.curloc[1] == 8:  # (2,8)~(5,8)에서는 무조건 왼쪽으로\n","            action = 2\n","        elif env.curloc[0] in [2,3,4,5] and env.curloc[1] == 0:  # (2,0)~(5,0)에서는 무조건 오른쪽으로\n","            action = 3\n","        else:  # 위 경우를 제외하곤 e-greedy로 액션 선택\n","            action = q.sample_action(history1, epsilon)\n","        #####################################################################################\n","        # action = q.sample_action(state1, epsilon)  # 위 조건을 적용 안 할 경우\n","        # make Move... action에 따른 이동\n","        gridmap, reward, cum_reward, done = env.step(action)\n","            # self.actions.append((new_x, new_y))...새로 도착한 위치를 경로 리스트에 추가\n","            # 누적 보상 계산\n","        ###########################\n","        # print(gridmap.reshape(10,9))\n","        ###########################\n","\n","        #####################################################################################\n","        # next input 만들어주기\n","        next_gridmap = np.reshape([gridmap],(1,1,10,9))                                             # 다음 그리드를 히스토리 사이즈에 맞게 reshape\n","        next_gridmap = torch.from_numpy(next_gridmap).float()                                       # 텐서로 변환\n","        history2 = torch.cat([next_gridmap,history1[:,:3,:,:]],dim=1) # (1,1+3,10,9)                # 지금 있는 히스토리중 마지막 채널을 지우고 new를 제일 앞에 붙임\n","\n","        done_mask = 0.0 if done else 1.0\n","        memory.put((history1, action, reward, history2, done_mask))  # 경험을 메모리에 저장\n","        history1 = history2\n","        #####################################################################################\n","\n","        # if memory.size() > train_start:  # 메모리에 train_start 크기 이상 쌓이면... 미니배치 훈련\n","        if j > train_start:  # 메모리에 미니배치 크기 이상 쌓이면... 미니배치 훈련\n","            #print('memory size:', memory.size())\n","            loss = train(q, q_target, memory, optimizer)\n","            if j % print_interval == 0:\n","                print('epiode #:', n_epi, 'loss:', loss, 'j:', j)\n","            losses.append(loss)\n","            cum_rewards.append(cum_reward)\n","            moves.append(mov)\n","            \n","\n","            if j % sync_freq == 0:  # sync_freq마다 q 네트워크 파라미터를 q_target 네트워크로 복사\n","                q_target.load_state_dict(q.state_dict())\n","\n","        ############## 현황 모니터링 #############################################################\n","        if done and j % 100 == 0:  # 100번 마다 mov 횟수 저장:\n","        #     moves.append(mov)\n","            print('종료: done =', done, '... j =', j, ' move =', mov)\n","        if env.goal_ob_reward:  # 최종 목적지 도달한 경우에만 화면에 표시\n","            goal_ob_reward_count += 1\n","            print(env.items, '종료: env.goal_ob_reward =', env.goal_ob_reward, '... j =', j, ' move =', mov, '@ 에피소드 #', n_epi)\n","            print(f\"{n_epi}번째 에피소드까지 총 {goal_ob_reward_count}번 finish 했습니다.\")\n","        ##########################################################################################\n","\n","        if done or mov > max_moves:\n","            mov = 0\n","            done = True\n","    \n","    # while loop 종료 ----- 최종 목적지 [9,4] 도착 또는 max_moves (=350) 초과\n","\n","    if j > train_start:  # 메모리에 train_start 크기 이상 쌓이면... 미니배치 훈련\n","        if (n_epi % 10000 == 0 and n_epi != 0) or n_epi >= epochs - 1:\n","            torch.save({'epoch': n_epi, \n","                        'model_state_dict': q.state_dict(), \n","                        'optimizer_state_dict': optimizer.state_dict(), \n","                        'loss': loss, \n","                        }, PATH)\n","            print('▶ 모델 저장됨!!! @ 에피소드', n_epi)\n","\n","        ##### gif 생성을 위한 경로(env.actions) 저장 ####################################    \n","        if n_epi % 1000 == 0 or env.goal_ob_reward:\n","            f.write(str(n_epi)+'/'+str(env.local_target_original)+'\\n')\n","            f.write(str(env.actions))\n","            f.write('\\n')\n","        ######################################### \n","f.close()\n","#########################################\n","## 프로그램 시작 및 종료 시간 출력\n","cur_time = datetime.now(tz)\n","end_time = cur_time.strftime(\"%H:%M:%S\")\n","print ('실행 종료!', 'Start@', start_time, 'End@', end_time)\n","        #cur_time = datetime.now(tz)\n","        #simple_cur_time = cur_time.strftime(\"%H:%M:%S\")\n","        #print('▶ Episode #', iter, 'start time:', simple_cur_time, end='→')\n","\n","print(gridmap.reshape(10,9))  # 최종 그리드맵 확인\n","\n","## loss 그래프\n","plt.figure(figsize=(10,7))\n","plt.plot(losses)\n","plt.xlabel(\"# of Actions (j)\",fontsize=22)\n","plt.ylabel(\"Loss\",fontsize=22)\n","\n","## 경로길이(이동 횟수) 그래프\n","plt.figure(figsize=(10,7))\n","plt.plot(moves)\n","plt.xlabel(\"# of Actions (j)\",fontsize=22)\n","plt.ylabel(\"Moves\",fontsize=22)\n","\n","## 보상값(cum_rewards) 그래프\n","plt.figure(figsize=(10,7))\n","plt.plot(cum_rewards)\n","plt.xlabel(\"# of Actions (j)\",fontsize=22)\n","plt.ylabel(\"Cumulative Rewards\",fontsize=22)"]},{"cell_type":"markdown","metadata":{"id":"q2kNcb0-3j-s"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"EUyczG0z3nay"},"source":["## 테스트 코드"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bfW9OaPsekYX"},"outputs":[],"source":["## test 코드 #################################################################################\n","def test(epochs=10, train_mode=False, display=True, model_load=True):  # train_mode = False 테스트 모드\n","##############################################################################################\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # GPU를 사용할 경우 ???\n","    print('tensor in', device)  # GPU 사용 확인\n","    test_env = Simulator()  # 데이터셋 읽기. 그리드월드 크기 지정\n","    test_q = Qnet()\n","    test_q.to(device)\n","\n","    if model_load:\n","        ###############################################################\n","        ## 학습한 모델 불러오기\n","        ###############################################################\n","        checkpoint = torch.load(PATH)\n","        q.load_state_dict(checkpoint['model_state_dict'])\n","        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","        epoch = checkpoint['epoch']\n","        loss = checkpoint['loss']\n","        q.eval()\n","\n","    ### 액션 저장하는 txt파일 만들기 #######################\n","    f = open(__file__ + '/ogz_conv_test_gif' + '.txt', 'w')\n","    ########################################################\n","    epochs = len(test_env.files)\n","    wins = 0\n","    for n_epi in range(epochs):\n","        gridmap = test_env.reset(n_epi)  # 에피소드 시작시 12개 값 초기화\n","        history = np.stack((gridmap,gridmap,gridmap,gridmap), axis = 0) # 초기 state로 히스토리 초기화 (4,10,9)\n","        history = np.reshape([history], (1,4,10,9)) # (배치, 채널, 가로, 세로) 로 reshape\n","        history = torch.from_numpy(history).float() # 텐서로 변환   \n","        done = False\n","        mov = 0\n","        while (not done):  # 최종 목적지 [9,4] 도착\n","            mov += 1\n","            # 상태 state1에서 action 결정\n","            #####################################################################################\n","            if test_env.curloc == [9,4]:  # 출발점에서는 무조건 위로 (action=0)\n","                action = 0\n","            elif test_env.curloc[0] == 0 and test_env.curloc[1] in [0,1,2,3,4,5,6,7,8]:  # (0,0)~(0,8)에서는 무조건 아래로\n","                action = 1\n","            elif test_env.curloc[0] in [2,3,4,5] and test_env.curloc[1] == 8:  # (2,8)~(5,8)에서는 무조건 왼쪽으로\n","                action = 2\n","            elif test_env.curloc[0] in [2,3,4,5] and test_env.curloc[1] == 0:  # (2,0)~(5,0)에서는 무조건 오른쪽으로\n","                action = 3\n","            else:  # 위 경우를 제외하곤 test 액션 선택\n","                action = q.test_action(history1)\n","            #####################################################################################\n","            # action = q.test_action(state)  # 위 조건을 적용하지 않을 경우\n","            # make Move... action에 따른 이동\n","            gridmap, reward, cum_reward, done = test_env.step(action)\n","\n","            next_gridmap = np.reshape([gridmap],(1,1,10,9)) # 다음 그리드를 히스토리 사이즈에 맞게 reshape\n","            next_gridmap = torch.from_numpy(next_gridmap).float() # 텐서로 변환\n","            history = torch.cat([next_gridmap,history[:,:3,:,:]],dim=1) # (1,1+3,10,9)\n","            # 지금 있는 히스토리중 마지막 채널을 지우고 new를 제일 앞에 붙임\n","            \n","            state_ = torch.from_numpy(gridmap).float()  # 넘파이 array를 Torch 텐서로 변환  # (10, 9)\n","            state = torch.unsqueeze(state_,0)  # conv2d용 차원 증가 (1, 10, 9)\n","            state = torch.unsqueeze(state,0)  # conv2d용 (1, 1, 10, 9)\n","            if display:\n","                print('Move #%s; Taking action: %s' % (mov, action))\n","                print(gridmap.reshape(10,9))\n","\n","            if test_env.goal_ob_reward:\n","                wins += 1\n","                if display:\n","                    print(\"Game won! Reward: %s\" % (cum_reward))\n","                else:\n","                    print(\"Game LOST. Reward: %s\" % (cum_reward))\n","                    \n","            #if (mov > 100):  # 경로 길이가 너무 길어서 제외시키는 조건 추가 필요시 사용\n","                #if display:\n","                    #print(\"Game lost; too many moves.\")\n","                #break\n","        \n","    win_perc = float(wins) / float(epochs)\n","    print(\"Test performed: {0}, # of wins: {1}\".format(epochs,wins))\n","    print(\"Win percentage: {}%\".format(100.0*win_perc))\n","    return win_perc"]},{"cell_type":"code","source":["test(epochs=10, train_mode=False, display=True, model_load=True)"],"metadata":{"id":"vmYkpzs2ryd5"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"ho_Baseline_reward_DQN_Conv2D_History_v2.0_0603.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.13"}},"nbformat":4,"nbformat_minor":0}